{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 원본 데이터 성능 ===\n",
      "Mean Squared Error: 2.6148\n",
      "R2 Score: 0.9546\n",
      "\n",
      "=== 증강 데이터 성능 ===\n",
      "Mean Squared Error: 1.9914\n",
      "R2 Score: 0.9630\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-1] 데이터 증강 (Data Augmentation)\n",
    "# 숫자 데이터 : 노이즈와 비선형성 추가\n",
    "#############################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 원본 데이터 생성\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) * 10  # Feature\n",
    "y = 2.5 * X.flatten() + np.random.randn(100) * 2  # Target with noise\n",
    "\n",
    "# 원본 데이터프레임\n",
    "original_data = pd.DataFrame({\"X\": X.flatten(), \"y\": y})\n",
    "\n",
    "# 데이터 증강: 노이즈와 비선형성 추가\n",
    "augmented_X = X + np.random.randn(100, 1) * 0.2  # 작은 노이즈 추가\n",
    "augmented_y = 2.5 * augmented_X.flatten() + np.random.randn(100) * 0.5 + 0.2 * np.sin(augmented_X.flatten())  # 비선형성 추가\n",
    "augmented_data = pd.DataFrame({\"X\": augmented_X.flatten(), \"y\": augmented_y})\n",
    "\n",
    "# 데이터 병합\n",
    "combined_data = pd.concat([original_data, augmented_data], ignore_index=True)\n",
    "\n",
    "# 데이터 분리: 원본 데이터\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(\n",
    "    original_data[\"X\"].values.reshape(-1, 1), original_data[\"y\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 데이터 분리: 증강 데이터\n",
    "X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(\n",
    "    combined_data[\"X\"].values.reshape(-1, 1), combined_data[\"y\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습: 원본 데이터\n",
    "model_orig = LinearRegression()\n",
    "model_orig.fit(X_train_orig, y_train_orig)\n",
    "y_pred_orig = model_orig.predict(X_test_orig)\n",
    "\n",
    "# 모델 학습: 증강 데이터\n",
    "model_aug = LinearRegression()\n",
    "model_aug.fit(X_train_aug, y_train_aug)\n",
    "y_pred_aug = model_aug.predict(X_test_aug)\n",
    "\n",
    "# 성능 평가\n",
    "mse_orig = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "r2_orig = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "mse_aug = mean_squared_error(y_test_aug, y_pred_aug)\n",
    "r2_aug = r2_score(y_test_aug, y_pred_aug)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 원본 데이터 성능 ===\")\n",
    "print(f\"Mean Squared Error: {mse_orig:.4f}\")\n",
    "print(f\"R2 Score: {r2_orig:.4f}\")\n",
    "\n",
    "print(\"\\n=== 증강 데이터 성능 ===\")\n",
    "print(f\"Mean Squared Error: {mse_aug:.4f}\")\n",
    "print(f\"R2 Score: {r2_aug:.4f}\")\n",
    "\n",
    "# 시각화\n",
    "plt.scatter(original_data[\"X\"], original_data[\"y\"], label=\"Original Data\", color=\"blue\", alpha=0.6)\n",
    "plt.scatter(augmented_data[\"X\"], augmented_data[\"y\"], label=\"Augmented Data\", color=\"orange\", alpha=0.4)\n",
    "plt.plot(X_test_orig, y_pred_orig, label=\"Model (Original)\", color=\"green\")\n",
    "plt.plot(X_test_aug, y_pred_aug, label=\"Model (Augmented)\", color=\"red\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Original vs Augmented Data and Models\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 새로운 데이터로 평가 (기본 데이터) ===\n",
      "새로운 데이터 정확도: 1.0000\n",
      "\n",
      "=== 기본 데이터 교차 검증 결과 ===\n",
      "교차 검증 점수 (기본 데이터): [0.93103448 0.96551724 1.         1.         1.        ]\n",
      "평균 교차 검증 점수: 0.9793\n",
      "\n",
      "=== 증강 데이터 포함 교차 검증 결과 ===\n",
      "교차 검증 점수 (증강 데이터 포함): [0.96491228 1.         0.96491228 0.98245614 0.98214286]\n",
      "평균 교차 검증 점수: 0.9789\n",
      "\n",
      "=== 하이퍼파라미터 튜닝 결과 (증강 데이터 포함) ===\n",
      "최적 파라미터: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "최적 교차 검증 점수: 0.9895\n",
      "\n",
      "=== 최적 모델 교차 검증 점수 (증강 데이터 포함) ===\n",
      "교차 검증 점수: [0.96491228 1.         0.96491228 0.98245614 0.98214286]\n",
      "평균 교차 검증 점수: 0.9789\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-2] 교차 검증 (Cross-Validation) + 데이터증강\n",
    "#############################################################\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "data = load_wine()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# 데이터를 학습 데이터와 새로운 테스트 데이터로 분리\n",
    "X_train, X_new, y_train, y_new = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 증강: 노이즈 추가 및 특성 변형\n",
    "np.random.seed(42)\n",
    "noise = np.random.normal(0, 0.2, X_train.shape)  # 평균 0, 표준편차 0.2인 노이즈\n",
    "X_augmented = X_train + noise  # 노이즈 추가\n",
    "y_augmented = y_train  # 레이블은 동일\n",
    "\n",
    "# 증강 데이터 합치기\n",
    "X_combined = np.vstack((X_train, X_augmented))\n",
    "y_combined = np.hstack((y_train, y_augmented))\n",
    "\n",
    "# 기본 모델 생성\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 교차 검증 없이 학습 및 새로운 데이터 평가 (기본 데이터)\n",
    "model.fit(X_train, y_train)\n",
    "new_predictions = model.predict(X_new)\n",
    "accuracy_new_data = accuracy_score(y_new, new_predictions)\n",
    "\n",
    "# 교차 검증 (기본 데이터)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_without_augmentation = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "\n",
    "# 교차 검증 (증강 데이터 포함)\n",
    "scores_with_augmentation = cross_val_score(model, X_combined, y_combined, cv=kf)\n",
    "\n",
    "# 데이터 스케일링 포함한 파이프라인 구성\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 하이퍼파라미터 튜닝 (증강 데이터 포함)\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 150],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "# 최적 모델로 교차 검증\n",
    "best_model = grid_search.best_estimator_\n",
    "scores_with_tuning = cross_val_score(best_model, X_combined, y_combined, cv=kf)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 새로운 데이터로 평가 (기본 데이터) ===\")\n",
    "print(f\"새로운 데이터 정확도: {accuracy_new_data:.4f}\")\n",
    "\n",
    "print(\"\\n=== 기본 데이터 교차 검증 결과 ===\")\n",
    "print(f\"교차 검증 점수 (기본 데이터): {scores_without_augmentation}\")\n",
    "print(f\"평균 교차 검증 점수: {scores_without_augmentation.mean():.4f}\")\n",
    "\n",
    "print(\"\\n=== 증강 데이터 포함 교차 검증 결과 ===\")\n",
    "print(f\"교차 검증 점수 (증강 데이터 포함): {scores_with_augmentation}\")\n",
    "print(f\"평균 교차 검증 점수: {scores_with_augmentation.mean():.4f}\")\n",
    "\n",
    "print(\"\\n=== 하이퍼파라미터 튜닝 결과 (증강 데이터 포함) ===\")\n",
    "print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
    "print(f\"최적 교차 검증 점수: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\n=== 최적 모델 교차 검증 점수 (증강 데이터 포함) ===\")\n",
    "print(f\"교차 검증 점수: {scores_with_tuning}\")\n",
    "print(f\"평균 교차 검증 점수: {scores_with_tuning.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 (일부):\n",
      " [[  -1.8306   -9.534  -654.0757    0.7241   -0.1813]\n",
      " [   0.2603    8.0151 -413.4652   -1.2733    1.4826]\n",
      " [  -1.3796    9.8744 -971.6567   -0.0728   -1.5796]\n",
      " [  -0.9981  -16.1506 1051.9476    2.3985    2.1207]\n",
      " [  -0.3696  122.3565  621.5719    0.0128   -1.4224]]\n",
      "\n",
      "스케일링된 데이터 (훈련 세트 일부):\n",
      " [[0.5246 0.7534 0.5159 0.7898 0.714 ]\n",
      " [0.6738 0.2881 0.6199 0.4736 0.4592]\n",
      " [0.3458 0.3688 0.2804 0.1617 0.5876]\n",
      " [0.3992 0.5641 0.541  0.6432 0.4749]\n",
      " [0.5227 0.4134 0.4271 0.1323 0.6014]]\n",
      "\n",
      "=== 평가 결과 ===\n",
      "원본 데이터 테스트 정확도: 0.8480\n",
      "스케일링된 데이터 테스트 정확도: 0.9360\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-3] 데이터 스케일링 (Data Scaling)\n",
    "# MinMaxScaler : 데이터를 특정 범위(기본값: [0, 1])로 정규화\n",
    "# 𝑋 : 원본 데이터 값\n",
    "# 𝑋_{min}  : 각 열의 최소값\n",
    "# 𝑋_{max}  : 각 열의 최대값\n",
    "# 𝑋′ : 변환된 데이터 값\n",
    "\n",
    "# 𝑋′ = (𝑋 - 𝑋_{min}) / (𝑋_{max} - 𝑋_{min})\n",
    "#############################################################\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 출력 형식 설정 (소수점 이하 4자리까지)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# 데이터 생성\n",
    "X, y = make_classification(\n",
    "    n_samples=500,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 인위적으로 특성의 스케일 차이를 크게 만듦\n",
    "X[:, 0] *= 1    # 첫 번째 특성: 0~1\n",
    "X[:, 1] *= 100  # 두 번째 특성: 0~100\n",
    "X[:, 2] *= 1000 # 세 번째 특성: 0~1000\n",
    "\n",
    "print(\"원본 데이터 (일부):\\n\", X[:5])\n",
    "\n",
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# KNN 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 1. 원본 데이터로 평가\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_original = knn.predict(X_test)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n스케일링된 데이터 (훈련 세트 일부):\\n\", X_train_scaled[:5])\n",
    "\n",
    "# 스케일링된 데이터 학습 및 평가\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = knn.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n=== 평가 결과 ===\")\n",
    "print(f\"원본 데이터 테스트 정확도: {accuracy_original:.4f}\")\n",
    "print(f\"스케일링된 데이터 테스트 정확도: {accuracy_scaled:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 클래스 분포:\n",
      " 1    1990\n",
      "0      10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[교차 검증] 원본 데이터 ROC-AUC: 1.0\n",
      "\n",
      "[분리 평가] === 원본 데이터 평가 결과 ===\n",
      "정확도: 1.0000\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00       498\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       1.00      1.00      1.00       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n",
      "\n",
      "ADASYN 적용 후 클래스 분포 (전체 데이터):\n",
      " 1    1990\n",
      "0     996\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[교차 검증] ADASYN 데이터 ROC-AUC: 0.9999874371859295\n",
      "\n",
      "[분리 평가] === ADASYN 데이터 평가 결과 ===\n",
      "정확도: 0.9980\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      1.00      1.00       498\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       0.83      1.00      0.90       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n",
      "\n",
      "SMOTE 적용 후 클래스 분포 (전체 데이터):\n",
      " 1    1990\n",
      "0     995\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[교차 검증] SMOTE 데이터 ROC-AUC: 0.9999911618393476\n",
      "\n",
      "[분리 평가] === SMOTE 데이터 평가 결과 ===\n",
      "정확도: 0.9980\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      1.00      1.00       498\n",
      "\n",
      "    accuracy                           1.00       500\n",
      "   macro avg       0.83      1.00      0.90       500\n",
      "weighted avg       1.00      1.00      1.00       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-4] 데이터 불균형 처리 (Handling Imbalanced Data)\n",
    "# ADASYN + SMOTE(Synthetic Minority Over-sampling Technique)\n",
    "#############################################################\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# 극단적인 불균형 데이터 생성\n",
    "X, y = make_classification(\n",
    "    n_classes=2,          # 이진 분류\n",
    "    class_sep=2,          # 클래스 간 분리 정도\n",
    "    weights=[0.005, 0.995], # 클래스 비율: 0.5% vs 99.5%\n",
    "    n_informative=3,      # 정보가 있는 독립 변수 3개\n",
    "    n_redundant=1,        # 중복된 독립 변수 1개\n",
    "    flip_y=0,             # 라벨 뒤집기 비율 없음\n",
    "    n_features=5,         # 총 특성 수: 5개\n",
    "    n_clusters_per_class=1, # 각 클래스 하나의 클러스터\n",
    "    n_samples=2000,       # 총 샘플 수: 2000개\n",
    "    random_state=10       # 난수 고정\n",
    ")\n",
    "print(\"원본 클래스 분포:\\n\", pd.Series(y).value_counts())\n",
    "\n",
    "# 교차 검증 설정\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 1. 원본 데이터 교차 검증 평가\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "scores_original = cross_val_score(model, X, y, cv=kf, scoring='roc_auc')\n",
    "print(\"\\n[교차 검증] 원본 데이터 ROC-AUC:\", scores_original.mean())\n",
    "\n",
    "# 데이터 분리 (훈련 세트와 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# 2. 원본 데이터 분리 평가\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_original = model.predict(X_test)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "\n",
    "print(\"\\n[분리 평가] === 원본 데이터 평가 결과 ===\")\n",
    "print(f\"정확도: {accuracy_original:.4f}\")\n",
    "print(\"분류 리포트:\\n\", classification_report(y_test, y_pred_original, zero_division=0))\n",
    "\n",
    "# ADASYN 적용\n",
    "adasyn = ADASYN(sampling_strategy=0.5, random_state=42)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X, y)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "print(\"\\nADASYN 적용 후 클래스 분포 (전체 데이터):\\n\", pd.Series(y_adasyn).value_counts())\n",
    "\n",
    "# 3. ADASYN 교차 검증 평가\n",
    "scores_adasyn = cross_val_score(model, X_adasyn, y_adasyn, cv=kf, scoring='roc_auc')\n",
    "print(\"\\n[교차 검증] ADASYN 데이터 ROC-AUC:\", scores_adasyn.mean())\n",
    "\n",
    "# 4. ADASYN 분리 평가\n",
    "model.fit(X_train_adasyn, y_train_adasyn)\n",
    "y_pred_adasyn = model.predict(X_test)\n",
    "accuracy_adasyn = accuracy_score(y_test, y_pred_adasyn)\n",
    "\n",
    "print(\"\\n[분리 평가] === ADASYN 데이터 평가 결과 ===\")\n",
    "print(f\"정확도: {accuracy_adasyn:.4f}\")\n",
    "print(\"분류 리포트:\\n\", classification_report(y_test, y_pred_adasyn, zero_division=0))\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(\"\\nSMOTE 적용 후 클래스 분포 (전체 데이터):\\n\", pd.Series(y_smote).value_counts())\n",
    "\n",
    "# 5. SMOTE 교차 검증 평가\n",
    "scores_smote = cross_val_score(model, X_smote, y_smote, cv=kf, scoring='roc_auc')\n",
    "print(\"\\n[교차 검증] SMOTE 데이터 ROC-AUC:\", scores_smote.mean())\n",
    "\n",
    "# 6. SMOTE 분리 평가\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = model.predict(X_test)\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "\n",
    "print(\"\\n[분리 평가] === SMOTE 데이터 평가 결과 ===\")\n",
    "print(f\"정확도: {accuracy_smote:.4f}\")\n",
    "print(\"분류 리포트:\\n\", classification_report(y_test, y_pred_smote, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with missing values:\n",
      "sepal length (cm)    1\n",
      "sepal width (cm)     5\n",
      "petal length (cm)    3\n",
      "petal width (cm)     1\n",
      "dtype: int64\n",
      "\n",
      "Accuracy before handling missing values (0 imputation): 0.96\n",
      "Accuracy after dropping missing samples: 0.98\n",
      "Accuracy after handling missing values (mean imputation): 0.96\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-5] 결측값 처리(Handling Missing Data)\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Iris 데이터 로드\n",
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "\n",
    "# 2. 데이터 준비 (입력 특성과 타겟 분리)\n",
    "X = iris_df.iloc[:, :-1]  # 입력 특성 (꽃받침, 꽃잎)\n",
    "y = iris_df['target']     # 타겟 (클래스)\n",
    "\n",
    "# 3. 결측값 생성 (예제용)\n",
    "# 랜덤으로 10개의 값에 결측값(NaN)을 삽입\n",
    "np.random.seed(42)\n",
    "missing_indices = np.random.choice(X.size, 10, replace=False)\n",
    "X_flat = X.values.flatten()\n",
    "X_flat[missing_indices] = np.nan\n",
    "X_with_missing = pd.DataFrame(X_flat.reshape(X.shape), columns=X.columns)\n",
    "\n",
    "# 결측값 확인\n",
    "print(\"Data with missing values:\")\n",
    "print(X_with_missing.isnull().sum())\n",
    "\n",
    "# 4. 결측값 처리 방법\n",
    "# (1) 결측값을 포함한 데이터를 그대로 사용 (결측값을 0으로 대체)\n",
    "X_with_zeros = X_with_missing.fillna(0)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X_with_zeros, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# (2) 결측값이 있는 샘플 제거\n",
    "X_dropped = X_with_missing.dropna()\n",
    "y_dropped = y[X_with_missing.dropna().index]\n",
    "X_train_dropped, X_test_dropped, y_train_dropped, y_test_dropped = train_test_split(\n",
    "    X_dropped, y_dropped, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# (3) 결측값을 평균값으로 대체\n",
    "X_imputed = X_with_missing.fillna(X_with_missing.mean())\n",
    "X_train_imputed, X_test_imputed, y_train_imputed, y_test_imputed = train_test_split(\n",
    "    X_imputed, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. 모델 학습 및 평가\n",
    "# (1) 결측값 처리 전 (0 대체)\n",
    "model_raw = LogisticRegression(max_iter=200)\n",
    "model_raw.fit(X_train_raw, y_train_raw)\n",
    "y_pred_raw = model_raw.predict(X_test_raw)\n",
    "accuracy_raw = accuracy_score(y_test_raw, y_pred_raw)\n",
    "\n",
    "# (2) 결측값 제거 데이터 사용\n",
    "model_dropped = LogisticRegression(max_iter=200)\n",
    "model_dropped.fit(X_train_dropped, y_train_dropped)\n",
    "y_pred_dropped = model_dropped.predict(X_test_dropped)\n",
    "accuracy_dropped = accuracy_score(y_test_dropped, y_pred_dropped)\n",
    "\n",
    "# (3) 결측값을 평균값으로 대체한 데이터 사용\n",
    "model_imputed = LogisticRegression(max_iter=200)\n",
    "model_imputed.fit(X_train_imputed, y_train_imputed)\n",
    "y_pred_imputed = model_imputed.predict(X_test_imputed)\n",
    "accuracy_imputed = accuracy_score(y_test_imputed, y_pred_imputed)\n",
    "\n",
    "# 6. 결과 출력\n",
    "print(f\"\\nAccuracy before handling missing values (0 imputation): {accuracy_raw:.2f}\")\n",
    "print(f\"Accuracy after dropping missing samples: {accuracy_dropped:.2f}\")\n",
    "print(f\"Accuracy after handling missing values (mean imputation): {accuracy_imputed:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "15                5.7               4.4                1.5               0.4   \n",
      "32                5.2               4.1                1.5               0.1   \n",
      "33                5.5               4.2                1.4               0.2   \n",
      "60                5.0               2.0                3.5               1.0   \n",
      "\n",
      "                           Reason  \n",
      "15  sepal width (cm) out of range  \n",
      "32  sepal width (cm) out of range  \n",
      "33  sepal width (cm) out of range  \n",
      "60  sepal width (cm) out of range  \n",
      "\n",
      "Original data size: 150\n",
      "Data size after removing outliers: 146\n",
      "Number of outliers detected: 4\n",
      "\n",
      "Accuracy before removing outliers: 1.00\n",
      "Accuracy after removing outliers: 0.95\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-6] 이상치 탐지(Outlier Detection)\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Iris 데이터 로드\n",
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "\n",
    "# 2. 데이터 준비 (입력 특성과 타겟 분리)\n",
    "X = iris_df.iloc[:, :-1]  # 입력 특성 (꽃받침, 꽃잎)\n",
    "y = iris_df['target']     # 타겟 (클래스)\n",
    "\n",
    "# 3. 이상치 탐지 및 제거\n",
    "def detect_outliers_iqr(data):\n",
    "    \"\"\"IQR(사분위 범위)을 사용하여 이상치 탐지\"\"\"\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = (data < lower_bound) | (data > upper_bound)\n",
    "    return ~outliers.any(axis=1), outliers\n",
    "\n",
    "# 이상치 탐지\n",
    "outlier_mask, outliers_boolean = detect_outliers_iqr(X)\n",
    "X_no_outliers = X[outlier_mask]\n",
    "y_no_outliers = y[outlier_mask]\n",
    "\n",
    "# 이상치 데이터 추출\n",
    "outliers_detected = X[~outlier_mask].copy()\n",
    "\n",
    "# 이상치 사유 추가\n",
    "reasons = []\n",
    "for index, row in outliers_detected.iterrows():\n",
    "    reason = []\n",
    "    for column in X.columns:\n",
    "        if outliers_boolean.at[index, column]:\n",
    "            reason.append(f\"{column} out of range\")\n",
    "    reasons.append(\", \".join(reason))\n",
    "outliers_detected['Reason'] = reasons\n",
    "\n",
    "print(\"Outliers detected:\")\n",
    "print(outliers_detected)\n",
    "\n",
    "# 이상치 개수 확인\n",
    "print(f\"\\nOriginal data size: {X.shape[0]}\")\n",
    "print(f\"Data size after removing outliers: {X_no_outliers.shape[0]}\")\n",
    "print(f\"Number of outliers detected: {X.shape[0] - X_no_outliers.shape[0]}\")\n",
    "\n",
    "# 4. 데이터 분리 (학습/테스트 셋)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_no_outliers, X_test_no_outliers, y_train_no_outliers, y_test_no_outliers = train_test_split(\n",
    "    X_no_outliers, y_no_outliers, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. 모델 학습 및 평가\n",
    "# (1) 이상치 제거 전\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_before = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# (2) 이상치 제거 후\n",
    "model_no_outliers = LogisticRegression(max_iter=200)\n",
    "model_no_outliers.fit(X_train_no_outliers, y_train_no_outliers)\n",
    "y_pred_no_outliers = model_no_outliers.predict(X_test_no_outliers)\n",
    "accuracy_after = accuracy_score(y_test_no_outliers, y_pred_no_outliers)\n",
    "\n",
    "# 6. 결과 출력\n",
    "print(f\"\\nAccuracy before removing outliers: {accuracy_before:.2f}\")\n",
    "print(f\"Accuracy after removing outliers: {accuracy_after:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected:\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "13                 4.3               3.0                1.1               0.1   \n",
      "15                 5.7               4.4                1.5               0.4   \n",
      "22                 4.6               3.6                1.0               0.2   \n",
      "23                 5.1               3.3                1.7               0.5   \n",
      "24                 4.8               3.4                1.9               0.2   \n",
      "41                 4.5               2.3                1.3               0.3   \n",
      "43                 5.0               3.5                1.6               0.6   \n",
      "44                 5.1               3.8                1.9               0.4   \n",
      "98                 5.1               2.5                3.0               1.1   \n",
      "106                4.9               2.5                4.5               1.7   \n",
      "117                7.7               3.8                6.7               2.2   \n",
      "119                6.0               2.2                5.0               1.5   \n",
      "131                7.9               3.8                6.4               2.0   \n",
      "\n",
      "                           Reason  \n",
      "13   petal length (cm) below 1.14  \n",
      "15    sepal width (cm) above 4.39  \n",
      "22   petal length (cm) below 1.14  \n",
      "23    petal width (cm) above 0.45  \n",
      "24   petal length (cm) above 1.84  \n",
      "41    sepal width (cm) below 2.49  \n",
      "43    petal width (cm) above 0.45  \n",
      "44   petal length (cm) above 1.84  \n",
      "98   petal length (cm) below 3.10  \n",
      "106  sepal length (cm) below 5.21  \n",
      "117   sepal width (cm) above 3.74  \n",
      "119   sepal width (cm) below 2.24  \n",
      "131   sepal width (cm) above 3.74  \n",
      "\n",
      "Original data size: 150\n",
      "Data size after removing outliers: 137\n",
      "Number of outliers detected: 13\n",
      "\n",
      "Accuracy before removing outliers: 1.00\n",
      "Accuracy after removing outliers: 0.93\n",
      "Removing outliers decreased the model's accuracy.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-6] 이상치 탐지(Outlier Detection) - 클래스별 이상치탐지\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Iris 데이터 로드\n",
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "\n",
    "# 2. 데이터 준비 (입력 특성과 타겟 분리)\n",
    "X = iris_df.iloc[:, :-1]  # 입력 특성 (꽃받침, 꽃잎)\n",
    "y = iris_df['target']     # 타겟 (클래스)\n",
    "\n",
    "# 3. 클래스별 IQR 기반 이상치 탐지\n",
    "def detect_outliers_iqr_by_class(data, target):\n",
    "    \"\"\"클래스별 IQR을 사용하여 이상치 탐지\"\"\"\n",
    "    outlier_mask = pd.Series(True, index=data.index)\n",
    "    reasons = pd.Series(\"\", index=data.index)\n",
    "\n",
    "    for cls in target.unique():\n",
    "        cls_data = data[target == cls]\n",
    "        Q1 = cls_data.quantile(0.25)\n",
    "        Q3 = cls_data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        cls_outliers = ~((cls_data >= lower_bound) & (cls_data <= upper_bound)).all(axis=1)\n",
    "\n",
    "        # 업데이트: 클래스별 마스크 및 이상치 사유 기록\n",
    "        outlier_mask[cls_data.index] &= ~cls_outliers\n",
    "        for idx, row in cls_data.iterrows():\n",
    "            if cls_outliers.at[idx]:\n",
    "                reason = []\n",
    "                for column in data.columns:\n",
    "                    if row[column] < lower_bound[column]:\n",
    "                        reason.append(f\"{column} below {lower_bound[column]:.2f}\")\n",
    "                    elif row[column] > upper_bound[column]:\n",
    "                        reason.append(f\"{column} above {upper_bound[column]:.2f}\")\n",
    "                reasons.at[idx] = \", \".join(reason)\n",
    "\n",
    "    return outlier_mask, reasons\n",
    "\n",
    "# 이상치 탐지 수행\n",
    "class_outlier_mask, outlier_reasons = detect_outliers_iqr_by_class(X, y)\n",
    "X_no_outliers = X[class_outlier_mask]\n",
    "y_no_outliers = y[class_outlier_mask]\n",
    "\n",
    "# 이상치 데이터 출력\n",
    "outliers_detected = X[~class_outlier_mask].copy()\n",
    "outliers_detected[\"Reason\"] = outlier_reasons[~class_outlier_mask]\n",
    "\n",
    "print(\"Outliers detected:\")\n",
    "print(outliers_detected)\n",
    "\n",
    "# 이상치 개수 확인\n",
    "print(f\"\\nOriginal data size: {X.shape[0]}\")\n",
    "print(f\"Data size after removing outliers: {X_no_outliers.shape[0]}\")\n",
    "print(f\"Number of outliers detected: {X.shape[0] - X_no_outliers.shape[0]}\")\n",
    "\n",
    "# 4. 데이터 분리 (학습/테스트 셋)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_no_outliers, X_test_no_outliers, y_train_no_outliers, y_test_no_outliers = train_test_split(\n",
    "    X_no_outliers, y_no_outliers, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. 모델 학습 및 평가\n",
    "# (1) 이상치 제거 전\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_before = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# (2) 이상치 제거 후\n",
    "model_no_outliers = LogisticRegression(max_iter=200)\n",
    "model_no_outliers.fit(X_train_no_outliers, y_train_no_outliers)\n",
    "y_pred_no_outliers = model_no_outliers.predict(X_test_no_outliers)\n",
    "accuracy_after = accuracy_score(y_test_no_outliers, y_pred_no_outliers)\n",
    "\n",
    "# 6. 결과 출력\n",
    "print(f\"\\nAccuracy before removing outliers: {accuracy_before:.2f}\")\n",
    "print(f\"Accuracy after removing outliers: {accuracy_after:.2f}\")\n",
    "\n",
    "if accuracy_after > accuracy_before:\n",
    "    print(\"Removing outliers improved the model's accuracy.\")\n",
    "elif accuracy_after == accuracy_before:\n",
    "    print(\"Removing outliers had no effect on the model's accuracy.\")\n",
    "else:\n",
    "    print(\"Removing outliers decreased the model's accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with duplicates:\n",
      "3 duplicate rows added.\n",
      "\n",
      "Accuracy with duplicates: 1.00\n",
      "Accuracy without duplicates: 1.00\n",
      "Duplicates had no effect on the model's accuracy.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-7] 데이터 중복 제거(Data Deduplication) LogisticRegression\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Iris 데이터 로드\n",
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "\n",
    "# 2. 중복 데이터 생성\n",
    "# 첫 번째와 두 번째 행을 복사하여 데이터프레임에 추가 (중복 데이터)\n",
    "duplicated_rows = iris_df.iloc[[0, 1]]\n",
    "iris_with_duplicates = pd.concat([iris_df, duplicated_rows], ignore_index=True)\n",
    "\n",
    "# 중복 데이터 확인\n",
    "print(\"Data with duplicates:\")\n",
    "print(iris_with_duplicates.duplicated().sum(), \"duplicate rows added.\")\n",
    "\n",
    "# 3. 데이터 준비 (입력 특성과 타겟 분리)\n",
    "X = iris_with_duplicates.iloc[:, :-1]  # 입력 특성 (꽃받침, 꽃잎)\n",
    "y = iris_with_duplicates['target']     # 타겟 (클래스)\n",
    "\n",
    "# 4. 데이터 중복 제거\n",
    "# 중복 데이터 제거\n",
    "X_no_duplicates = X[~iris_with_duplicates.duplicated()]\n",
    "y_no_duplicates = y[~iris_with_duplicates.duplicated()]\n",
    "\n",
    "# 5. 데이터 분리 (중복 제거 전후)\n",
    "# - 중복 데이터 포함\n",
    "X_train_with_duplicates, X_test_with_duplicates, y_train_with_duplicates, y_test_with_duplicates = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "# - 중복 데이터 제거\n",
    "X_train_no_duplicates, X_test_no_duplicates, y_train_no_duplicates, y_test_no_duplicates = train_test_split(\n",
    "    X_no_duplicates, y_no_duplicates, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 6. 모델 학습 및 평가\n",
    "# (1) 중복 데이터 포함\n",
    "model_with_duplicates = LogisticRegression(max_iter=200)\n",
    "model_with_duplicates.fit(X_train_with_duplicates, y_train_with_duplicates)\n",
    "y_pred_with_duplicates = model_with_duplicates.predict(X_test_with_duplicates)\n",
    "accuracy_with_duplicates = accuracy_score(y_test_with_duplicates, y_pred_with_duplicates)\n",
    "\n",
    "# (2) 중복 데이터 제거\n",
    "model_no_duplicates = LogisticRegression(max_iter=200)\n",
    "model_no_duplicates.fit(X_train_no_duplicates, y_train_no_duplicates)\n",
    "y_pred_no_duplicates = model_no_duplicates.predict(X_test_no_duplicates)\n",
    "accuracy_no_duplicates = accuracy_score(y_test_no_duplicates, y_pred_no_duplicates)\n",
    "\n",
    "# 7. 결과 출력\n",
    "print(f\"\\nAccuracy with duplicates: {accuracy_with_duplicates:.2f}\")\n",
    "print(f\"Accuracy without duplicates: {accuracy_no_duplicates:.2f}\")\n",
    "\n",
    "# 8. 결과 비교 분석\n",
    "if accuracy_with_duplicates > accuracy_no_duplicates:\n",
    "    print(\"Including duplicates improved accuracy, but it may indicate overfitting.\")\n",
    "elif accuracy_with_duplicates == accuracy_no_duplicates:\n",
    "    print(\"Duplicates had no effect on the model's accuracy.\")\n",
    "else:\n",
    "    print(\"Removing duplicates improved the model's accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with duplicates:\n",
      "3 duplicate rows added.\n",
      "\n",
      "Accuracy with duplicates (Random Forest): 0.96\n",
      "Accuracy without duplicates (Random Forest): 1.00\n",
      "Removing duplicates improved the model's accuracy.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-7] 데이터 중복 제거(Data Deduplication) RandomForestClassifier\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Iris 데이터 로드\n",
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "\n",
    "# 2. 중복 데이터 생성\n",
    "# 첫 번째와 두 번째 행을 복사하여 데이터프레임에 추가 (중복 데이터)\n",
    "duplicated_rows = iris_df.iloc[[0, 1]]\n",
    "iris_with_duplicates = pd.concat([iris_df, duplicated_rows], ignore_index=True)\n",
    "\n",
    "# 중복 데이터 확인\n",
    "print(\"Data with duplicates:\")\n",
    "print(iris_with_duplicates.duplicated().sum(), \"duplicate rows added.\")\n",
    "\n",
    "# 3. 데이터 준비 (입력 특성과 타겟 분리)\n",
    "X = iris_with_duplicates.iloc[:, :-1]  # 입력 특성 (꽃받침, 꽃잎)\n",
    "y = iris_with_duplicates['target']     # 타겟 (클래스)\n",
    "\n",
    "# 4. 데이터 중복 제거\n",
    "# 중복 데이터 제거\n",
    "X_no_duplicates = X[~iris_with_duplicates.duplicated()]\n",
    "y_no_duplicates = y[~iris_with_duplicates.duplicated()]\n",
    "\n",
    "# 5. 데이터 분리 (중복 제거 전후)\n",
    "# - 중복 데이터 포함\n",
    "X_train_with_duplicates, X_test_with_duplicates, y_train_with_duplicates, y_test_with_duplicates = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "# - 중복 데이터 제거\n",
    "X_train_no_duplicates, X_test_no_duplicates, y_train_no_duplicates, y_test_no_duplicates = train_test_split(\n",
    "    X_no_duplicates, y_no_duplicates, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 6. 모델 학습 및 평가\n",
    "# (1) 중복 데이터 포함\n",
    "model_with_duplicates = RandomForestClassifier(random_state=42)\n",
    "model_with_duplicates.fit(X_train_with_duplicates, y_train_with_duplicates)\n",
    "y_pred_with_duplicates = model_with_duplicates.predict(X_test_with_duplicates)\n",
    "accuracy_with_duplicates = accuracy_score(y_test_with_duplicates, y_pred_with_duplicates)\n",
    "\n",
    "# (2) 중복 데이터 제거\n",
    "model_no_duplicates = RandomForestClassifier(random_state=42)\n",
    "model_no_duplicates.fit(X_train_no_duplicates, y_train_no_duplicates)\n",
    "y_pred_no_duplicates = model_no_duplicates.predict(X_test_no_duplicates)\n",
    "accuracy_no_duplicates = accuracy_score(y_test_no_duplicates, y_pred_no_duplicates)\n",
    "\n",
    "# 7. 결과 출력\n",
    "print(f\"\\nAccuracy with duplicates (Random Forest): {accuracy_with_duplicates:.2f}\")\n",
    "print(f\"Accuracy without duplicates (Random Forest): {accuracy_no_duplicates:.2f}\")\n",
    "\n",
    "# 8. 결과 비교 분석\n",
    "if accuracy_with_duplicates > accuracy_no_duplicates:\n",
    "    print(\"Including duplicates improved accuracy, but it may indicate overfitting.\")\n",
    "elif accuracy_with_duplicates == accuracy_no_duplicates:\n",
    "    print(\"Duplicates had no effect on the model's accuracy.\")\n",
    "else:\n",
    "    print(\"Removing duplicates improved the model's accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with raw data: 1.00\n",
      "Accuracy with scaled data (StandardScaler): 1.00\n",
      "Accuracy with log-transformed data: 0.93\n",
      "Raw data provided the highest accuracy.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-8] 데이터 변환(Data Transformation) - iris data\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 1. Iris 데이터 로드\n",
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "\n",
    "# 2. 데이터 준비 (입력 특성과 타겟 분리)\n",
    "X = iris_df.iloc[:, :-1]  # 입력 특성 (꽃받침, 꽃잎)\n",
    "y = iris_df['target']     # 타겟 (클래스)\n",
    "\n",
    "# 3. 데이터 변환\n",
    "# (1) 스케일링 (표준화)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# (2) 로그 변환\n",
    "X_log_transformed = np.log1p(X)\n",
    "\n",
    "# 4. 데이터 분리 (학습/테스트 셋)\n",
    "# 원본 데이터\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# 스케일링 데이터\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "# 로그 변환 데이터\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_log_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 5. 모델 학습 및 평가\n",
    "# (1) 원본 데이터\n",
    "model_raw = LogisticRegression(max_iter=200)\n",
    "model_raw.fit(X_train_raw, y_train_raw)\n",
    "y_pred_raw = model_raw.predict(X_test_raw)\n",
    "accuracy_raw = accuracy_score(y_test_raw, y_pred_raw)\n",
    "\n",
    "# (2) 스케일링 데이터\n",
    "model_scaled = LogisticRegression(max_iter=200)\n",
    "model_scaled.fit(X_train_scaled, y_train_scaled)\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test_scaled, y_pred_scaled)\n",
    "\n",
    "# (3) 로그 변환 데이터\n",
    "model_log = LogisticRegression(max_iter=200)\n",
    "model_log.fit(X_train_log, y_train_log)\n",
    "y_pred_log = model_log.predict(X_test_log)\n",
    "accuracy_log = accuracy_score(y_test_log, y_pred_log)\n",
    "\n",
    "# 6. 결과 출력\n",
    "print(f\"\\nAccuracy with raw data: {accuracy_raw:.2f}\")\n",
    "print(f\"Accuracy with scaled data (StandardScaler): {accuracy_scaled:.2f}\")\n",
    "print(f\"Accuracy with log-transformed data: {accuracy_log:.2f}\")\n",
    "\n",
    "# 7. 결과 비교 분석\n",
    "if max(accuracy_raw, accuracy_scaled, accuracy_log) == accuracy_raw:\n",
    "    print(\"Raw data provided the highest accuracy.\")\n",
    "elif max(accuracy_raw, accuracy_scaled, accuracy_log) == accuracy_scaled:\n",
    "    print(\"Scaled data provided the highest accuracy.\")\n",
    "elif max(accuracy_raw, accuracy_scaled, accuracy_log) == accuracy_log:\n",
    "    print(\"Log-transformed data provided the highest accuracy.\")\n",
    "else:\n",
    "    print(\"Multiple methods resulted in the same accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California housing dataset loaded successfully!\n",
      "\n",
      "Feature statistics before transformation:\n",
      "           longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count   20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "unique           NaN           NaN                 NaN           NaN   \n",
      "top              NaN           NaN                 NaN           NaN   \n",
      "freq             NaN           NaN                 NaN           NaN   \n",
      "mean     -119.569704     35.631861           28.639486   2635.763081   \n",
      "std         2.003532      2.135952           12.585558   2181.615252   \n",
      "min      -124.350000     32.540000            1.000000      2.000000   \n",
      "25%      -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%      -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%      -118.010000     37.710000           37.000000   3148.000000   \n",
      "max      -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "        total_bedrooms    population    households  median_income  \\\n",
      "count     20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "unique             NaN           NaN           NaN            NaN   \n",
      "top                NaN           NaN           NaN            NaN   \n",
      "freq               NaN           NaN           NaN            NaN   \n",
      "mean        537.870553   1425.476744    499.539680       3.870671   \n",
      "std         421.385070   1132.462122    382.329753       1.899822   \n",
      "min           1.000000      3.000000      1.000000       0.499900   \n",
      "25%         296.000000    787.000000    280.000000       2.563400   \n",
      "50%         435.000000   1166.000000    409.000000       3.534800   \n",
      "75%         647.000000   1725.000000    605.000000       4.743250   \n",
      "max        6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "        median_house_value ocean_proximity  \n",
      "count         20640.000000           20640  \n",
      "unique                 NaN               5  \n",
      "top                    NaN       <1H OCEAN  \n",
      "freq                   NaN            9136  \n",
      "mean         206855.816909             NaN  \n",
      "std          115395.615874             NaN  \n",
      "min           14999.000000             NaN  \n",
      "25%          119600.000000             NaN  \n",
      "50%          179700.000000             NaN  \n",
      "75%          264725.000000             NaN  \n",
      "max          500001.000000             NaN  \n",
      "\n",
      "Evaluation Results (MSE, MAE, RMSE, R2 Score, Explained Variance Score):\n",
      "Raw: MSE = 4730676245.23, MAE = 50100.15, RMSE = 68779.91, R2 = 0.6396, EVS = 0.6396\n",
      "Standard Scaled: MSE = 4730676245.23, MAE = 50100.15, RMSE = 68779.91, R2 = 0.6396, EVS = 0.6396\n",
      "Log-transformed: MSE = 5163513024.46, MAE = 53394.98, RMSE = 71857.59, R2 = 0.6066, EVS = 0.6066\n",
      "Min-Max Scaled: MSE = 4730676245.23, MAE = 50100.15, RMSE = 68779.91, R2 = 0.6396, EVS = 0.6396\n",
      "\n",
      "Standard scaling provided the best R² score.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-8] 데이터 변환(Data Transformation) - housing.csv data\n",
    "#############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import math\n",
    "\n",
    "# 1. 데이터 로드\n",
    "url = \"https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-15/housing.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"California housing dataset loaded successfully!\")\n",
    "print(\"\\nFeature statistics before transformation:\")\n",
    "print(data.describe(include=\"all\"))\n",
    "\n",
    "# 2. 범주형 데이터 처리\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_columns = encoder.fit_transform(data[[\"ocean_proximity\"]])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_columns, columns=encoder.get_feature_names_out([\"ocean_proximity\"])\n",
    ")\n",
    "\n",
    "# 원본 데이터에서 `ocean_proximity` 제거 후 인코딩된 데이터 추가\n",
    "data = pd.concat([data.drop(columns=[\"ocean_proximity\"]), encoded_df], axis=1)\n",
    "\n",
    "# 3. 결측값 처리\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# 데이터 준비\n",
    "X = data_imputed.drop(columns=[\"median_house_value\"])  # 특성 데이터\n",
    "y = data_imputed[\"median_house_value\"]  # 타깃 변수\n",
    "\n",
    "# 4. 데이터 변환\n",
    "# (1) 원본 데이터\n",
    "X_raw = X.copy()\n",
    "\n",
    "# (2) 스케일링 (표준화)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# (3) 로그 변환\n",
    "X_log_transformed = X.copy()\n",
    "for column in X_log_transformed.columns:\n",
    "    if (X_log_transformed[column] <= 0).any():\n",
    "        X_log_transformed[column] += abs(X_log_transformed[column].min()) + 1\n",
    "X_log_transformed = np.log1p(X_log_transformed)\n",
    "X_log_transformed = pd.DataFrame(\n",
    "    SimpleImputer(strategy=\"mean\").fit_transform(X_log_transformed), columns=X.columns\n",
    ")\n",
    "\n",
    "# (4) Min-Max Scaling\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_minmax_scaled = pd.DataFrame(minmax_scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 5. 데이터 분리\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y, test_size=0.3, random_state=42)\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_log_transformed, y, test_size=0.3, random_state=42)\n",
    "X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax = train_test_split(X_minmax_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 6. 모델 학습 및 평가\n",
    "def calculate_rmse(mse):\n",
    "    return math.sqrt(mse)\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = calculate_rmse(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    evs = explained_variance_score(y_test, y_pred)\n",
    "    return mse, mae, rmse, r2, evs\n",
    "\n",
    "# 평가 결과 저장\n",
    "results = {}\n",
    "\n",
    "# (1) 원본 데이터\n",
    "model_raw = LinearRegression()\n",
    "results[\"Raw\"] = evaluate_model(model_raw, X_train_raw, X_test_raw, y_train_raw, y_test_raw)\n",
    "\n",
    "# (2) 스케일링 데이터\n",
    "model_scaled = LinearRegression()\n",
    "results[\"Standard Scaled\"] = evaluate_model(model_scaled, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled)\n",
    "\n",
    "# (3) 로그 변환 데이터\n",
    "model_log = LinearRegression()\n",
    "results[\"Log-transformed\"] = evaluate_model(model_log, X_train_log, X_test_log, y_train_log, y_test_log)\n",
    "\n",
    "# (4) Min-Max Scaling 데이터\n",
    "model_minmax = LinearRegression()\n",
    "results[\"Min-Max Scaled\"] = evaluate_model(model_minmax, X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax)\n",
    "\n",
    "# 7. 결과 출력\n",
    "print(\"\\nEvaluation Results (MSE, MAE, RMSE, R2 Score, Explained Variance Score):\")\n",
    "for key, (mse, mae, rmse, r2, evs) in results.items():\n",
    "    print(f\"{key}: MSE = {mse:.2f}, MAE = {mae:.2f}, RMSE = {rmse:.2f}, R2 = {r2:.4f}, EVS = {evs:.4f}\")\n",
    "\n",
    "# 8. 결과 비교 분석\n",
    "best_r2 = max(results[key][3] for key in results)\n",
    "if best_r2 == results[\"Raw\"][3]:\n",
    "    print(\"\\nRaw data provided the best R² score.\")\n",
    "elif best_r2 == results[\"Standard Scaled\"][3]:\n",
    "    print(\"\\nStandard scaling provided the best R² score.\")\n",
    "elif best_r2 == results[\"Log-transformed\"][3]:\n",
    "    print(\"\\nLog transformation provided the best R² score.\")\n",
    "elif best_r2 == results[\"Min-Max Scaled\"][3]:\n",
    "    print(\"\\nMin-Max scaling provided the best R² score.\")\n",
    "else:\n",
    "    print(\"\\nMultiple transformations resulted in the same R² score.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before Feature Engineering: 0.89\n",
      "Accuracy after Feature Engineering: 0.91\n",
      "\n",
      "Feature Engineering improved the model's performance!\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-9] 특성 엔지니어링(Feature Engineering)\n",
    "#############################################################\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 데이터 로드 및 노이즈 추가\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# 노이즈 추가\n",
    "np.random.seed(42)\n",
    "X_noisy = X + np.random.normal(0, 0.5, X.shape)\n",
    "\n",
    "# 2. 특성 엔지니어링 수행 전 평가\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_noisy, y, test_size=0.3, random_state=42)\n",
    "model_raw = LogisticRegression(max_iter=500)\n",
    "model_raw.fit(X_train_raw, y_train)\n",
    "y_pred_raw = model_raw.predict(X_test_raw)\n",
    "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
    "\n",
    "# 3. 특성 엔지니어링 수행: 상호작용 특성 추가\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_fe = pd.DataFrame(poly.fit_transform(X_noisy), columns=poly.get_feature_names_out(X.columns))\n",
    "\n",
    "# 4. 특성 엔지니어링 후 평가\n",
    "X_train_fe, X_test_fe, y_train, y_test = train_test_split(X_fe, y, test_size=0.3, random_state=42)\n",
    "model_fe = LogisticRegression(max_iter=500)\n",
    "model_fe.fit(X_train_fe, y_train)\n",
    "y_pred_fe = model_fe.predict(X_test_fe)\n",
    "accuracy_fe = accuracy_score(y_test, y_pred_fe)\n",
    "\n",
    "# 5. 결과 출력\n",
    "print(f\"Accuracy before Feature Engineering: {accuracy_raw:.2f}\")\n",
    "print(f\"Accuracy after Feature Engineering: {accuracy_fe:.2f}\")\n",
    "\n",
    "if accuracy_fe > accuracy_raw:\n",
    "    print(\"\\nFeature Engineering improved the model's performance!\")\n",
    "elif accuracy_fe == accuracy_raw:\n",
    "    print(\"\\nFeature Engineering did not affect the model's performance.\")\n",
    "else:\n",
    "    print(\"\\nFeature Engineering decreased the model's performance.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "\n",
      "Features after Feature Engineering:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   sepal_length_to_width_ratio  petal_length_to_width_ratio  \\\n",
      "0                     1.457143                          7.0   \n",
      "1                     1.633333                          7.0   \n",
      "2                     1.468750                          6.5   \n",
      "3                     1.483871                          7.5   \n",
      "4                     1.388889                          7.0   \n",
      "\n",
      "   sepal_petal_length_diff  \n",
      "0                      3.7  \n",
      "1                      3.5  \n",
      "2                      3.4  \n",
      "3                      3.1  \n",
      "4                      3.6  \n",
      "\n",
      "Accuracy before Feature Engineering: 1.00\n",
      "Accuracy after Feature Engineering: 1.00\n",
      "Feature Engineering did not affect the model's performance.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [1] 데이터 처리 및 변환\n",
    "# [1-10] 정보 병합(Data Fusion)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [2] 모델 복잡도 및 일반화\n",
    "# [2-1] 과적합 방지 (Overfitting Prevention)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [2] 모델 복잡도 및 일반화\n",
    "# [2-2] 정규화 (L1, L2 Regularization)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [2] 모델 복잡도 및 일반화\n",
    "# [2-3] 드롭아웃 (Dropout)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [2] 모델 복잡도 및 일반화\n",
    "# [2-4] 조기 종료 (Early Stopping)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [2] 모델 복잡도 및 일반화\n",
    "# [2-5] 앙상블 학습 (Ensemble Learning)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package lime not found. Installing...\n",
      "Package scikit-learn not found. Installing...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LimeTabularExplainer.__init__() got an unexpected keyword argument 'training_sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# LIME explainer 생성\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mlime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlime_tabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLimeTabularExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscretize_continuous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 테스트 데이터의 첫 번째 샘플을 선택하여 예측 설명\u001b[39;00m\n\u001b[0;32m     55\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# 첫 번째 샘플\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: LimeTabularExplainer.__init__() got an unexpected keyword argument 'training_sample_weight'"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# [2] 모델 복잡도 및 일반화\n",
    "# [2-6] 모델 해석성(Model Interpretability) : LIME, SHAP\n",
    "#############################################################\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 필요한 패키지가 설치되어 있는지 확인하고, 없으면 설치\n",
    "required_packages = ['lime', 'xgboost', 'scikit-learn', 'matplotlib']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Package {package} not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# 필수 라이브러리 import\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 로드\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# XGBoost 모델 학습\n",
    "model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# LIME explainer 생성\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train_scaled, \n",
    "    training_labels=y_train, \n",
    "    mode=\"classification\", \n",
    "    training_sample_weight=None, \n",
    "    feature_names=data.feature_names, \n",
    "    class_names=data.target_names, \n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# 테스트 데이터의 첫 번째 샘플을 선택하여 예측 설명\n",
    "i = 0  # 첫 번째 샘플\n",
    "explanation = explainer.explain_instance(X_test_scaled[i], model.predict_proba)\n",
    "\n",
    "# 결과 시각화\n",
    "explanation.show_in_notebook(show_table=True, show_all=False)\n",
    "\n",
    "# 특정 샘플에 대한 LIME 해석 그래프 출력\n",
    "explanation.as_pyplot_figure()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [3] 하이퍼파라미터 최적화\n",
    "# [3-1] 하이퍼파라미터 튜닝 (Hyperparameter Tuning)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [3] 하이퍼파라미터 최적화\n",
    "# [3-2] 그리드 서치 (Grid Search)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [3] 하이퍼파라미터 최적화\n",
    "# [3-3] 랜덤 서치 (Random Search)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [3] 하이퍼파라미터 최적화\n",
    "# [3-4] 베이즈 최적화 (Bayesian Optimization)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [3] 하이퍼파라미터 최적화\n",
    "# [3-5] 하이퍼파라미터 탐색 자동화 (Automated Hyperparameter Tuning)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [4] 학습 과정 최적화\n",
    "# [4-1] 학습률 스케줄링 (Learning Rate Scheduling)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [4] 학습 과정 최적화\n",
    "# [4-2] 가중치 초기화 (Weight Initialization)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [4] 학습 과정 최적화\n",
    "# [4-3] 활성화 함수 선택 (Activation Function Selection)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [4] 학습 과정 최적화\n",
    "# [4-4] 전이 학습 (Transfer Learning)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [4] 학습 과정 최적화\n",
    "# [4-5] 모델 구조 최적화 (Model Architecture Optimization)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [4] 학습 과정 최적화\n",
    "# [4-6] 온라인 학습 (Online Learning)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [5] 성능 향상\n",
    "# [5-1] 특성 중요도 분석 및 선택 (Feature Selection)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [5] 성능 향상\n",
    "# [5-2] 손실 함수 커스터마이징 (Custom Loss Function)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# [6] 하드웨어 및 시스템 최적화\n",
    "# [6-1] 하드웨어 최적화 (Hardware Optimization)\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
