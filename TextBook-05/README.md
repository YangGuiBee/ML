#  05 : ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning, UL) : êµ°ì§‘í™”(Clustering)

---

	[1] Partitioning-Based Clustering : ë°ì´í„°ì…‹ì„ ì‚¬ì „ì— ì •ì˜ëœ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¡œ ë¶„í• í•˜ë©°, ê° í´ëŸ¬ìŠ¤í„°ì— ë°ì´í„°ë¥¼ ë°°ì •í•˜ê³  ì´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ë°©ì‹
	[1-1] K-means : ê° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬(centroid)ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„í• 
	[1-2] K-medoids : K-meansì™€ ìœ ì‚¬í•˜ì§€ë§Œ í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ìœ¼ë¡œ í‰ê· ê°’ ëŒ€ì‹  ë°ì´í„° í¬ì¸íŠ¸ ì¤‘ í•˜ë‚˜ë¥¼ ëŒ€í‘œë¡œ ì„ íƒ
	[1-3] K-modes : ë²”ì£¼í˜• ë°ì´í„°ì— íŠ¹í™”ëœ K-means ë³€í˜•
	[1-4] PAM(Partitioning Around Medoids) : K-medoidsì˜ ëŒ€í‘œì ì¸ êµ¬í˜„ìœ¼ë¡œ ê° í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì„ ë°ì´í„°ë¥¼ ëŒ€í‘œí•˜ëŠ” ë°ì´í„° í¬ì¸íŠ¸ë¡œ ì„¤ì •í•˜ê³  ì¤‘ì‹¬ì„ ì´ë™í•˜ë©° í´ëŸ¬ìŠ¤í„°ë§
	[1-5] CLARANS(Clustering Large Applications based on RANdomized Search) : PAMì˜ ê°œì„  ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ëœë¤ ìƒ˜í”Œë§ì„ í†µí•´ í´ëŸ¬ìŠ¤í„°ë§
	[1-6] CLARA(Clustering LARge Applications) : PAMì„ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ì ìš©í•˜ê¸° ìœ„í•´ ìƒ˜í”Œë§ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§
	[1-7] FCM(Fuzzy C-means) : í¼ì§€ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì¤‘ì²© í´ëŸ¬ìŠ¤í„°ì—ì„œ ìœ ì—°í•˜ê²Œ ì ìš©

	[2] Hierarchical-Based Clustering : ë°ì´í„°ì˜ ê³„ì¸µì  êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§
	[2-1] BIRCH(Balanced Iterative Reducing and Clustering using Hierarchies) : ë°ì´í„° ì••ì¶•ì„ í™œìš©. CF(Clustering Feature) íŠ¸ë¦¬ë¼ëŠ” ë°ì´í„° êµ¬ì¡°ë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„°ë§
	[2-2] CURE(Clustering Using Representatives) : ê° í´ëŸ¬ìŠ¤í„°ë¥¼ ì—¬ëŸ¬ ëŒ€í‘œ í¬ì¸íŠ¸ë¡œ ìš”ì•½í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§
	[2-3] ROCK(Robust Clustering using Links) : ë°ì´í„° í¬ì¸íŠ¸ ê°„ì˜ ì—°ê²° ìˆ˜(ë§í¬ ìˆ˜)ë¥¼ ë°”íƒ•ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°
	[2-4] Chameleon : í´ëŸ¬ìŠ¤í„° ê°„ì˜ ë‚´ë¶€ ë° ì™¸ë¶€ ê´€ê³„ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§
 	[2-5] Hierarchical Clustering(Agglomerative / Divisive) : ìƒí–¥ì‹(Agglomerative)ì€ ê° ë°ì´í„° í¬ì¸íŠ¸ì—ì„œ ì‹œì‘í•˜ì—¬ ì ì°¨ í•©ì³ê°€ëŠ” ë°©ì‹, í•˜í–¥ì‹(Divisive)ì€ ì „ì²´ì—ì„œ ì‹œì‘í•˜ì—¬ ì ì°¨ ë¶„í• .
	
	[3] Density-Based Clustering : ë°ì´í„°ì˜ ë°€ë„ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„°ë¥¼ í˜•ì„±
	[3-1] DBSCAN(Density-Based Spatial Clustering of Applications with Noise) : ì£¼ì–´ì§„ ë°˜ê²½ ë‚´ì— íŠ¹ì • ìˆ˜ ì´ìƒì˜ í¬ì¸íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì´ë¥¼ í´ëŸ¬ìŠ¤í„°ì˜ ì¼ë¶€ë¡œ ê°„ì£¼í•˜ì—¬ ì—°ê²°ëœ ê³ ë°€ë„ ì§€ì—­ì„ í´ëŸ¬ìŠ¤í„°ë¡œ í˜•ì„±	
	[3-2] OPTICS(Ordering Points To Identify the Clustering Structure) : DBSCANê³¼ ìœ ì‚¬í•˜ë‚˜, í´ëŸ¬ìŠ¤í„°ì˜ ë°€ë„ê°€ ë³€ë™í•˜ëŠ” ë°ì´í„°ì— ëŒ€í•´ ë” ìœ ì—°í•˜ê²Œ í´ëŸ¬ìŠ¤í„°ë§
	[3-3] DBCLASD(Distribution Based Clustering of Large Spatial Databases) : ê³ ë°€ë„ êµ¬ì—­ì„ ìš°ì„ ì ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§í•˜ëŠ” ë°€ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ëŒ€ê·œëª¨ ê³µê°„ ë°ì´í„°ë² ì´ìŠ¤ì— ì í•©
	[3-4] DENCLUE(DENsity-based CLUstEring) : ë°€ë„ë¥¼ ê°€ìš°ì‹œì•ˆ ì»¤ë„ë¡œ ëª¨ë¸ë§í•˜ì—¬, ë°€ë„ í•¨ìˆ˜ì˜ êµ­ì†Œì  ê·¹ëŒ€ê°’ì„ ì¤‘ì‹¬ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ í˜•ì„±
 	[3-5] Mean-Shift Clustering : ë°ì´í„° ê³µê°„ì—ì„œ ê° í¬ì¸íŠ¸ê°€ ë°ì´í„°ì˜ ë°€ë„ê°€ ë†’ì€ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ì—¬ ìˆ˜ë ´í•  ë•Œê¹Œì§€ ë°˜ë³µí•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§

 	[4] Grid-Based Clustering : ë°ì´í„° ê³µê°„ì„ ê²©ì(grid)ë¡œ ë‚˜ëˆ„ê³  ê° ê²©ìì˜ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ í˜•ì„±
	[4-1] Wave-Cluster : ì›¨ì´ë¸”ë › ë³€í™˜(ì£¼íŒŒìˆ˜ ë¶„ì„ ë„êµ¬ë¡œ, ì‹œê°„ì´ë‚˜ ê³µê°„ì—ì„œ ì‹ í˜¸ì˜ êµ­ì†Œì ì¸ ë³€í™”ë¥¼ í¬ì°©)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ë°€ë„ë¥¼ ì¸¡ì •í•˜ê³ , ê³ ë°€ë„ ì§€ì—­ì„ í´ëŸ¬ìŠ¤í„°ë¡œ ë¶„ë¥˜
	[4-2] STING(Statistical Information Grid-based method) : ë°ì´í„° ê³µê°„ì„ ê³„ì¸µì  ê²©ìë¡œ ë‚˜ëˆ„ê³ , ê° ê²©ìì˜ í†µê³„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°
	[4-3] CLIQUE(CLustering In QUEst) : ë°ì´í„° ê³µê°„ì„ ê²©ìí™”í•˜ê³ , ë°€ë„ê°€ ë†’ì€ ê²©ìë“¤ì„ í´ëŸ¬ìŠ¤í„°
	[4-4] OptiGrid : ë°ì´í„° ë¶„í¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì ì˜ ê²©ìë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§

	[5] Model-Based Clustering : ê° ëª¨ë¸ì€ ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼, EMê³¼ GMMì€ í™•ë¥ ì  ëª¨ë¸ë§, COBWEBê³¼ CLASSITëŠ” ê³„ì¸µì  êµ¬ì¡°, SOMì€ ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›ìœ¼ë¡œ í‘œí˜„í•˜ê±°ë‚˜ ì‹œê°í™”í•  ë•Œ ìœ ìš©
	[5-1] EM(Expectation-Maximization) : ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ ë³€ìˆ˜(í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”)ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ìµœì í™”
	[5-2] COBWEB : íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±
	[5-3] CLASSIT : COBWEBì˜ ë³€í˜•ìœ¼ë¡œ ì—°ì†ì ì¸ ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë° ì´ˆì 
	[5-4] SOMs(Self-Organizing Maps) : ì¸ê³µì‹ ê²½ë§ì˜ ì¼ì¢…ìœ¼ë¡œ ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›ìœ¼ë¡œ í‘œí˜„
 	[5-5] GMM(Gaussian Mixture Model) : ì—¬ëŸ¬ ê°œì˜ ì •ê·œ ë¶„í¬ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ëª¨ë¸ë§í•˜ëŠ” í˜¼í•© ëª¨ë¸(EM ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”)

	[6] Graph-Based Clustering : ê·¸ë˜í”„ ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ìœ ì‚¬ì„±ì„ í™œìš©
	[6-1] Spectral Clustering : ë¹„ì„ í˜• ë°ì´í„°ì˜ ê·¸ë˜í”„ í‘œí˜„ì„ í†µí•´ ë°ì´í„°ì˜ ì—°ê²°ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§
	[6-2] Affinity Propagation : ë°ì´í„° í¬ì¸íŠ¸ ê°„ì˜ "ìœ ì‚¬ë„"ì™€ "ìš°ì„ ë„"ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ì (ëŒ€í‘œ í¬ì¸íŠ¸)ì„ ìë™ìœ¼ë¡œ ì„ íƒ

---  

![](./images/6Cluster.jpg)

https://scikit-learn.org/stable/unsupervised_learning.html
<br>

### êµ°ì§‘í™”(Clustering)ì´ë€?
ë°ì´í„° í¬ì¸íŠ¸ë“¤ì„ ë³„ê°œì˜ êµ°ì§‘ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ëŠ” ê²ƒ<br>
ìœ ì‚¬ì„±ì´ ë†’ì€ ë°ì´í„°ë“¤ì„ ë™ì¼í•œ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ì„œë¡œë‹¤ë¥¸ êµ°ì§‘ë“¤ì´ ìƒì´ì„±ì„ ê°€ì§€ë„ë¡ ê·¸ë£¹í™”<br>
êµ°ì§‘í™” í™œìš©ë¶„ì•¼ : ê³ ê°, ì‹œì¥, ìƒí’ˆ, ê²½ì œ ë° ì‚¬íšŒí™œë™ ë“±ì˜ ì„¸ë¶„í™”(Segmentation) â†’ ì´ë¯¸ì§€ ì‹ë³„, ì´ìƒê²€ì¶œ ë“±<br>

<br>

---

# [1-1] k-Means
â–£ ì •ì˜ : ë°ì´í„°ë¥¼ Kê°œì˜ êµ°ì§‘ìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ì (centroid)ì„ êµ°ì§‘ ë‚´ ë°ì´í„° í¬ì¸íŠ¸ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì •ì˜í•˜ì—¬ ê° ë°ì´í„°ì˜ í¬ì¸íŠ¸ì™€ êµ°ì§‘ ì¤‘ì‹¬ê°„ì˜ ê±°ë¦¬(ìœ í´ë¦¬ë””ì•ˆ ê¸°ì¤€)ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ í• ë‹¹í•˜ëŠ” êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜<br>
â–£ í•„ìš”ì„± : ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•˜ì—¬ ìˆ¨ê²¨ì§„ íŒ¨í„´ì„ ë°œê²¬í•˜ëŠ” ë° ìœ ìš©<br>
â–£ ì¥ì  : êµ¬í˜„ì´ ì‰½ê³  ê°„ë‹¨í•˜ê³  ê³„ì‚°ì†ë„ê°€ ë¹ ë¥´ë©°, ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ì í•©(ì¼ë°˜ì ì¸ êµ°ì§‘í•˜ì—ì„œ ê°€ì¥ë§ì´ í™œìš©)<br>
â–£ ë‹¨ì  : êµ°ì§‘ì˜ ê°œìˆ˜(K)ë¥¼ ì‚¬ì „ì— ì •ì˜í•´ì•¼ í•˜ë©°, êµ¬í˜• êµ°ì§‘ì´ ì•„ë‹ˆê±°ë‚˜ ì´ìƒì¹˜(outliers)ê°€ ìˆì„ ê²½ìš° ì„±ëŠ¥ ì €í•˜(ê±°ë¦¬ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì†ì„±ì˜ ìˆ˜ê°€ ë§ì„ ê²½ìš° êµ°ì§‘ì˜ ì •í™•ë„ê°€ ë–¨ì–´ì§€ëŠ” ë‹¨ì ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ PCAë¡œ ì°¨ì›ì¶•ì†Œ í•„ìš”)<br>
â–£ ì‘ìš©ë¶„ì•¼ : ê³ ê° ì„¸ë¶„í™”, ì´ë¯¸ì§€ ë¶„í• , ì¶”ì²œ ì‹œìŠ¤í…œ<br>
â–£ ëª¨ë¸ì‹ : ğ¾ëŠ” êµ°ì§‘ì˜ ê°œìˆ˜, $ğ¶_ğ‘–$ëŠ” ië²ˆì§¸ êµ°ì§‘, $ğœ‡_ğ‘–$ëŠ” ië²ˆì§¸ êµ°ì§‘ì˜ ì¤‘ì‹¬, ğ‘¥ëŠ” ë°ì´í„° í¬ì¸íŠ¸<br>
![](./images/kmeans.PNG)
<br>ì¶œì²˜ : https://www.saedsayad.com/clustering_kmeans.htm<br>

	from sklearn.cluster import KMeans  # KMeans êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ sklearnì˜ cluster ëª¨ë“ˆì—ì„œ KMeans í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸
	from sklearn.datasets import load_iris  # ì˜ˆì œ ë°ì´í„°ë¡œ iris ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ sklearnì˜ datasets ëª¨ë“ˆì—ì„œ load_iris í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸
	from sklearn.metrics import silhouette_score, accuracy_score  # Silhouette Scoreì™€ Accuracy ê³„ì‚°ì„ ìœ„í•´ ì„í¬íŠ¸
	import matplotlib.pyplot as plt  # ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•´ matplotlibì˜ pyplot ëª¨ë“ˆì„ pltë¡œ ì„í¬íŠ¸
	import numpy as np  # ë°°ì—´ ê³„ì‚°ì„ ìœ„í•´ numpyë¥¼ ì„í¬íŠ¸
	from scipy.stats import mode  # Accuracy ê³„ì‚° ì‹œ êµ°ì§‘ê³¼ ì‹¤ì œ ë¼ë²¨ì„ ë§¤í•‘í•˜ê¸° ìœ„í•´ mode í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸
	
	# ë°ì´í„° ë¡œë“œ
	iris = load_iris()  # load_iris í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ iris ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , ì´ë¥¼ iris ë³€ìˆ˜ì— ì €ì¥
	X = iris.data  # iris ë°ì´í„°ì…‹ì˜ ì†ì„±ê°’(í”¼ì²˜)ë“¤ë§Œ Xì— ì €ì¥(shape: [150, 4])
	true_labels = iris.target  # ì‹¤ì œ ë¼ë²¨ì„ ì €ì¥
	
	# K-Means ì•Œê³ ë¦¬ì¦˜ ì ìš©
	kmeans = KMeans(n_clusters=3, random_state=0)  # KMeans ê°ì²´ë¥¼ ìƒì„±í•˜ê³ , n_clusters=3ìœ¼ë¡œ êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ì„¤ì •
	kmeans.fit(X)  # KMeans ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ X ë°ì´í„°ì…‹ì— ëŒ€í•´ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•˜ê³ , ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ êµ°ì§‘ì„ í•™ìŠµ
	labels = kmeans.labels_  # í•™ìŠµ í›„, ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ì†í•˜ëŠ” êµ°ì§‘ì˜ ë ˆì´ë¸”ì„ labelsì— ì €ì¥
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(X, labels)  # Silhouette Score ê³„ì‚°
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(labels)
	for i in np.unique(labels):
	    mask = (labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™”
	plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=50)  # X[:, 0] ëª¨ë“ í–‰ì˜ ì²«ë²ˆì§¸ ì—´ì„ Xì¢Œí‘œ, X[:, 1] ëª¨ë“ í–‰ì˜ ë‘ë²ˆì§¸ ì—´ì„ Yì¢Œí‘œë¡œ ì‚°ì ë„ ê·¸ë¦¬ê¸°
	plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='X', s=200, label='Centroids')  # êµ°ì§‘ ì¤‘ì‹¬ì„ 'X'ë¡œ í‘œì‹œ
	plt.title("K-Means Clustering on Iris Dataset")  # ê·¸ë˜í”„ì˜ ì œëª©ì„ ì„¤ì •
	plt.xlabel("Feature 1")  # Xì¶• ë ˆì´ë¸”ì„ 'Feature 1'ë¡œ ì„¤ì •
	plt.ylabel("Feature 2")  # Yì¶• ë ˆì´ë¸”ì„ 'Feature 2'ë¡œ ì„¤ì •
	plt.legend()
	plt.show()  # ê·¸ë˜í”„ë¥¼ í™”ë©´ì— ì¶œë ¥


![](./images/kmeans_param.PNG)

![](./images/1-1.PNG)

<br>

## êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ì˜ í‰ê°€ ë°©ë²•(Elbow, Silhouette)
**â–£ Elbow :** êµ°ì§‘ ìˆ˜ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•œ ì‹œê°ì  ë°©ë²•ìœ¼ë¡œ êµ°ì§‘ ìˆ˜ë¥¼ ë³€í™”ì‹œí‚¤ë©´ì„œ ê° êµ°ì§‘ ìˆ˜ì— ë”°ë¥¸ ê´€ì„±(Inertia), ì¦‰ êµ°ì§‘ ë‚´ SSE(Sum of Squared Errors) ë˜ëŠ” WCSS(Within-Cluster Sum of Squares) ê°’ì„ ê³„ì‚°(êµ°ì§‘ì˜ ê°œìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ê° êµ°ì§‘ì´ ë” ì‘ì•„ì§€ê³ , ë°ì´í„° í¬ì¸íŠ¸ë“¤ì´ êµ°ì§‘ ì¤‘ì‹¬ì— ë” ê°€ê¹Œì›Œì§€ê¸° ë•Œë¬¸ì— WCSSì´ ê°ì†Œí•˜ë©°, êµ°ì§‘ ìˆ˜ë¥¼ ê³„ì† ì¦ê°€ì‹œí‚¤ë‹¤ ë³´ë©´, ì–´ëŠ ìˆœê°„ë¶€í„° ì˜¤ì°¨ê°€ í¬ê²Œ ì¤„ì–´ë“¤ì§€ ì•ŠëŠ” êµ¬ê°„ì´ ë‚˜íƒ€ë‚˜ëŠ”ë° ì´ë•Œì˜ êµ°ì§‘ ìˆ˜ë¥¼ ìµœì ì˜ êµ°ì§‘ ìˆ˜ë¡œ ì„ íƒ)<br>

	import matplotlib.pyplot as plt  # ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ matplotlib ë¼ì´ë¸ŒëŸ¬ë¦¬ import
	from sklearn.datasets import load_iris  # iris ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê¸° ìœ„í•œ ëª¨ë“ˆ import
	from sklearn.cluster import KMeans  # KMeans êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ import

	# ë°ì´í„° ë¡œë“œ
	iris = load_iris()  # iris ë°ì´í„°ì…‹ ë¡œë“œ
	data = iris.data  # iris ë°ì´í„°ì…‹ì—ì„œ ì…ë ¥ ë°ì´í„°(features) ì¶”ì¶œ

	# ì—˜ë³´ ê¸°ë²•ì„ ì‚¬ìš©í•œ ìµœì ì˜ êµ°ì§‘ ìˆ˜ ì°¾ê¸°
	wcss = []  # ê° êµ°ì§‘ ìˆ˜ì— ëŒ€í•œ WCSS ê°’ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
	for k in range(1, 5):  # êµ°ì§‘ ìˆ˜ë¥¼ 1ë¶€í„° 10ê¹Œì§€ ë³€ê²½í•˜ë©° ë°˜ë³µ
    	kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)  # kê°œì˜ êµ°ì§‘ì„ ê°€ì§€ëŠ” KMeans ëª¨ë¸ ìƒì„±
    	kmeans.fit(data)  # KMeans ëª¨ë¸ì„ ë°ì´í„°ì— í•™ìŠµì‹œí‚´
    	wcss.append(kmeans.inertia_)  # í•™ìŠµëœ ëª¨ë¸ì˜ ê´€ì„± ê°’(WCSS)ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

	# ê·¸ë˜í”„ ì‹œê°í™”
	plt.plot(range(1, 5), wcss, marker='o')  # êµ°ì§‘ ìˆ˜ì— ë”°ë¥¸ WCSS ê°’ì„ ì„  ê·¸ë˜í”„ë¡œ ì‹œê°í™”
	plt.title('Elbow Method')  # ê·¸ë˜í”„ ì œëª© ì„¤ì •
	plt.xlabel('Number of clusters')  # xì¶• ë ˆì´ë¸” ì„¤ì •
	plt.ylabel('WCSS')  # yì¶• ë ˆì´ë¸” ì„¤ì •
	plt.show()  # ê·¸ë˜í”„ ì¶œë ¥

 ![](./images/elbow.PNG)

	import numpy as np
	import matplotlib.pyplot as plt
	from sklearn.datasets import load_iris
	from sklearn.cluster import KMeans
	from sklearn.metrics import silhouette_score, accuracy_score
	import pandas as pd
	import seaborn as sns
	from scipy.stats import mode

	# ë°ì´í„° ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target

	# K-means í´ëŸ¬ìŠ¤í„°ë§ (êµ°ì§‘ ìˆ˜ë¥¼ 2ë¡œ ì„¤ì •)
	kmeans = KMeans(n_clusters=2, init='k-means++', random_state=42)
	predicted_labels = kmeans.fit_predict(data)

	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")

	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤í•‘í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(2):  # ê° êµ°ì§‘ì— ëŒ€í•´ ë°˜ë³µ
    		mask = (predicted_labels == i)
    		mapped_labels[mask] = mode(true_labels[mask])[0]

	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")

	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ì¶”ê°€
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels  # ì˜ˆì¸¡ëœ êµ°ì§‘ ë ˆì´ë¸” ì¶”ê°€

	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=iris.feature_names[0], y=iris.feature_names[1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("K-means Clustering on Iris Dataset (n_clusters=2)")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/elbow2.PNG)

![](./images/elbow3.PNG)

**â–£ Silhouette :** ê° êµ°ì§‘ ê°„ì˜ ê±°ë¦¬ê°€ ì–¼ë§ˆë‚˜ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ì‘ì§‘ë ¥ìˆê²Œ êµ°ì§‘í™”ë˜ì—ˆëŠ”ì§€ë¥¼ í‰ê°€í•˜ëŠ” ì§€í‘œ. ê° ë°ì´í„° í¬ì¸íŠ¸ì— ëŒ€í•´ ì‹¤ë£¨ì—£ ê³„ìˆ˜(Silhouette Coefficient)ë¥¼ ê³„ì‚°í•˜ë©°, ì´ ê°’ì€ ë°ì´í„° í¬ì¸íŠ¸ê°€ ìì‹ ì˜ êµ°ì§‘ì— ì–¼ë§ˆë‚˜ ì˜ ì†í•´ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„<br>

	import matplotlib.pyplot as plt
	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import KMeans
	from sklearn.metrics import silhouette_score, accuracy_score
	from scipy.stats import mode

	# ë°ì´í„° ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target

	# ì‹¤ë£¨ì—£ ë¶„ì„ ë° ì •í™•ë„ë¥¼ í†µí•œ ìµœì ì˜ êµ°ì§‘ ìˆ˜ ì°¾ê¸°
	silhouette_scores = []
	accuracies = []

	for k in range(2, 11):  # êµ°ì§‘ ìˆ˜ëŠ” ìµœì†Œ 2ê°œ ì´ìƒì´ì–´ì•¼ ì‹¤ë£¨ì—£ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŒ
		kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)
		predicted_labels = kmeans.fit_predict(data)
    
    		# Silhouette Score ê³„ì‚°
    		silhouette = silhouette_score(data, predicted_labels)
    		silhouette_scores.append(silhouette)
    
    		# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤í•‘í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
    		mapped_labels = np.zeros_like(predicted_labels)
    		for i in range(k):
			mask = (predicted_labels == i)
			mapped_labels[mask] = mode(true_labels[mask])[0]
    
    		accuracy = accuracy_score(true_labels, mapped_labels)
    		accuracies.append(accuracy)

	# ì‹¤ë£¨ì—£ ì ìˆ˜ ê·¸ë˜í”„ ì‹œê°í™”
	plt.figure(figsize=(12, 5))

	plt.subplot(1, 2, 1)
	plt.plot(range(2, 11), silhouette_scores, marker='o')
	plt.title('Silhouette Analysis')
	plt.xlabel('Number of clusters')
	plt.ylabel('Silhouette Score')

	# ì •í™•ë„ ê·¸ë˜í”„ ì‹œê°í™”
	plt.subplot(1, 2, 2)
	plt.plot(range(2, 11), accuracies, marker='o', color='orange')
	plt.title('Accuracy by Number of Clusters')
	plt.xlabel('Number of clusters')
	plt.ylabel('Accuracy')
	plt.tight_layout()
	plt.show()

![](./images/silhouette.PNG)
<br>

# [1-2] K-medoids
â–£ ì •ì˜: K-meansì™€ ìœ ì‚¬í•˜ì§€ë§Œ, ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ì„ êµ°ì§‘ë‚´ ê°€ì¥ ì¤‘ì•™ì— ìœ„ì¹˜í•œ ì‹¤ì œ ë°ì´í„° í¬ì¸íŠ¸(medoid)ë¡œ ì„¤ì •í•¨ìœ¼ë¡œì¨ ì´ìƒì¹˜(outlier)ì— ë” ê°•í•˜ë‹¤.<br>
â–£ í•„ìš”ì„±: ì´ìƒì¹˜ê°€ ë§ì€ ë°ì´í„°ë‚˜ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ë°ì´í„°ì—ì„œ K-meansì˜ ë‹¨ì ì„ ë³´ì™„í•˜ì—¬ ì•ˆì •ì ì¸ êµ°ì§‘í™”ë¥¼ ì œê³µ<br>
â–£ ì¥ì : K-meansì— ë¹„í•´ ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•˜ê³ , êµ°ì§‘ ì¤‘ì‹¬ì´ ì‹¤ì œ ë°ì´í„° í¬ì¸íŠ¸ì´ê¸° ë•Œë¬¸ì— í•´ì„ì´ ìš©ì´<br>
â–£ ë‹¨ì : ê³„ì‚°(ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ë¿ ì•„ë‹ˆë¼ ë§¨í—ˆíŠ¼ ê±°ë¦¬, ë¯¼ì½”í”„ìŠ¤í‚¤ ê±°ë¦¬ ë“± ì‚¬ìš©ê°€ëŠ¥)ì— ë”°ë¼ ë³µì¡í•˜ê³  ëŠë¦´ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë©°, ë¹„êµ¬í˜• êµ°ì§‘ì„ ì˜ ë¶„ë¥˜í•˜ì§€ ëª»í•¨<br>
â–£ ì‘ìš©ë¶„ì•¼: ì˜ë£Œ ë°ì´í„° ë¶„ì„, ë²”ì£¼í˜• ë°ì´í„°ê°€ í¬í•¨ëœ ê³ ê° ì„¸ë¶„í™”<br>
â–£ ëª¨ë¸ì‹: K-medoidsëŠ” ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ìœ¼ë¡œ ê°€ì¥ ëŒ€í‘œì ì¸ í¬ì¸íŠ¸(medoid)ë¥¼ ì„ íƒí•˜ì—¬ êµ°ì§‘ ë‚´ ë°ì´í„°ì™€ì˜ ì´ ë¹„ìœ ì‚¬ë„ë¥¼ ìµœì†Œí™”<br>
![](./images/k-medoids.png)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	from scipy.spatial.distance import cdist
	import pandas as pd
	import matplotlib.pyplot as plt
	import seaborn as sns
	from scipy.stats import mode
	
	class KMedoids:
	    def __init__(self, n_clusters=3, max_iter=300, random_state=None):
	        self.n_clusters = n_clusters
	        self.max_iter = max_iter
	        self.random_state = random_state
	
	    def fit_predict(self, X):
	        if self.random_state:
	            np.random.seed(self.random_state)
	
	        # 1. ì´ˆê¸° ë©”ë„ì´ë“œë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒ
	        medoids = np.random.choice(len(X), self.n_clusters, replace=False)
	
	        for _ in range(self.max_iter):
	            # ê° ë°ì´í„° í¬ì¸íŠ¸ì™€ ë©”ë„ì´ë“œ ê°„ ê±°ë¦¬ ê³„ì‚°
	            distances = cdist(X, X[medoids], metric='euclidean')
	            labels = np.argmin(distances, axis=1)
	
	            # ìƒˆë¡œìš´ ë©”ë„ì´ë“œ ê³„ì‚°
	            new_medoids = np.copy(medoids)
	            for i in range(self.n_clusters):
	                cluster_points = np.where(labels == i)[0]
	                intra_cluster_distances = cdist(X[cluster_points], X[cluster_points], metric='euclidean').sum(axis=1)
	                new_medoids[i] = cluster_points[np.argmin(intra_cluster_distances)]
	
	            # ë©”ë„ì´ë“œê°€ ë³€í•˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œ
	            if np.array_equal(medoids, new_medoids):
	                break
	            medoids = new_medoids
	
	        self.labels_ = labels
	        self.medoids_ = X[medoids]
	        return self.labels_
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# KMedoids ì•Œê³ ë¦¬ì¦˜ ì ìš©
	kmedoids = KMedoids(n_clusters=3, random_state=0)
	clusters = kmedoids.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = clusters  # êµ°ì§‘í™” ê²°ê³¼ ì¶”ê°€
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, clusters)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(clusters)
	for i in np.unique(clusters):
	    mask = (clusters == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™”
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.scatter(kmedoids.medoids_[:, 0], kmedoids.medoids_[:, 1], c='red', marker='X', s=200, label='Medoids')
	plt.title("K-medoids Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # Xì¶•: ì²« ë²ˆì§¸ íŠ¹ì§•
	plt.ylabel(iris.feature_names[1])  # Yì¶•: ë‘ ë²ˆì§¸ íŠ¹ì§•
	plt.legend(title='Cluster')
	plt.show()

![](./images/1-2.PNG)
<br>

# [1-3] K-modes
â–£ ì •ì˜: ë²”ì£¼í˜• ë°ì´í„°ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ì€ ìµœë¹ˆê°’(mode)ìœ¼ë¡œ ê²°ì •<br>
â–£ í•„ìš”ì„±: ë²”ì£¼í˜• ë°ì´í„°ë¥¼ êµ°ì§‘í™”í•˜ëŠ” ë° ìœ ìš©í•˜ë©°, ì¼ë°˜ì ì¸ K-meansì™€ëŠ” ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì´ í•„ìš”<br>
â–£ ì¥ì : ë²”ì£¼í˜• ë°ì´í„°ì— íŠ¹í™”ë˜ì–´ ìˆìœ¼ë©°, K-meansì™€ ìœ ì‚¬í•˜ê²Œ ë¹ ë¥´ê²Œ ê³„ì‚°<br>
â–£ ë‹¨ì : ë²”ì£¼í˜•ì´ ì•„ë‹Œ ìˆ˜ì¹˜í˜• ë°ì´í„°ì—ëŠ” ë¶€ì í•©í•˜ë©°, K ê°’ì„ ì‚¬ì „ì— ì„¤ì •í•´ì•¼ í•¨<br>
â–£ ì‘ìš©ë¶„ì•¼: ì„¤ë¬¸ ë°ì´í„° ë¶„ì„, ê³ ê° ì„¸ë¶„í™”ì—ì„œ ë²”ì£¼í˜• íŠ¹ì„±ì„ í¬í•¨í•œ êµ°ì§‘í™”<br>
â–£ ëª¨ë¸ì‹: ë²”ì£¼í˜• ë°ì´í„°ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´ í—´ë° ê±°ë¦¬(Hamming distance)ë¥¼ ì‚¬ìš©(êµ°ì§‘ì˜ ì¤‘ì‹¬ì€ ê° ì†ì„±ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ì„¤ì •)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	import pandas as pd
	import matplotlib.pyplot as plt
	import seaborn as sns
	from scipy.stats import mode
	
	class SimpleKModes:
	    def __init__(self, n_clusters=3, max_iter=100, random_state=None):
	        self.n_clusters = n_clusters
	        self.max_iter = max_iter
	        self.random_state = random_state
	
	    def fit_predict(self, X):
	        if self.random_state:
	            np.random.seed(self.random_state)
	        
	        # ì´ˆê¸° í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì„ ë¬´ì‘ìœ„ë¡œ ì„ íƒ
	        centers = X.sample(n=self.n_clusters, random_state=self.random_state).to_numpy()
	        
	        for _ in range(self.max_iter):
	            # ê° ë°ì´í„° í¬ì¸íŠ¸ì™€ ì¤‘ì‹¬ ê°„ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” í•­ëª© ìˆ˜ë¡œ ê±°ë¦¬ ê³„ì‚°
	            distances = np.array([[np.sum(x != center) for center in centers] for x in X.to_numpy()])
	            labels = np.argmin(distances, axis=1)
	            
	            # ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´ ìƒˆë¡œìš´ ì¤‘ì‹¬ ê³„ì‚°
	            new_centers = np.array([
	                X[labels == i].mode().iloc[0].to_numpy() if len(X[labels == i]) > 0 else centers[i]
	                for i in range(self.n_clusters)
	            ])
	            
	            # ì¤‘ì‹¬ì´ ë³€í•˜ì§€ ì•Šìœ¼ë©´ ìˆ˜ë ´
	            if np.array_equal(centers, new_centers):
	                break
	            centers = new_centers
	
	        self.labels_ = labels
	        self.centers_ = centers
	        return labels
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = pd.DataFrame(iris.data, columns=iris.feature_names)
	true_labels = iris.target
	
	# ë°ì´í„°ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜ (Low, Medium, High)
	data_cat = data.apply(lambda x: pd.cut(x, bins=3, labels=["Low", "Medium", "High"]))
	
	# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ì¸ì½”ë”©
	data_encoded = data_cat.apply(lambda x: x.cat.codes)
	
	# Simple K-Modes í´ëŸ¬ìŠ¤í„°ë§ ì ìš©
	simple_kmodes = SimpleKModes(n_clusters=3, max_iter=100, random_state=0)
	clusters = simple_kmodes.fit_predict(data_encoded)
	
	# êµ°ì§‘í™” ê²°ê³¼ ì¶”ê°€
	data["Cluster"] = clusters  # ì›ë³¸ ë°ì´í„°ì— êµ°ì§‘í™” ê²°ê³¼ë¥¼ ì¶”ê°€
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data_encoded, clusters)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(clusters)
	for i in np.unique(clusters):
	    mask = (clusters == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue="Cluster", data=data, palette="viridis", s=100)
	plt.title("Simple K-Modes Clustering on Iris Dataset (First 2 Features)")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title="Cluster")
	plt.show()

![](./images/1-3.PNG)
<br>

# [1-4] PAM(Partitioning Around Medoids)
â–£ ì •ì˜: K-medoids ì ‘ê·¼ë²•ì„ êµ¬í˜„í•˜ëŠ” íƒìš•ì  ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê° êµ°ì§‘ì—ì„œ ê°€ì¥ ìµœì ì˜ Medoidë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì°¾ëŠ”ë‹¤<br>
â–£ í•„ìš”ì„±: ì´ìƒì¹˜ê°€ ë§ì€ ë°ì´í„°ì…‹ì—ì„œë„ ì•ˆì •ì ì¸ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ<br>
â–£ ì¥ì : K-meansì— ë¹„í•´ ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•˜ë©° ë‹¤ì–‘í•œ ê±°ë¦¬ ì¸¡ì • ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ<br>
â–£ ë‹¨ì : ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ê³„ì‚° ë¹„ìš©ì´ ë†’ê³  êµ°ì§‘ ìˆ˜(K)ë¥¼ ì‚¬ì „ì— ì§€ì •í•´ì•¼ í•¨<br>
â–£ ì‘ìš©ë¶„ì•¼: ë²”ì£¼í˜• ë°ì´í„°ë¥¼ í¬í•¨í•œ ê³ ê° ì„¸ë¶„í™”, ì˜ë£Œ ë°ì´í„° ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: PAMì€ ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ìœ¼ë¡œ ê°€ì¥ ëŒ€í‘œì ì¸ medoidë¥¼ ì„ íƒí•˜ì—¬ êµ°ì§‘ ë‚´ ë¹„ìœ ì‚¬ë„ë¥¼ ìµœì†Œí™”<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	from scipy.spatial.distance import cdist
	import pandas as pd
	import matplotlib.pyplot as plt
	import seaborn as sns
	from scipy.stats import mode
	
	class PAM:
	    def __init__(self, n_clusters=3, max_iter=300, random_state=None):
	        self.n_clusters = n_clusters
	        self.max_iter = max_iter
	        self.random_state = random_state
	
	    def fit_predict(self, X):
	        if self.random_state:
	            np.random.seed(self.random_state)
	        
	        # 1. ì´ˆê¸° ë©”ë„ì´ë“œ ì„ íƒ (ëœë¤ ìƒ˜í”Œë§)
	        medoids = np.random.choice(len(X), self.n_clusters, replace=False)
	        
	        for _ in range(self.max_iter):
	            # ê° í¬ì¸íŠ¸ì™€ ëª¨ë“  ë©”ë„ì´ë“œ ê°„ ê±°ë¦¬ ê³„ì‚°
	            distances = cdist(X, X[medoids], metric='euclidean')
	            labels = np.argmin(distances, axis=1)
	            
	            # ìƒˆë¡œìš´ ë©”ë„ì´ë“œ ê³„ì‚°
	            new_medoids = np.copy(medoids)
	            for i in range(self.n_clusters):
	                # í˜„ì¬ êµ°ì§‘ì— ì†í•œ ë°ì´í„° í¬ì¸íŠ¸ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
	                cluster_points = np.where(labels == i)[0]
	                
	                # êµ°ì§‘ ë‚´ ë°ì´í„° í¬ì¸íŠ¸ ê°„ ê±°ë¦¬ì˜ ì´í•©ì´ ìµœì†Œê°€ ë˜ëŠ” í¬ì¸íŠ¸ë¥¼ ë©”ë„ì´ë“œë¡œ ì„¤ì •
	                intra_cluster_distances = cdist(X[cluster_points], X[cluster_points], metric='euclidean').sum(axis=1)
	                new_medoids[i] = cluster_points[np.argmin(intra_cluster_distances)]
	            
	            # ë©”ë„ì´ë“œê°€ ë³€í™”ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
	            if np.array_equal(medoids, new_medoids):
	                break
	            medoids = new_medoids
	        
	        self.labels_ = labels
	        self.medoids_ = medoids
	        return self.labels_
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = pd.DataFrame(iris.data, columns=iris.feature_names)
	true_labels = iris.target
	
	# PAM ì•Œê³ ë¦¬ì¦˜ ì ìš© (êµ°ì§‘ ìˆ˜: 3)
	pam = PAM(n_clusters=3, random_state=0)
	clusters = pam.fit_predict(iris.data)  # ë°ì´í„°ì— ë§ì¶° êµ°ì§‘í™” ìˆ˜í–‰
	
	# êµ°ì§‘í™” ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
	data['Cluster'] = clusters  # ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ êµ°ì§‘ ë ˆì´ë¸” ì¶”ê°€
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(iris.data, clusters)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(clusters)
	for i in np.unique(clusters):
	    mask = (clusters == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue='Cluster', data=data, palette='viridis', s=100)
	plt.scatter(iris.data[pam.medoids_, 0], iris.data[pam.medoids_, 1], c='red', marker='X', s=200, label='Medoids')
	plt.title("PAM (Partitioning Around Medoids) Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()
	
![](./images/1-4.PNG)
<br>

# [1-5] CLARANS(Clustering Large Applications based on RANdomized Search)
â–£ ì •ì˜: PAM(PAMê³¼ K-medoids)ì˜ í™•ì¥íŒìœ¼ë¡œ, ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— íš¨ìœ¨ì ì¸ êµ°ì§‘í™”ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ëœë¤í™”ëœ íƒìƒ‰ ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜. PAMì˜ ì „ì²´ ë°ì´í„°ì…‹ íƒìƒ‰ ë°©ì‹ ëŒ€ì‹  ìƒ˜í”Œë§ê³¼ ëœë¤ ì„ íƒì„ í†µí•´ ìµœì ì˜ medoidë¥¼ ì°¾ëŠ”ë‹¤<br>
â–£ í•„ìš”ì„±: PAMì˜ ëŠë¦° ì„±ëŠ¥ì„ ë³´ì™„í•˜ì—¬ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œë„ ë¹ ë¥´ê²Œ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„<br>
â–£ ì¥ì : ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ì ìš©í•  ìˆ˜ ìˆìœ¼ë©°, PAMë³´ë‹¤ í›¨ì”¬ íš¨ìœ¨ì ì´ë©°, ëœë¤ íƒìƒ‰ ë°©ì‹ì„ í†µí•´ ìµœì ì˜ medoidë¥¼ ë¹ ë¥´ê²Œ ê²€ìƒ‰<br>
â–£ ë‹¨ì : ëœë¤í™”ëœ íƒìƒ‰ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì‹¤í–‰ ê²°ê³¼ê°€ ë§¤ë²ˆ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë©°, PAMê³¼ ë™ì¼í•˜ê²Œ êµ°ì§‘ ìˆ˜(K)ë¥¼ ì‚¬ì „ì— ì§€ì •í•´ì•¼ í•¨<br>
â–£ ì‘ìš©ë¶„ì•¼: ëŒ€ê·œëª¨ ê³ ê° ì„¸ë¶„í™”, ê¸ˆìœµ ë°ì´í„° ë¶„ì„, ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë° ë¬¸ì„œ ë¶„ë¥˜<br>
â–£ ëª¨ë¸ì‹: ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ì¼ë¶€ë¥¼ ëœë¤í•˜ê²Œ ìƒ˜í”Œë§í•˜ì—¬ ìµœì ì˜ medoidë¥¼ ì°¾ëŠ” ë°©ì‹ìœ¼ë¡œ, ê¸°ì¡´ PAMì˜ ê°œë…ì„ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ë§ê²Œ í™•ì¥. ì´ë¥¼ í†µí•´ ë°ì´í„° íƒìƒ‰ ê³¼ì •ì„ ì¤„ì´ê³  íš¨ìœ¨ì„±ì„ ê°•í™”<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	from scipy.spatial.distance import cdist
	import pandas as pd
	import matplotlib.pyplot as plt
	import seaborn as sns
	from scipy.stats import mode
	
	class CLARANS:
	    def __init__(self, n_clusters=3, numlocal=5, maxneighbor=10, random_state=None):
	        self.n_clusters = n_clusters
	        self.numlocal = numlocal  # ëœë¤ ì´ˆê¸°í™” ë°˜ë³µ íšŸìˆ˜
	        self.maxneighbor = maxneighbor  # ê° ì´ˆê¸°í™” ë‹¹ ëœë¤ íƒìƒ‰ ì´ì›ƒ ìˆ˜
	        self.random_state = random_state
	
	    def fit_predict(self, X):
	        if self.random_state:
	            np.random.seed(self.random_state)
	        
	        best_medoids = None
	        best_score = float('inf')
	        labels = None
	
	        # numlocalë²ˆì˜ ëœë¤ ì´ˆê¸°í™” ë°˜ë³µ
	        for _ in range(self.numlocal):
	            # ì´ˆê¸° ë©”ë„ì´ë“œ ëœë¤ ì„ íƒ
	            medoids = np.random.choice(len(X), self.n_clusters, replace=False)
	            current_score = self._calculate_total_cost(X, medoids)
	
	            improved = True
	            while improved:
	                improved = False
	                # maxneighbor ë²ˆ ë§Œí¼ ëœë¤ìœ¼ë¡œ ì´ì›ƒ íƒìƒ‰
	                for _ in range(self.maxneighbor):
	                    # í˜„ì¬ ë©”ë„ì´ë“œ ì¤‘ í•˜ë‚˜ì™€ ë¹„ë©”ë„ì´ë“œ ì¤‘ í•˜ë‚˜ë¥¼ êµí™˜
	                    new_medoids = np.copy(medoids)
	                    non_medoids = [i for i in range(len(X)) if i not in medoids]
	                    new_medoids[np.random.randint(0, self.n_clusters)] = np.random.choice(non_medoids)
	                    
	                    # ìƒˆë¡œìš´ ë©”ë„ì´ë“œ ì…‹ìœ¼ë¡œ ë¹„ìš© ê³„ì‚°
	                    new_score = self._calculate_total_cost(X, new_medoids)
	                    if new_score < current_score:
	                        medoids = new_medoids
	                        current_score = new_score
	                        improved = True
	                        break
	            
	            # ìµœì ì˜ ë©”ë„ì´ë“œ ì…‹ ì—…ë°ì´íŠ¸
	            if current_score < best_score:
	                best_medoids = medoids
	                best_score = current_score
	                labels = np.argmin(cdist(X, X[best_medoids]), axis=1)
	
	        self.medoids_ = best_medoids
	        self.labels_ = labels
	        return self.labels_
	
	    def _calculate_total_cost(self, X, medoids):
	        # ë©”ë„ì´ë“œ ì…‹ì— ëŒ€í•œ ì´ ë¹„ìš©(ê±°ë¦¬ í•©ê³„) ê³„ì‚°
	        distances = cdist(X, X[medoids], metric='euclidean')
	        return np.sum(np.min(distances, axis=1))
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = pd.DataFrame(iris.data, columns=iris.feature_names)
	true_labels = iris.target
	
	# CLARANS ì•Œê³ ë¦¬ì¦˜ ì ìš© (êµ°ì§‘ ìˆ˜: 3)
	clarans = CLARANS(n_clusters=3, numlocal=5, maxneighbor=10, random_state=0)
	clusters = clarans.fit_predict(iris.data)  # ë°ì´í„°ì— ë§ì¶° êµ°ì§‘í™” ìˆ˜í–‰
	
	# êµ°ì§‘í™” ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
	data['Cluster'] = clusters  # ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ êµ°ì§‘ ë ˆì´ë¸” ì¶”ê°€
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(iris.data, clusters)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(clusters)
	for i in np.unique(clusters):
	    mask = (clusters == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue='Cluster', data=data, palette='viridis', s=100)
	plt.scatter(iris.data[clarans.medoids_, 0], iris.data[clarans.medoids_, 1], c='red', marker='X', s=200, label='Medoids')
	plt.title("CLARANS Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/1-5.PNG)
<br>

# [1-6] CLARA(Clustering LARge Applications)
â–£ ì •ì˜: PAMì„ ëŒ€ê·œëª¨ ë°ì´í„°ì— ì ìš©í•  ìˆ˜ ìˆë„ë¡ í™•ì¥í•œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ë°ì´í„°ì˜ ì¼ë¶€ ìƒ˜í”Œì„ ì‚¬ìš©í•˜ì—¬ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°, ì—¬ëŸ¬ ë²ˆì˜ ìƒ˜í”Œë§ì„ í†µí•´ ê°€ì¥ ì•ˆì •ì ì¸ medoidë¥¼ ì„ íƒ<br>
â–£ í•„ìš”ì„±: PAMì˜ ë†’ì€ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ê³ ì ê°œë°œë˜ì–´ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œë„ ë¹ ë¥´ê²Œ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰<br>
â–£ ì¥ì : PAMë³´ë‹¤ ê³„ì‚°ì´ íš¨ìœ¨ì ì´ë©°, ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ì í•©í•˜ë©°, í‘œë³¸ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ ë©”ëª¨ë¦¬ì™€ ì‹œê°„ íš¨ìœ¨ì <br>
â–£ ë‹¨ì : ìƒ˜í”Œë§ì„ í†µí•´ ê²°ê³¼ì˜ ì‹ ë¢°ë„ê°€ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìœ¼ë©°, ì „ì²´ ë°ì´í„°ì…‹ì„ ë°˜ì˜í•˜ì§€ ëª»í•  ê°€ëŠ¥ì„±. êµ°ì§‘ ìˆ˜(K)ë¥¼ ì‚¬ì „ì— ì§€ì •í•´ì•¼ í•¨<br>
â–£ ì‘ìš©ë¶„ì•¼: ëŒ€ê·œëª¨ ê³ ê° ë°ì´í„°ì˜ êµ°ì§‘í™”, ìƒë¬¼í•™ì  ë°ì´í„° ë¶„ì„, ì‹œì¥ ì¡°ì‚¬ ë°ì´í„°ì˜ ë¶„ì„ ë° êµ°ì§‘í™”<br>
â–£ ëª¨ë¸ì‹: ë°ì´í„°ì…‹ì—ì„œ ì¼ë¶€ ìƒ˜í”Œì„ ì„ íƒí•˜ì—¬ PAMì„ ì ìš©í•˜ê³ , ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ ìˆ˜í–‰í•˜ì—¬ ìµœì ì˜ medoidë¥¼ ì°¾ëŠ”ë‹¤<br>

	import numpy as np	
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	from scipy.spatial.distance import cdist
	import pandas as pd
	import matplotlib.pyplot as plt
	import seaborn as sns
	from scipy.stats import mode
	
	class CLARA:
	    def __init__(self, n_clusters=3, n_samples=25, numlocal=5, max_iter=300, random_state=None):
	        self.n_clusters = n_clusters
	        self.n_samples = n_samples  # ê° ìƒ˜í”Œì˜ í¬ê¸°
	        self.numlocal = numlocal    # PAM ë°˜ë³µ íšŸìˆ˜
	        self.max_iter = max_iter    # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
	        self.random_state = random_state
	
	    def fit_predict(self, X):
	        if self.random_state:
	            np.random.seed(self.random_state)
	
	        best_medoids = None
	        best_score = float('inf')
	        best_labels = None
	
	        # numlocal ë²ˆì˜ ìƒ˜í”Œë§ ë°˜ë³µ
	        for _ in range(self.numlocal):
	            # ë°ì´í„°ì—ì„œ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§
	            sample_indices = np.random.choice(len(X), self.n_samples, replace=False)
	            sample = X[sample_indices]
	
	            # PAMì„ ìƒ˜í”Œì— ì ìš©í•˜ì—¬ ìµœì ì˜ ë©”ë„ì´ë“œ ì°¾ê¸°
	            medoids = self._initialize_medoids(sample)
	            for _ in range(self.max_iter):
	                distances = cdist(sample, sample[medoids], metric='euclidean')
	                labels = np.argmin(distances, axis=1)
	                
	                new_medoids = np.copy(medoids)
	                for i in range(self.n_clusters):
	                    cluster_points = np.where(labels == i)[0]
	                    intra_cluster_distances = cdist(sample[cluster_points], sample[cluster_points], metric='euclidean').sum(axis=1)
	                    new_medoids[i] = cluster_points[np.argmin(intra_cluster_distances)]
	
	                if np.array_equal(medoids, new_medoids):
	                    break
	                medoids = new_medoids
	
	            # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ë¹„ìš© ê³„ì‚°
	            full_distances = cdist(X, sample[medoids], metric='euclidean')
	            full_score = np.sum(np.min(full_distances, axis=1))
	
	            # ë” ë‚˜ì€ ë©”ë„ì´ë“œ ì…‹ì´ ë°œê²¬ë˜ë©´ ê°±ì‹ 
	            if full_score < best_score:
	                best_medoids = medoids
	                best_score = full_score
	                best_labels = np.argmin(full_distances, axis=1)
	
	        self.medoids_ = sample[best_medoids]  # ìµœì ì˜ ë©”ë„ì´ë“œë¥¼ ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ì¸ë±ì‹±
	        self.labels_ = best_labels
	        return self.labels_
	
	    def _initialize_medoids(self, X):
	        return np.random.choice(len(X), self.n_clusters, replace=False)
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = pd.DataFrame(iris.data, columns=iris.feature_names)
	true_labels = iris.target
	
	# CLARA ì•Œê³ ë¦¬ì¦˜ ì ìš© (êµ°ì§‘ ìˆ˜: 3)
	clara = CLARA(n_clusters=3, n_samples=30, numlocal=5, max_iter=300, random_state=0)
	clusters = clara.fit_predict(iris.data)  # ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ êµ°ì§‘í™” ìˆ˜í–‰
	
	# êµ°ì§‘í™” ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
	data['Cluster'] = clusters  # ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ êµ°ì§‘ ë ˆì´ë¸” ì¶”ê°€
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(iris.data, clusters)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(clusters)
	for i in np.unique(clusters):
	    mask = (clusters == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue='Cluster', data=data, palette='viridis', s=100)
	plt.scatter(clara.medoids_[:, 0], clara.medoids_[:, 1], c='red', marker='X', s=200, label='Medoids')
	plt.title("CLARA Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()
	
![](./images/1-6.PNG)
<br>

# [1-7] FCM(Fuzzy C-means) 
â–£ ì •ì˜: ì†Œí”„íŠ¸ êµ°ì§‘í™” ë°©ë²•ìœ¼ë¡œ ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ì—¬ëŸ¬ êµ°ì§‘ì— ì†í•  ìˆ˜ ìˆìœ¼ë©°, êµ°ì§‘ ì†Œì† í™•ë¥ ì„ ê³„ì‚°í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±. ë°ì´í„°ê°€ ëª…í™•í•˜ê²Œ êµ¬ë¶„ë˜ì§€ ì•Šì„ ë•Œ ìœ ìš©<br>
â–£ í•„ìš”ì„±: ë°ì´í„°ê°€ ëª…í™•íˆ êµ¬ë¶„ë˜ì§€ ì•ŠëŠ” ê²½ìš°, ê° ë°ì´í„°ê°€ ì—¬ëŸ¬ êµ°ì§‘ì— ì†Œì†ë  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•˜ì—¬ ë”ìš± ìœ ì—°í•œ êµ°ì§‘í™”ë¥¼ ì œê³µ<br>
â–£ ì¥ì : ë°ì´í„°ë¥¼ ì—¬ëŸ¬ êµ°ì§‘ì— ê±¸ì³ ì†Œì†ì‹œí‚¬ ìˆ˜ ìˆì–´ ìœ ì—°í•œ êµ°ì§‘í™”ê°€ ê°€ëŠ¥í•˜ë©° êµ°ì§‘ ê²½ê³„ê°€ ëª¨í˜¸í•œ ë°ì´í„°ì— ì í•©<br>
â–£ ë‹¨ì : ì´ìƒì¹˜ì— ë¯¼ê°í•˜ê³  ì´ˆê¸° ì¤‘ì‹¬ ì„¤ì •ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©°, êµ°ì§‘ ê°œìˆ˜ì™€ í¼ì§€ ì§€ìˆ˜(m)ë¥¼ ë¯¸ë¦¬ ì„¤ì •í•´ì•¼ í•¨<br>
â–£ ì‘ìš©ë¶„ì•¼: ì´ë¯¸ì§€ ë¶„í•  ë° íŒ¨í„´ ì¸ì‹, ìƒë¬¼í•™ì—ì„œ ìœ ì „ì ë°ì´í„° êµ°ì§‘í™”, ê³ ê° ì„¸ë¶„í™”ì™€ ê°™ì€ ë§ˆì¼€íŒ… ë¶„ì•¼<br>
â–£ ëª¨ë¸ì‹: ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ êµ°ì§‘ì— ì†í•  í™•ë¥ (ì†Œì†ë„, membership value)ì„ ê³„ì‚°í•˜ì—¬ êµ°ì§‘í™”í•¨. ì´ë•Œ ê° êµ°ì§‘ì˜ ì¤‘ì‹¬ê³¼ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ì˜ ê±°ë¦¬ì˜ ì—­ìˆ˜ì— ë”°ë¼ ì†Œì†ë„ê°€ ê²°ì •ë˜ë©°, ëª©ì  í•¨ìˆ˜ë¥¼ ìµœì†Œí™” í•¨. ì—¬ê¸°ì„œ $ğ‘¢_{ğ‘–ğ‘—}$ëŠ” ë°ì´í„° í¬ì¸íŠ¸ $ğ‘¥_ğ‘–$ê°€ êµ°ì§‘ $ğ‘_ğ‘—$ì— ì†í•  í™•ë¥ ì´ë©°, ğ‘šì€ í¼ì§€ ì§€ìˆ˜ë¡œ, êµ°ì§‘ì˜ ê²½ê³„ë¥¼ ì¡°ì •í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰<br>
![](./images/FCM.png)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	import pandas as pd
	import matplotlib.pyplot as plt
	import seaborn as sns
	from scipy.stats import mode
	
	class FCM:
	    def __init__(self, n_clusters=3, m=2.0, max_iter=300, error=1e-5, random_state=None):
	        self.n_clusters = n_clusters
	        self.m = m
	        self.max_iter = max_iter
	        self.error = error
	        self.random_state = random_state
	
	    def initialize_membership(self, n_samples):
	        if self.random_state:
	            np.random.seed(self.random_state)
	        U = np.random.rand(n_samples, self.n_clusters)
	        U = U / np.sum(U, axis=1, keepdims=True)
	        return U
	
	    def update_centers(self, X, U):
	        um = U ** self.m
	        return (um.T @ X) / np.sum(um.T, axis=1, keepdims=True)
	
	    def update_membership(self, X, centers):
	        dist = np.linalg.norm(X[:, np.newaxis] - centers, axis=2)
	        dist = np.fmax(dist, np.finfo(np.float64).eps)
	        inv_dist = dist ** (- 2 / (self.m - 1))
	        return inv_dist / np.sum(inv_dist, axis=1, keepdims=True)
	
	    def fit(self, X):
	        n_samples = X.shape[0]
	        U = self.initialize_membership(n_samples)
	
	        for _ in range(self.max_iter):
	            U_old = U.copy()
	            centers = self.update_centers(X, U)
	            U = self.update_membership(X, centers)
	            if np.linalg.norm(U - U_old) < self.error:
	                break
	
	        self.centers = centers
	        self.u = U
	        self.labels_ = np.argmax(U, axis=1)
	        return self
	
	    def predict(self, X):
	        return np.argmax(self.update_membership(X, self.centers), axis=1)
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# FCM ì•Œê³ ë¦¬ì¦˜ ì ìš©
	fcm = FCM(n_clusters=3, m=2.0, max_iter=300, random_state=0)
	fcm.fit(data)
	
	# ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ êµ°ì§‘ ì†Œì†ë„ (ë©¤ë²„ì‹­) ë° êµ°ì§‘ ë ˆì´ë¸” ì˜ˆì¸¡
	fcm_labels = fcm.labels_
	membership_matrix = fcm.u
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = fcm_labels
	df['Membership 1'] = membership_matrix[:, 0]
	df['Membership 2'] = membership_matrix[:, 1]
	df['Membership 3'] = membership_matrix[:, 2]
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, fcm_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(fcm_labels)
	for i in np.unique(fcm_labels):
	    mask = (fcm_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.scatter(fcm.centers[:, 0], fcm.centers[:, 1], c='red', marker='X', s=200, label='Centers')
	plt.title("Fuzzy C-means (FCM) Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()
                                                                          
![](./images/1-7.PNG)
<br>

---

# [2-1] BIRCH(Balanced Iterative Reducing and Clustering using Hierarchies)
â–£ ì •ì˜: ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ êµ°ì§‘í™”í•  ìˆ˜ ìˆëŠ” ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰. BIRCHëŠ” ë°ì´í„°ë¥¼ í´ëŸ¬ìŠ¤í„°ë§ í”¼ì²˜(Clustering Feature, CF) íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ìœ ì§€í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ êµ°ì§‘ì„ í˜•ì„±<br>
â–£ í•„ìš”ì„±: ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ êµ°ì§‘í™”í•  ìˆ˜ ìˆìœ¼ë©°, ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ê³„ì¸µì  êµ°ì§‘í™”ê°€ í•„ìš”í•  ë•Œ ìœ ìš©<br>
â–£ ì¥ì : ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ë©´ì„œ ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©° ë‹¤ë¥¸ ê³„ì¸µì  ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ì†ë„ê°€ ë¹ ë¥´ë©°, ë°ì´í„°ë¥¼ ì••ì¶•í•˜ì—¬ êµ°ì§‘í™” ê³¼ì •ì„ ë‹¨ìˆœí™”í•  ìˆ˜ ìˆìŒ<br>
â–£ ë‹¨ì : êµ°ì§‘ì˜ ë°€ë„ê°€ ê³ ë¥´ê²Œ ë¶„í¬ëœ ê²½ìš°ì— ë” ì˜ ì‘ë™í•˜ë©°, ë°€ë„ê°€ ë¶ˆê· ì¼í•œ ê²½ìš° ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìœ¼ë©°, ì´ˆê¸° ë§¤ê°œë³€ìˆ˜ ì„¤ì •ì— ë”°ë¼ ì„±ëŠ¥ì´ í¬ê²Œ ì˜í–¥ì„ ë°›ì„ ìˆ˜ ìˆìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼: ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë°ì´í„° êµ°ì§‘í™”, ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ë¶„ì„, ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ êµ°ì§‘í™”<br>
â–£ ëª¨ë¸ì‹: í´ëŸ¬ìŠ¤í„°ë§ í”¼ì²˜(CF)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ê³  ê³„ì¸µì ìœ¼ë¡œ êµ°ì§‘í™”(ì—¬ê¸°ì„œ  ğ‘ì€ í´ëŸ¬ìŠ¤í„°ì˜ ë°ì´í„° í¬ì¸íŠ¸ ê°œìˆ˜, ğ¿ğ‘†ëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ í•©ê³„, ğ‘†ğ‘†ëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ ì œê³± í•©ê³„ì´ë©°, ì´ë¥¼ í†µí•´ ê° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ê³¼ ë¶„ì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°)<br>
ğ¶ğ¹ = (ğ‘,ğ¿ğ‘†,ğ‘†ğ‘†)

	from sklearn.datasets import load_iris
	from sklearn.cluster import Birch
	import pandas as pd
	import matplotlib.pyplot as plt
	import seaborn as sns
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	
	# BIRCH ì•Œê³ ë¦¬ì¦˜ ì ìš© (êµ°ì§‘ ìˆ˜: 3)
	birch = Birch(n_clusters=3, threshold=0.5, branching_factor=50)
	birch.fit(data)
	labels = birch.predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = labels  # ê° í¬ì¸íŠ¸ì˜ êµ°ì§‘ ë¼ë²¨
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("BIRCH Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/2-1.PNG)
<br>

# [2-2] CURE(Clustering Using Representatives)
â–£ ì •ì˜: êµ°ì§‘ì„ í˜•ì„±í•  ë•Œ ê° êµ°ì§‘ì˜ ëŒ€í‘œ í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ì–‘ê³¼ í¬ê¸°ì˜ êµ°ì§‘ì„ ì˜ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ ê³„ì¸µì  êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜. êµ°ì§‘ì˜ ëŒ€í‘œ í¬ì¸íŠ¸ë“¤ì€ êµ°ì§‘ ë‚´ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì§„ ì—¬ëŸ¬ ìœ„ì¹˜ì— ë°°ì¹˜ë˜ì–´ ì „ì²´ êµ°ì§‘ì˜ ë¶„í¬ë¥¼ ë‚˜íƒ€ëƒ„<br>
â–£ í•„ìš”ì„±: êµ°ì§‘ì˜ í˜•íƒœë‚˜ í¬ê¸°ê°€ ë‹¤ì–‘í•œ ë°ì´í„°ì—ì„œ êµ°ì§‘ì„ ë³´ë‹¤ ì •í™•í•˜ê²Œ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ì§€ì›<br>
â–£ ì¥ì : ë‹¤ì–‘í•œ í˜•íƒœì™€ í¬ê¸°ì˜ êµ°ì§‘ì„ íš¨ê³¼ì ìœ¼ë¡œ íƒì§€í•  ìˆ˜ ìˆìœ¼ë©°, ë…¸ì´ì¦ˆì— ê°•í•˜ê³  ì´ìƒì¹˜ì˜ ì˜í–¥ì„ ì ê²Œ ë°›ìŒ<br>
â–£ ë‹¨ì : ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” ê³„ì‚° ë¹„ìš©ì´ ë†’ê³ , êµ°ì§‘ ë‚´ ëŒ€í‘œ í¬ì¸íŠ¸ì˜ ê°œìˆ˜ì™€ ì¶•ì†Œ ë¹„ìœ¨ ë“±ì˜ ë§¤ê°œë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”<br>
â–£ ì‘ìš©ë¶„ì•¼: ì§€ë¦¬ì  ë°ì´í„° ë¶„ì„, ëŒ€ê·œëª¨ ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ì—ì„œ ì»¤ë®¤ë‹ˆí‹° íƒìƒ‰, ìœ ì „ì ë°ì´í„°ì˜ êµ°ì§‘í™”<br>
â–£ ëª¨ë¸ì‹: ê° êµ°ì§‘ì˜ ëŒ€í‘œ í¬ì¸íŠ¸ë¥¼ ì§€ì •í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ë¥¸ êµ°ì§‘ê³¼ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±. êµ°ì§‘ ë‚´ì˜ ëŒ€í‘œ í¬ì¸íŠ¸ë“¤ì€ êµ°ì§‘ ì¤‘ì‹¬ì—ì„œ ì¼ì • ë¹„ìœ¨ë¡œ ì¶•ì†Œë˜ë©°, ì—¬ëŸ¬ ê°œì˜ ëŒ€í‘œ í¬ì¸íŠ¸ë¥¼ í†µí•´ êµ°ì§‘ì˜ ë¶„í¬ë¥¼ í‘œí˜„<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import AgglomerativeClustering
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.spatial.distance import cdist
	from scipy.stats import mode
	
	# ê°„ë‹¨í•œ CURE ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
	class CURE:
	    def __init__(self, n_clusters=3, n_representatives=5, shrink_factor=0.5):
	        self.n_clusters = n_clusters
	        self.n_representatives = n_representatives
	        self.shrink_factor = shrink_factor
	        self.labels_ = None
	    
	    def fit_predict(self, X):
	        # ì´ˆê¸° êµ°ì§‘ ì„¤ì • (ê° í¬ì¸íŠ¸ê°€ í•˜ë‚˜ì˜ êµ°ì§‘)
	        n_samples = X.shape[0]
	        clusters = [[i] for i in range(n_samples)]
	        cluster_centers = [X[i] for i in range(n_samples)]
	        
	        # ê³„ì¸µì  êµ°ì§‘í™” ê³¼ì •
	        while len(clusters) > self.n_clusters:
	            # ê° êµ°ì§‘ì—ì„œ ëŒ€í‘œ í¬ì¸íŠ¸ ìƒ˜í”Œë§
	            representative_points = [self._get_representatives(X[cluster]) for cluster in clusters]
	            
	            # êµ°ì§‘ ê°„ ìµœì†Œ ê±°ë¦¬ ê³„ì‚°
	            distances = cdist(np.vstack(representative_points), np.vstack(representative_points), metric='euclidean')
	            np.fill_diagonal(distances, np.inf)
	            min_idx = np.unravel_index(np.argmin(distances), distances.shape)
	            cluster_a, cluster_b = min_idx[0] // self.n_representatives, min_idx[1] // self.n_representatives
	            
	            # êµ°ì§‘ ë³‘í•©
	            clusters[cluster_a].extend(clusters[cluster_b])
	            clusters.pop(cluster_b)
	            
	            # ë³‘í•©ëœ êµ°ì§‘ì˜ ì¤‘ì‹¬ ì—…ë°ì´íŠ¸
	            new_representative = self._get_representatives(X[clusters[cluster_a]])
	            cluster_centers[cluster_a] = new_representative
	            cluster_centers.pop(cluster_b)
	        
	        # ìµœì¢… êµ°ì§‘ ë ˆì´ë¸” ìƒì„±
	        self.labels_ = np.empty(n_samples, dtype=int)
	        for cluster_id, cluster in enumerate(clusters):
	            for index in cluster:
	                self.labels_[index] = cluster_id
	                
	        return self.labels_
	    
	    def _get_representatives(self, cluster_points):
	        # êµ°ì§‘ì—ì„œ ëŒ€í‘œ í¬ì¸íŠ¸ë¥¼ ìƒ˜í”Œë§í•˜ê³  ì¶•ì†Œ
	        center = np.mean(cluster_points, axis=0)
	        distances = cdist(cluster_points, [center], metric='euclidean').flatten()
	        representative_indices = np.argsort(distances)[:self.n_representatives]
	        representatives = cluster_points[representative_indices]
	        return center + self.shrink_factor * (representatives - center)
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# CURE ì•Œê³ ë¦¬ì¦˜ ì ìš©
	cure = CURE(n_clusters=3, n_representatives=5, shrink_factor=0.5)
	predicted_labels = cure.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("CURE Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()
 
![](./images/2-2.PNG)
<br>

# [2-3] ROCK(Robust Clustering using Links)
â–£ ì •ì˜: ë²”ì£¼í˜• ë°ì´í„°ì—ì„œ ìœ ì‚¬í•œ í•­ëª©ì„ êµ°ì§‘í™”í•˜ëŠ” ë° ìµœì í™”ëœ ê³„ì¸µì  êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê° ë°ì´í„° í¬ì¸íŠ¸ ê°„ì˜ ì—°ê²°(link)ì„ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘ì˜ ë°€ë„ë¥¼ ì¸¡ì •í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±<br>
â–£ í•„ìš”ì„±: ë²”ì£¼í˜• ë°ì´í„°ì™€ ê°™ì´ ëª…í™•í•œ ê±°ë¦¬ ê³„ì‚°ì´ ì–´ë ¤ìš´ ê²½ìš°, ë°ì´í„° ê°„ì˜ ì—°ê²° ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë° ìœ ìš©<br>
â–£ ì¥ì : ë²”ì£¼í˜• ë°ì´í„°ì— íŠ¹í™”ë˜ì–´ ìˆì–´, ë²”ì£¼í˜• íŠ¹ì„±ì„ ì˜ ë°˜ì˜í•œ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•˜ê³  ë°€ë„ê°€ ë†’ì€ êµ°ì§‘ì„ ì˜ íƒì§€í•  ìˆ˜ ìˆìŒ<br>
â–£ ë‹¨ì : ê³„ì‚° ë¹„ìš©ì´ ë†’ì•„ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ëŠ” ì í•©í•˜ì§€ ì•Šìœ¼ë©°, ê±°ë¦¬ ê³„ì‚°ë³´ë‹¤ ì—°ê²° ê¸°ë°˜ êµ°ì§‘í™”ê°€ ë³µì¡<br>
â–£ ì‘ìš©ë¶„ì•¼: ì¶”ì²œ ì‹œìŠ¤í…œ, ë¬¸ì„œ ë¶„ë¥˜ ë° í…ìŠ¤íŠ¸ ë§ˆì´ë‹, ë²”ì£¼í˜• ì†ì„±ì´ ë§ì€ ë°ì´í„°ì˜ êµ°ì§‘í™”<br>
â–£ ëª¨ë¸ì‹: ë°ì´í„° í¬ì¸íŠ¸ ê°„ì˜ ì—°ê²°ì„ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘ì„ í˜•ì„±í•˜ë©°, ì—°ê²°ì˜ ê°œìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘ ê°„ì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ì—¬ êµ°ì§‘í™”<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.neighbors import kneighbors_graph
	from sklearn.cluster import AgglomerativeClustering
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# 1ë‹¨ê³„: K-ìµœê·¼ì ‘ ì´ì›ƒ ê·¸ë˜í”„ ìƒì„± (ìœ ì‚¬ë„ ë§í¬ ê¸°ë°˜ ìƒì„±)
	n_neighbors = 10
	knn_graph = kneighbors_graph(data, n_neighbors=n_neighbors, mode='connectivity', include_self=False)
	
	# 2ë‹¨ê³„: Agglomerative Clusteringì„ í†µí•´ ìœ ì‚¬ë„ ë§í¬ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘í™”
	rock_clustering = AgglomerativeClustering(n_clusters=3, connectivity=knn_graph, linkage='average')
	predicted_labels = rock_clustering.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("ROCK Clustering (Approximation) on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/2-3.PNG)
<br>

# [2-4] Chameleon
â–£ ì •ì˜: ë°ì´í„°ì˜ ì§€ì—­ì  ë°€ë„ì™€ ëª¨ì–‘ì„ ê³ ë ¤í•˜ì—¬ ìœ ì‚¬ì„±ì„ ê³„ì‚°í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ê³„ì¸µì  êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ°ì§‘ì„ ë‚˜ëˆ„ëŠ” ì´ˆê¸° ë¶„í• ê³¼ ë™ì  ë³‘í•© ë‹¨ê³„ ë“± 2ë‹¨ê³„ë¡œ êµ¬ì„±<br>
â–£ í•„ìš”ì„±: ë‹¤ì–‘í•œ ëª¨ì–‘ê³¼ ë°€ë„ì˜ êµ°ì§‘ì´ ìˆëŠ” ë°ì´í„°ì—ì„œ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•  ë•Œ ìœ ìš©<br>
â–£ ì¥ì : êµ°ì§‘ì˜ ë°€ë„ì™€ ëª¨ì–‘ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ì–‘í•œ êµ°ì§‘ êµ¬ì¡°ë¥¼ ì˜ íƒì§€í•  ìˆ˜ ìˆìœ¼ë©° ë‹¤ë¥¸ ê³„ì¸µì  êµ°ì§‘í™”ë³´ë‹¤ ìœ ì—°í•œ êµ°ì§‘í™”ë¥¼ ì œê³µ<br>
â–£ ë‹¨ì : ê³„ì‚° ë¹„ìš©ì´ ë§¤ìš° ë†’ìœ¼ë©°, ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œëŠ” ì‹¤í–‰ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìœ¼ë©° ì´ˆê¸° í´ëŸ¬ìŠ¤í„°ë§ê³¼ ë³‘í•© ê¸°ì¤€ì„ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì–´ë µë‹¤<br>
â–£ ì‘ìš©ë¶„ì•¼: ì†Œì…œ ë„¤íŠ¸ì›Œí¬ì—ì„œ ì»¤ë®¤ë‹ˆí‹° íƒìƒ‰, ë¹„ì •í˜• ë°ì´í„° ë¶„ì„, ì›¹ ë¬¸ì„œ ë¶„ë¥˜<br>
â–£ ëª¨ë¸ì‹: ë‘ ë‹¨ê³„ë¡œ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ”ë° ì²«ì§¸, ë°ì´í„°ë¥¼ ì‘ì€ ì´ˆê¸° êµ°ì§‘ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ë‘˜ì§¸, ìœ ì‚¬í•œ êµ°ì§‘ì„ ë™ì ìœ¼ë¡œ ë³‘í•©í•˜ì—¬ ìµœì¢… êµ°ì§‘ì„ í˜•ì„±<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.neighbors import kneighbors_graph
	from sklearn.cluster import AgglomerativeClustering, DBSCAN
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# 1ë‹¨ê³„: K-ìµœê·¼ì ‘ ì´ì›ƒ ê·¸ë˜í”„ ìƒì„±
	n_neighbors = 10
	knn_graph = kneighbors_graph(data, n_neighbors=n_neighbors, include_self=False)
	
	# 2ë‹¨ê³„: ì´ˆê¸° êµ°ì§‘í™” - ê·¸ë˜í”„ ê¸°ë°˜ì˜ ê³„ì¸µì  êµ°ì§‘í™” ìˆ˜í–‰
	initial_clustering = AgglomerativeClustering(n_clusters=10, connectivity=knn_graph, linkage='average')
	initial_labels = initial_clustering.fit_predict(data)
	
	# 3ë‹¨ê³„: êµ°ì§‘ ë³‘í•© - DBSCANì„ ì‚¬ìš©í•˜ì—¬ ì‘ì€ êµ°ì§‘ì„ ë°€ë„ ê¸°ë°˜ìœ¼ë¡œ ë³‘í•©
	# AgglomerativeClusteringìœ¼ë¡œ ìƒì„±ëœ ì´ˆê¸° êµ°ì§‘ë“¤ì„ DBSCANìœ¼ë¡œ ë‹¤ì‹œ ë³‘í•©
	data_with_initial_labels = pd.DataFrame(data)
	data_with_initial_labels['initial_cluster'] = initial_labels
	
	# ê° ì´ˆê¸° êµ°ì§‘ì„ DBSCANì„ í†µí•´ ë³‘í•©
	dbscan = DBSCAN(eps=0.5, min_samples=5)
	final_labels = dbscan.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = final_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = final_labels != -1  # ë…¸ì´ì¦ˆê°€ ì•„ë‹Œ í¬ì¸íŠ¸ë§Œ ì„ íƒ
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], final_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(final_labels)
	for i in np.unique(final_labels):
	    mask = (final_labels == i)
	    if np.any(mask):  # êµ°ì§‘ì— ì†í•˜ëŠ” í¬ì¸íŠ¸ê°€ ìˆì„ ë•Œë§Œ ê³„ì‚°
	        mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels[valid_points], mapped_labels[valid_points])
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Chameleon Clustering (Approximation) on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/2-4.PNG)
<br>

# [2-5] Hierarchical Clustering(Agglomerative / Divisive)
â–£ ì •ì˜ : ë°ì´í„°ë¥¼ ë³‘í•©(bottom-up)í•˜ê±°ë‚˜ ë¶„í• (top-down)í•˜ì—¬ ê³„ì¸µì ì¸ êµ°ì§‘ êµ¬ì¡°ë¥¼ ë§Œë“œëŠ” ë°©ë²•<br>
â–£ í•„ìš”ì„± : êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ì‚¬ì „ì— ì •í•  í•„ìš” ì—†ì´ ê³„ì¸µì  ê´€ê³„ë¥¼ íŒŒì•…í•  ë•Œ ì‚¬ìš©<br>
â–£ ì¥ì  : êµ°ì§‘ ìˆ˜ë¥¼ ë¯¸ë¦¬ ì •í•  í•„ìš” ì—†ìœ¼ë©°, ë´ë“œë¡œê·¸ë¨(dendrogram)ì„ í†µí•œ êµ°ì§‘ ë¶„ì„ ê°€ëŠ¥<br>
â–£ ë‹¨ì  : ê³„ì‚° ë³µì¡ë„ê°€ ë†’ìœ¼ë©°, ì´ˆê¸° ë³‘í•© ë˜ëŠ” ë¶„í•  ê²°ì •ì´ ìµœì¢… ê²°ê³¼ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼ : ê³„í†µìˆ˜ ë¶„ì„, í…ìŠ¤íŠ¸ ë° ë¬¸ì„œ ë¶„ë¥˜<br> 
â–£ ëª¨ë¸ì‹ : $ğ¶_ğ‘–$ì™€ $ğ¶_ğ‘—$ëŠ” ê°ê° ë‘ êµ°ì§‘ì´ê³ , ğ‘‘(ğ‘¥,ğ‘¦)ëŠ” ë‘ ë°ì´í„° í¬ì¸íŠ¸ ğ‘¥ì™€ ğ‘¦ ê°„ì˜ ê±°ë¦¬<br>
![](./images/Hclustering.PNG)

	#(Agglomerative)
	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import KMeans
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Divisive Clustering í•¨ìˆ˜
	def divisive_clustering(data, num_clusters):
	    clusters = {0: data}  # ì´ˆê¸° ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ í° êµ°ì§‘ìœ¼ë¡œ ì„¤ì •
	    current_cluster_id = 0
	    
	    while len(clusters) < num_clusters:
	        # ê°€ì¥ í° êµ°ì§‘ ì„ íƒ
	        largest_cluster_id = max(clusters, key=lambda k: len(clusters[k]))
	        largest_cluster_data = clusters[largest_cluster_id]
	        
	        # í•´ë‹¹ êµ°ì§‘ì„ ë‘ ê°œë¡œ ë¶„í• 
	        kmeans = KMeans(n_clusters=2, random_state=0).fit(largest_cluster_data)
	        labels = kmeans.labels_
	        
	        # ìƒˆë¡œìš´ êµ°ì§‘ì— ë°ì´í„° í• ë‹¹
	        new_cluster_id = max(clusters.keys()) + 1
	        clusters[largest_cluster_id] = largest_cluster_data[labels == 0]
	        clusters[new_cluster_id] = largest_cluster_data[labels == 1]
	        
	        # í´ëŸ¬ìŠ¤í„° ID ì¦ê°€
	        current_cluster_id += 1
	    
	    # ìµœì¢… êµ°ì§‘ ë ˆì´ë¸” ìƒì„±
	    predicted_labels = np.zeros(data.shape[0], dtype=int)
	    for cluster_id, cluster_data in clusters.items():
	        for idx in range(data.shape[0]):
	            if data[idx] in cluster_data:
	                predicted_labels[idx] = cluster_id
	                
	    return predicted_labels
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# Divisive Clustering ì‹¤í–‰
	num_clusters = 3
	predicted_labels = divisive_clustering(data, num_clusters)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(num_clusters):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Divisive Hierarchical Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/2-51.PNG)

	#(Divisive)
 	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import KMeans
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Divisive Clustering í•¨ìˆ˜
	def divisive_clustering(data, num_clusters):
	    clusters = {0: data}  # ì´ˆê¸° ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ í° êµ°ì§‘ìœ¼ë¡œ ì„¤ì •
	    current_cluster_id = 0
	    
	    while len(clusters) < num_clusters:
	        # ê°€ì¥ í° êµ°ì§‘ ì„ íƒ
	        largest_cluster_id = max(clusters, key=lambda k: len(clusters[k]))
	        largest_cluster_data = clusters[largest_cluster_id]
	        
	        # í•´ë‹¹ êµ°ì§‘ì„ ë‘ ê°œë¡œ ë¶„í• 
	        kmeans = KMeans(n_clusters=2, random_state=0).fit(largest_cluster_data)
	        labels = kmeans.labels_
	        
	        # ìƒˆë¡œìš´ êµ°ì§‘ì— ë°ì´í„° í• ë‹¹
	        new_cluster_id = max(clusters.keys()) + 1
	        clusters[largest_cluster_id] = largest_cluster_data[labels == 0]
	        clusters[new_cluster_id] = largest_cluster_data[labels == 1]
	        
	        # í´ëŸ¬ìŠ¤í„° ID ì¦ê°€
	        current_cluster_id += 1
	    
	    # ìµœì¢… êµ°ì§‘ ë ˆì´ë¸” ìƒì„±
	    predicted_labels = np.zeros(data.shape[0], dtype=int)
	    for cluster_id, cluster_data in clusters.items():
	        for idx in range(data.shape[0]):
	            if data[idx] in cluster_data:
	                predicted_labels[idx] = cluster_id
	                
	    return predicted_labels
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# Divisive Clustering ì‹¤í–‰
	num_clusters = 3
	predicted_labels = divisive_clustering(data, num_clusters)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(num_clusters):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Divisive Hierarchical Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/2-52.PNG)
<br>

â–£ ë´ë“œë¡œê·¸ë¨(dendrogram) : ë‚˜ë¬´(tree) ëª¨ì–‘ì˜ ë„ì‹ìœ¼ë¡œ, ê³„ì¸µì  êµ°ì§‘í™”ì˜ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. ì´ ê·¸ë˜í”„ëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ë³‘í•©ë˜ê±°ë‚˜ ë¶„í• ë˜ëŠ” ê³¼ì •ì„ ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œí˜„í•˜ë©°, êµ°ì§‘ ê°„ì˜ ê´€ê³„ë¥¼ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤€ë‹¤.<br> 
ë´ë“œë¡œê·¸ë¨ì˜ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:<br>
(1) ê° ë°ì´í„° í¬ì¸íŠ¸ëŠ” ë§¨ ì•„ë˜ì—ì„œ ê°œë³„ ë…¸ë“œë¡œ ì‹œì‘ : ë´ë“œë¡œê·¸ë¨ì—ì„œ ê° ë°ì´í„° í¬ì¸íŠ¸ëŠ” ë§¨ ì•„ë˜ì— ìœ„ì¹˜í•œ ê°œë³„ ë…¸ë“œë¡œ ì‹œì‘. ì´ ë‹¨ê³„ì—ì„œëŠ” ê°ê°ì˜ ë°ì´í„°ê°€ í•˜ë‚˜ì˜ êµ°ì§‘ì„ ì´ë£¨ê³  ìˆë‹¤.<br>
(2) ë°ì´í„° í¬ì¸íŠ¸ë“¤ì´ ë³‘í•© : ê³„ì¸µì  êµ°ì§‘í™”ì˜ ê³¼ì •ì—ì„œ ìœ ì‚¬í•œ ë°ì´í„° í¬ì¸íŠ¸ë¼ë¦¬ ìˆœì°¨ì ìœ¼ë¡œ ë³‘í•©ë˜ë©°, ë³‘í•©ë˜ëŠ” ê³¼ì •ì´ ë´ë“œë¡œê·¸ë¨ì—ì„œ ìƒìœ„ë¡œ ì˜¬ë¼ê°€ë©´ì„œ ë‘ ë…¸ë“œê°€ ì—°ê²°ë˜ëŠ” í˜•íƒœë¡œ ì‹œê°í™” ëœë‹¤.<br>
(3) ë³‘í•©ëœ êµ°ì§‘ì´ ë‹¤ì‹œ ë‹¤ë¥¸ êµ°ì§‘ê³¼ ë³‘í•© : ìœ ì‚¬í•œ êµ°ì§‘ë¼ë¦¬ ê³„ì† ë³‘í•©ë˜ë©° ì ì  ë” í° êµ°ì§‘ì„ í˜•ì„±í•˜ê²Œ ëœë‹¤. ë´ë“œë¡œê·¸ë¨ì˜ ìƒë‹¨ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ë” í° êµ°ì§‘ì´ ë³‘í•©ëœ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê²°êµ­ ëª¨ë“  ë°ì´í„°ê°€ í•˜ë‚˜ì˜ êµ°ì§‘ìœ¼ë¡œ ë³‘í•©ëœë‹¤.<br>
(4) êµ°ì§‘ ê°„ì˜ ê±°ë¦¬ ì •ë³´: ë´ë“œë¡œê·¸ë¨ì—ì„œ ë‘ êµ°ì§‘ì´ ë³‘í•©ëœ ë†’ì´(ìˆ˜ì§ ì¶•)ëŠ” ê·¸ ë‘ êµ°ì§‘ ì‚¬ì´ì˜ ìœ ì‚¬ë„ ë˜ëŠ” ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ì¦‰, ë³‘í•©ëœ ë†’ì´ê°€ í´ìˆ˜ë¡ ë‘ êµ°ì§‘ ê°„ì˜ ê±°ë¦¬ê°€ ë” ë©€ì—ˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ë°ì´í„°ë¥¼ ë‚˜ëˆ„ê±°ë‚˜ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ ê¸°ì¤€ì´ ëœë‹¤.<br>
ë´ë“œë¡œê·¸ë¨ì˜ ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:<br>
(1) êµ°ì§‘ì˜ ê°œìˆ˜ ì„ íƒì´ ìœ ì—° : ë´ë“œë¡œê·¸ë¨ì„ í†µí•´ ë°ì´í„°ê°€ ì–´ë–»ê²Œ êµ°ì§‘í™”ë˜ì—ˆëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•œ í›„, ì„ì˜ì˜ ë†’ì´ì—ì„œ ì„ ì„ ê·¸ì–´ êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë‹¤. íŠ¹ì • ë†’ì´ì—ì„œ ë´ë“œë¡œê·¸ë¨ì„ ìë¥´ë©´ ê·¸ ë†’ì´ ê¸°ì¤€ìœ¼ë¡œ ëª‡ ê°œì˜ êµ°ì§‘ì´ í˜•ì„±ë˜ëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ìˆìœ¼ë©° ì´ë¡œ ì¸í•´ êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ ê²°ì •í•˜ì§€ ì•Šê³ ë„ êµ°ì§‘ì„ í˜•ì„±í•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë´ë“œë¡œê·¸ë¨ì—ì„œ ê° êµ°ì§‘ ê°„ì˜ ìœ ì‚¬ë„ê°€ ë†’ì§€ ì•Šë‹¤ê³  íŒë‹¨ë˜ëŠ” ì§€ì ì—ì„œ ì˜ë¼ë‚´ë©´ ë‹¤ìˆ˜ì˜ ì‘ì€ êµ°ì§‘ì´ ë§Œë“¤ì–´ì§ˆ ìˆ˜ ìˆê³ , ë°˜ëŒ€ë¡œ ìœ ì‚¬ë„ê°€ ë†’ë‹¤ê³  íŒë‹¨ë˜ëŠ” ì§€ì ì—ì„œ ìë¥´ë©´ ì†Œìˆ˜ì˜ í° êµ°ì§‘ì´ í˜•ì„±ë  ìˆ˜ ìˆë‹¤.<br>
(2) êµ°ì§‘ ê°„ì˜ ìœ ì‚¬ë„ ë° ê³„ì¸µ êµ¬ì¡° íŒŒì•… : ë´ë“œë¡œê·¸ë¨ì€ ë‹¨ìˆœíˆ êµ°ì§‘ì„ ë‚˜ëˆ„ëŠ” ê²ƒ ì´ìƒìœ¼ë¡œ êµ°ì§‘ ê°„ì˜ ìœ ì‚¬ë„ì™€ ê³„ì¸µì  ê´€ê³„ë¥¼ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤€ë‹¤. ì´ë¥¼ í†µí•´ ë‘ êµ°ì§‘ì´ ë³‘í•©ë˜ëŠ” ì‹œì ê³¼ ê·¸ êµ°ì§‘ë“¤ì´ ë‹¤ë¥¸ êµ°ì§‘ë“¤ê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ íŒŒì•…í•˜ê³  ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ°ì§‘í™” ê²°ê³¼ë¥¼ ë”ìš± ìƒì„¸í•˜ê²Œ í•´ì„í•  ìˆ˜ ìˆë‹¤.<br>
(3) ë‹¤ì–‘í•œ ìˆ˜ì¤€ì—ì„œ êµ°ì§‘ ë¶„ì„ ê°€ëŠ¥ : ë´ë“œë¡œê·¸ë¨ì„ í™œìš©í•˜ë©´ ë°ì´í„°ì…‹ì„ ë‹¤ì–‘í•œ ìˆ˜ì¤€ì—ì„œ ë¶„ì„í•  ìˆ˜ ìˆë‹¤. íŠ¹ì • ë†’ì´ì—ì„œ êµ°ì§‘ì„ ì˜ë¼ë‚´ë©´ ë” í° êµ°ì§‘ì„ í˜•ì„±í•  ìˆ˜ ìˆê³ , ë” ë‚®ì€ ë†’ì´ì—ì„œëŠ” ì„¸ë¶€ì ì¸ êµ°ì§‘ì„ ì‹ë³„í•¨ìœ¼ë¡œì¨ ë‹¤ë‹¨ê³„ êµ°ì§‘ ë¶„ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.<br>
(4) êµ°ì§‘ì˜ êµ¬ì¡°ì  ê´€ê³„ ì‹œê°í™” : ë´ë“œë¡œê·¸ë¨ì„ í†µí•´ ë°ì´í„°ë¥¼ ê³„ì¸µì ìœ¼ë¡œ êµ°ì§‘í™”í•œ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•¨ìœ¼ë¡œì¨ ë°ì´í„°ê°€ ì ì§„ì ìœ¼ë¡œ ì–´ë–»ê²Œ ë³‘í•©ë˜ëŠ”ì§€, ê·¸ë¦¬ê³  êµ°ì§‘í™”ê°€ íŠ¹ì • ê¸°ì¤€ì— ë”°ë¼ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë‹¤.<br>

	from scipy.cluster.hierarchy import dendrogram, linkage
	from sklearn.datasets import load_iris
	import matplotlib.pyplot as plt

	# ë°ì´í„° ë¡œë“œ
	iris = load_iris()
	X = iris.data

	# ê³„ì¸µì  êµ°ì§‘í™” ìˆ˜í–‰
	Z = linkage(X, 'ward')  # ward: ìµœì†Œë¶„ì‚° ê¸°ì¤€ ë³‘í•©

	# ë´ë“œë¡œê·¸ë¨ ì‹œê°í™”
	plt.figure(figsize=(10, 5))
	dendrogram(Z)
	plt.title("Hierarchical Clustering Dendrogram")
	plt.xlabel("Sample Index")
	plt.ylabel("Distance")
	plt.show()

![](./images/dendrogram.PNG)
<br>

---

# [3-1] DBSCAN(Density-Based Spatial Clustering of Applications with Noise)
â–£ ì •ì˜ : ë°€ë„ê°€ ë†’ì€ ì˜ì—­ì„ êµ°ì§‘ìœ¼ë¡œ ë¬¶ê³ , ë°€ë„ê°€ ë‚®ì€ ì ë“¤ì€ ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ëŠ” ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜<br>
â–£ í•„ìš”ì„± : ë‹¤ì–‘í•œ ë°€ë„ì˜ ë°ì´í„° êµ°ì§‘í™” ë° ì´ìƒì¹˜ íƒì§€ì— ìœ ìš©<br>
â–£ ì¥ì  : êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ì‚¬ì „ ì„¤ì •í•  í•„ìš” ì—†ìœ¼ë©°, ì´ìƒì¹˜(outliers)ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬ ê°€ëŠ¥<br>
â–£ ë‹¨ì  : ì ì ˆí•œ íŒŒë¼ë¯¸í„°(Epsilon(Îµ) : Clusterë¥¼ êµ¬ì„±í•˜ëŠ” ìµœì†Œì˜ ê±°ë¦¬, Min Points(MinPts): Clusterë¥¼ êµ¬ì„±ì‹œ í•„ìš”í•œ ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜) ì„¤ì •ì´ í•„ìš”í•˜ë©°, ë°€ë„ê°€ ê· ì¼í•˜ì§€ ì•Šì€ ë°ì´í„°ì— ë¶€ì í•©<br>
â–£ ì‘ìš©ë¶„ì•¼ : ì´ìƒ íƒì§€, ì§€ë¦¬ì  ë°ì´í„° ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: ê° ì ì—ì„œ ë°˜ê²½ ğœ– ë‚´ì— ìˆëŠ” ì ë“¤ì´ ë¯¸ë¦¬ ì •ì˜ëœ MinPts ë³´ë‹¤ ë§ìœ¼ë©´ ê·¸ ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ êµ°ì§‘ì„ í˜•ì„±<br>
â–£ ë™ì‘ ê³¼ì •:<br> 
(1) ë°ì´í„° ì¤‘ì— ì„ì˜ì˜ í¬ì¸íŠ¸ë¥¼ ì„ íƒ<br>
(2) ì„ íƒí•œ ë°ì´í„°ì™€ Epsilon ê±°ë¦¬ ë‚´ì— ìˆëŠ” ëª¨ë“  ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì°¾ìŒ<br>
(3) ì£¼ë³€ì— ìˆëŠ” ë°ì´í„° í¬ì¸íŠ¸ ê°¯ìˆ˜ê°€ Min Points ì´ìƒì´ë©´, í•´ë‹¹ í¬ì¸íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ëŠ” Clusterë¥¼ ìƒì„±<br>
(4) ì–´ë– í•œ í¬ì¸íŠ¸ê°€ ìƒì„±í•œ Cluster ì•ˆì— ì¡´ì¬í•˜ëŠ” ë‹¤ë¥¸ ì  ì¤‘ì— ë‹¤ë¥¸ Clusterì˜ ì¤‘ì‹¬ì´ ë˜ëŠ” ë°ì´í„° í¬ì¸íŠ¸ê°€ ì¡´ì¬í•œë‹¤ë©´ ë‘ ClusterëŠ” í•˜ë‚˜ì˜ Clusterë¡œ ê°„ì£¼<br>
(5) 1~4ë²ˆì„ ëª¨ë“  í¬ì¸íŠ¸ì— ëŒ€í•´ì„œ ë°˜ë³µ. ì–´ëŠ Clusterì—ë„ í¬í•¨ë˜ì§€ ì•ŠëŠ” ë°ì´í„° í¬ì¸íŠ¸ëŠ” ì´ìƒì¹˜ë¡œ ì²˜ë¦¬<br>

![](./images/31.PNG)
<br>
![](./images/32.PNG)
<br>
![](./images/33.PNG)
<br>
![](./images/34.PNG)
<br>
![](./images/35.PNG)
<br>
![](./images/36.PNG)
<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import DBSCAN
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# DBSCAN ì•Œê³ ë¦¬ì¦˜ ì ìš©
	dbscan = DBSCAN(eps=0.5, min_samples=5)
	predicted_labels = dbscan.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = predicted_labels != -1  # ë…¸ì´ì¦ˆê°€ ì•„ë‹Œ í¬ì¸íŠ¸ë§Œ ì„ íƒ
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], predicted_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    if np.any(mask):  # êµ°ì§‘ì— ì†í•˜ëŠ” í¬ì¸íŠ¸ê°€ ìˆì„ ë•Œë§Œ ê³„ì‚°
	        mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels[valid_points], mapped_labels[valid_points])
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("DBSCAN Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/3-1.PNG)
<br>

# [3-2] OPTICS(Ordering Points To Identify the Clustering Structure)
â–£ ì •ì˜ : ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™”(DBSCAN)ì˜ í™•ì¥ìœ¼ë¡œ, ì—¬ëŸ¬ ë°€ë„ ìˆ˜ì¤€ì—ì„œ ë°ì´í„°ì˜ êµ°ì§‘ êµ¬ì¡°ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆë„ë¡ ë°€ë„ê°€ ë‹¤ë¥¸ êµ°ì§‘ì„ ìœ ì—°í•˜ê²Œ ì°¾ê¸° ìœ„í•´ ë„ë‹¬ ê°€ëŠ¥ ê±°ë¦¬(reachability distance)ë¥¼ ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜<br>
â–£ í•„ìš”ì„± : ë‹¤ì–‘í•œ ë°€ë„ë¥¼ ê°€ì§„ ë°ì´í„°ì—ì„œ êµ°ì§‘ì„ ì°¾ì•„ë‚´ê³  ì´ìƒì¹˜(outliers)ë¥¼ ì²˜ë¦¬í•  ë•Œ ìœ ìš©<br>
â–£ ì¥ì  : DBSCANê³¼ ìœ ì‚¬í•˜ê²Œ ì´ìƒì¹˜ë¥¼ ê°ì§€í•  ìˆ˜ ìˆìœ¼ë©°, ì—¬ëŸ¬ ë°€ë„ ìˆ˜ì¤€ì—ì„œ êµ°ì§‘ì„ ì‹ë³„ ê°€ëŠ¥<br>
â–£ ë‹¨ì  : ê³„ì‚° ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë©°, ì ì ˆí•œ ë§¤ê°œë³€ìˆ˜ ì„¤ì •ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼ : ì§€ë¦¬ì  ë°ì´í„° ë¶„ì„, ì´ìƒì¹˜ íƒì§€<br>
â–£ ëª¨ë¸ì‹ : DBSCANê³¼ ìœ ì‚¬í•˜ê²Œ ë°€ë„ ê¸°ë°˜ ì ‘ê·¼ì„ ë”°ë¥´ë©°, ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ reachability-distanceì™€ core-distanceë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘êµ¬ì¡° í˜•ì„±<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import OPTICS
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# OPTICS ì•Œê³ ë¦¬ì¦˜ ì ìš©
	optics = OPTICS(min_samples=5, xi=0.05, min_cluster_size=0.1)
	predicted_labels = optics.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = predicted_labels != -1
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], predicted_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels[valid_points], mapped_labels[valid_points])
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("OPTICS Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/3-2.PNG)
<br>

# [3-3] DBCLASD(Distribution Based Clustering of Large Spatial Databases)
â–£ ì •ì˜: í™•ë¥  ë°€ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ëŠ” ë°€ë„ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ í™•ë¥  ë¶„í¬ë¡œ ëª¨ë¸ë§í•˜ê³ , ê³µê°„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë†’ì€ ë°€ë„ë¥¼ ê°€ì§„ ë°ì´í„° êµ°ì§‘ì„ ì°¾ëŠ”ë‹¤<br>
â–£ í•„ìš”ì„±: ëŒ€ê·œëª¨ ê³µê°„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°€ë„ì— ê¸°ë°˜í•œ êµ°ì§‘ì„ ì°¾ê³ ì í•  ë•Œ ìœ ìš©í•˜ë©°, ë°ì´í„°ì˜ í™•ë¥  ë¶„í¬ë¥¼ í™œìš©í•´ ì •í™•í•œ êµ°ì§‘ì„ íƒìƒ‰í•  ìˆ˜ ìˆìŒ<br>
â–£ ì¥ì : ê³µê°„ ë°ì´í„°ì—ì„œ êµ°ì§‘í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ë…¸ì´ì¦ˆê°€ í¬í•¨ëœ ë°ì´í„°ì—ì„œ ê°•ê±´í•œ êµ°ì§‘í™”ê°€ ê°€ëŠ¥<br>
â–£ ë‹¨ì : ì„¤ì •ëœ í™•ë¥  ë¶„í¬ê°€ ë°ì´í„°ì™€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ êµ°ì§‘í™”ê°€ ë¶€ì •í™•í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œëŠ” ê³„ì‚° ë¹„ìš©ì´ ë†’ë‹¤<br>
â–£ ì‘ìš©ë¶„ì•¼: ì§€ë¦¬ì  ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„, ê³µê°„ ë°ì´í„°ì—ì„œ ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™”, ì´ìƒ íƒì§€ ë° ë°€ë„ ê¸°ë°˜ íŒ¨í„´ íƒìƒ‰<br>
â–£ ëª¨ë¸ì‹: ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ í™•ë¥  ë°€ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘ì„ í˜•ì„±í•˜ë©°, í™•ë¥  ë°€ë„ëŠ” ì£¼ì–´ì§„ í™•ë¥  ë¶„í¬ ëª¨ë¸ì„ ì‚¬ìš©í•´ ê³„ì‚°<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	from scipy.stats import multivariate_normal
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# ê°„ë‹¨í•œ DBCLASD êµ¬í˜„ (ì •ê·œ ë¶„í¬ ê¸°ë°˜)
	class DBCLASD:
	    def __init__(self, threshold=0.01, epsilon=1e-6):
	        self.threshold = threshold  # ë¶„í¬ ì í•© ì„ê³„ê°’
	        self.epsilon = epsilon  # ê³µë¶„ì‚° í–‰ë ¬ì— ì¶”ê°€í•  ì‘ì€ ê°’
	        self.clusters = []  # êµ°ì§‘ ì •ë³´ ì €ì¥
	    
	    def fit_predict(self, X):
	        labels = -np.ones(X.shape[0], dtype=int)  # ì´ˆê¸°ê°’ -1 (ë…¸ì´ì¦ˆ)
	        
	        for i, point in enumerate(X):
	            added_to_cluster = False
	            for cluster_id, (mean, cov) in enumerate(self.clusters):
	                # ê¸°ì¡´ êµ°ì§‘ì˜ ë¶„í¬ì™€ ë¹„êµí•˜ì—¬ í•´ë‹¹ ë¶„í¬ì— ì†í•˜ëŠ”ì§€ í™•ì¸
	                adjusted_cov = cov + self.epsilon * np.eye(cov.shape[0])  # ì‘ì€ ê°’ì„ ë”í•˜ì—¬ ì–‘ì˜ ì •ë¶€í˜¸ í–‰ë ¬ë¡œ ë§Œë“¦
	                if multivariate_normal(mean=mean, cov=adjusted_cov).pdf(point) > self.threshold:
	                    labels[i] = cluster_id
	                    # êµ°ì§‘ ì—…ë°ì´íŠ¸
	                    points_in_cluster = X[labels == cluster_id]
	                    mean = np.mean(points_in_cluster, axis=0)
	                    cov = np.cov(points_in_cluster, rowvar=False)
	                    self.clusters[cluster_id] = (mean, cov)
	                    added_to_cluster = True
	                    break
	            if not added_to_cluster:
	                # ìƒˆë¡œìš´ êµ°ì§‘ ìƒì„±
	                labels[i] = len(self.clusters)
	                mean = point
	                cov = np.cov(X.T) + self.epsilon * np.eye(X.shape[1])  # ê³µë¶„ì‚° ì´ˆê¸°ê°’ì— epsilonì„ ë”í•¨
	                self.clusters.append((mean, cov))
	        
	        self.labels_ = labels
	        return labels
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# DBCLASD ì•Œê³ ë¦¬ì¦˜ ì ìš©
	dbclasd = DBCLASD(threshold=0.01, epsilon=1e-6)
	predicted_labels = dbclasd.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = predicted_labels != -1
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], predicted_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("DBCLASD Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/3-3.png)
<br>

# [3-4] DENCLUE(DENsity-based CLUstEring)
â–£ ì •ì˜: í™•ë¥  ë°€ë„ í•¨ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ì˜ ë°€ë„ ë¶„í¬ë¥¼ ëª¨ë¸ë§í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ë°€ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ë°ì´í„° í¬ì¸íŠ¸ê°€ ëª¨ì—¬ì„œ í˜•ì„±í•˜ëŠ” ë°€ë„ í•¨ìˆ˜ì—ì„œ ë°€ë„ê°€ ë†’ì€ ì˜ì—­ì„ êµ°ì§‘ìœ¼ë¡œ í˜•ì„±í•˜ëŠ” ê²ƒ<br>
â–£ í•„ìš”ì„±: ë°ì´í„°ì˜ ë°€ë„ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘í™”í•˜ê³ , ë…¸ì´ì¦ˆë‚˜ ì´ìƒì¹˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ êµ¬ë¶„í•  í•„ìš”ê°€ ìˆì„ ë•Œ ìœ ìš©<br>
â–£ ì¥ì : ëª…í™•í•˜ê²Œ ì •ì˜ëœ êµ°ì§‘ì„ ìƒì„±í•˜ê³ , ë°€ë„ê°€ ë‚®ì€ ì§€ì—­ì„ ë…¸ì´ì¦ˆë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„° ë¶„í¬ì— ë”°ë¼ ë‹¤ì–‘í•œ ë°€ë„ì˜ êµ°ì§‘ì„ ì˜ íƒì§€í•  ìˆ˜ ìˆìŒ<br>
â–£ ë‹¨ì : ë°€ë„ í•¨ìˆ˜ë¥¼ ì„¤ì •í•˜ëŠ” ë° í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ê°€ ë§ìœ¼ë©° ê³„ì‚°ì´ ë³µì¡í•˜ì—¬ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼: íŒ¨í„´ ì¸ì‹ ë° ì´ë¯¸ì§€ ì²˜ë¦¬, ë°ì´í„° ë§ˆì´ë‹ì—ì„œ ë°€ë„ ê¸°ë°˜ íŒ¨í„´ íƒìƒ‰, í™˜ê²½ ëª¨ë‹ˆí„°ë§ ë°ì´í„° ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ ë°€ë„ ê¸°ì—¬ë¥¼ ê°€ìš°ì‹œì•ˆ ì»¤ë„ ë“±ìœ¼ë¡œ ëª¨ë¸ë§í•˜ì—¬ ë°€ë„ í•¨ìˆ˜ë¥¼ ê³„ì‚°(êµ°ì§‘ì€ ë°€ë„ í•¨ìˆ˜ì˜ ê·¹ëŒ€ì ì—ì„œ ì‹œì‘í•˜ì—¬ êµ°ì§‘í™”)<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.neighbors import KernelDensity
	from sklearn.cluster import DBSCAN
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Gaussian Kernel Density Estimation (KDE)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ë°€ë„ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ
	def kde_transform(data, bandwidth=0.5):
	    kde = KernelDensity(bandwidth=bandwidth)
	    kde.fit(data)
	    log_densities = kde.score_samples(data)
	    return log_densities
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# KDE ë³€í™˜ ì ìš© (ë°€ë„ ê¸°ë°˜ íŠ¹ì§• ê°•ì¡°)
	log_densities = kde_transform(data, bandwidth=0.5)
	density_threshold = np.percentile(log_densities, 75)  # ë°€ë„ ê¸°ì¤€ì„ 75í¼ì„¼íƒ€ì¼ë¡œ ì„¤ì •
	high_density_points = data[log_densities >= density_threshold]  # ë°€ë„ê°€ ë†’ì€ í¬ì¸íŠ¸ ì„ íƒ
	
	# DBSCAN ì•Œê³ ë¦¬ì¦˜ ì ìš© (ë°€ë„ê°€ ë†’ì€ ì˜ì—­ì—ì„œ ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™” ìˆ˜í–‰)
	dbscan = DBSCAN(eps=0.5, min_samples=5)
	predicted_labels = dbscan.fit_predict(high_density_points)
	
	# ë°€ë„ê°€ ë†’ì€ í¬ì¸íŠ¸ë“¤ì— ëŒ€í•œ ë ˆì´ë¸”ì„ ì „ì²´ ë°ì´í„° ë ˆì´ë¸”ì— ë§¤í•‘
	full_labels = -np.ones(data.shape[0], dtype=int)  # ì´ˆê¸°ê°’ -1 (ë…¸ì´ì¦ˆ)
	high_density_indices = np.where(log_densities >= density_threshold)[0]
	full_labels[high_density_indices] = predicted_labels
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = full_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = full_labels != -1
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], full_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(full_labels)
	for i in np.unique(full_labels):
	    mask = (full_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels[full_labels != -1], mapped_labels[full_labels != -1])
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("DENCLUE Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/3-4.PNG)
<br>

# [3-5] Mean-Shift Clustering
â–£ ì •ì˜ : ë°ì´í„°ì˜ ë°€ë„ê°€ ë†’ì€ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ë©° êµ°ì§‘ì˜ ì¤‘ì‹¬ì„ ì°¾ëŠ” ë¹„ëª¨ìˆ˜ êµ°ì§‘í™” ë°©ë²•<br>
â–£ í•„ìš”ì„± : êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ì‚¬ì „ ì„¤ì •í•  í•„ìš” ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ êµ°ì§‘ì„ ì°¾ì„ ë•Œ ìœ ìš©<br>
â–£ ì¥ì  : êµ°ì§‘ ê°œìˆ˜ ì‚¬ì „ ì„¤ì • ë¶ˆí•„ìš”í•˜ë©°, ë¹„ì„ í˜•ì  ë¶„í¬ì—ë„ ì í•©<br>
â–£ ë‹¨ì  : ê³„ì‚° ë¹„ìš©ì´ í¬ê³  ê³ ì°¨ì› ë°ì´í„°ì— ì í•©í•˜ì§€ ì•ŠìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼ : ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜, ê°ì²´ ì¶”ì <br>
â–£ ëª¨ë¸ì‹ : ğ¾ëŠ” ì»¤ë„ í•¨ìˆ˜, ğ‘¥ëŠ” ì´ë™í•  ì , ğ‘(ğ‘¥)ëŠ” ë°˜ê²½ ë‚´ ì´ì›ƒ ì <br>
![](./images/meanshift.PNG)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import MeanShift
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# Mean-Shift Clustering ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ
	mean_shift = MeanShift()
	predicted_labels = mean_shift.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(len(np.unique(predicted_labels))):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Mean-Shift Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/3-5.PNG)
<br>

---

# [4-1] Wave-Cluster
â–£ ì •ì˜: ì›¨ì´ë¸”ë¦¿ ë³€í™˜ì„ ì´ìš©í•œ í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê²©ì í˜•íƒœë¡œ ë‚˜ëˆˆ í›„ ì›¨ì´ë¸”ë¦¿ ë³€í™˜ì„ ì‚¬ìš©í•´ ë°€ë„ê°€ ë†’ì€ ì˜ì—­ì„ êµ°ì§‘ìœ¼ë¡œ íƒì§€<br>
â–£ í•„ìš”ì„±: ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ êµ°ì§‘í™”ê°€ ê°€ëŠ¥í•˜ë©°, ë‹¤ì°¨ì› ê³µê°„ì—ì„œ ë‹¤ì–‘í•œ ë°€ë„ì˜ êµ°ì§‘ì„ ì‹ë³„í•˜ëŠ” ë° ìœ ìš©<br>
â–£ ì¥ì : ë‹¤ì°¨ì› ë°ì´í„°ì—ì„œ ë‹¤ì–‘í•œ ëª¨ì–‘ì˜ êµ°ì§‘ì„ íš¨ê³¼ì ìœ¼ë¡œ íƒì§€í•  ìˆ˜ ìˆìœ¼ë©°, ë…¸ì´ì¦ˆì™€ ì´ìƒì¹˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•  ìˆ˜ ìˆìŒ<br>
â–£ ë‹¨ì : ì ì ˆí•œ ì›¨ì´ë¸”ë¦¿ ë³€í™˜ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ê¸° ì–´ë µê³  ë°ì´í„°ì˜ í•´ìƒë„ì™€ ê²©ì í¬ê¸°ì— ë”°ë¼ êµ°ì§‘ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼: ì´ë¯¸ì§€ ë¶„ì„, ì˜ìƒ ì²˜ë¦¬ ë° íŒ¨í„´ ì¸ì‹, ëŒ€ê·œëª¨ ì§€ë¦¬ ë°ì´í„° ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: ê° ê²©ìì—ì„œ ì›¨ì´ë¸”ë¦¿ ë³€í™˜ì„ ìˆ˜í–‰í•˜ì—¬ ë°€ë„ê°€ ë†’ì€ í´ëŸ¬ìŠ¤í„° ì˜ì—­ì„ ì‹ë³„. ì›¨ì´ë¸”ë¦¿ ë³€í™˜ì„ í†µí•´ ê³ ì£¼íŒŒì™€ ì €ì£¼íŒŒ ì„±ë¶„ì„ ë¶„ë¦¬í•˜ì—¬ ë…¸ì´ì¦ˆì™€ ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ê³ , ë°€ë„ê°€ ë†’ì€ ì˜ì—­ì„ êµ°ì§‘ìœ¼ë¡œ í˜•ì„±<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import DBSCAN
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.ndimage import gaussian_filter1d
	from scipy.stats import mode
	
	# Gaussian í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°€ë„ ê¸°ë°˜ íŠ¹ì§•ì„ ê°•ì¡°í•˜ëŠ” í•¨ìˆ˜
	def gaussian_filter_transform(data, sigma=1):
	    transformed_data = []
	    for feature in data.T:  # ê° í”¼ì²˜(ì—´)ì— ëŒ€í•´ í•„í„°ë§ ìˆ˜í–‰
	        transformed_feature = gaussian_filter1d(feature, sigma=sigma)
	        transformed_data.append(transformed_feature)
	    return np.array(transformed_data).T
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# Gaussian í•„í„° ì ìš© (ë°€ë„ ê¸°ë°˜ íŠ¹ì§• ê°•ì¡°)
	transformed_data = gaussian_filter_transform(data, sigma=1)
	
	# DBSCAN ì•Œê³ ë¦¬ì¦˜ ì ìš© (ë³€í™˜ëœ ë°ì´í„°ì—ì„œ ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™” ìˆ˜í–‰)
	dbscan = DBSCAN(eps=0.5, min_samples=5)
	predicted_labels = dbscan.fit_predict(transformed_data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = predicted_labels != -1
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], predicted_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Wave-Cluster (Gaussian Filter Approximation) Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/4-1.PNG)
<br>

# [4-2] STING(Statistical Information Grid-based method)
â–£ ì •ì˜: ë°ì´í„° ê³µê°„ì„ ê²©ì í˜•íƒœë¡œ ë‚˜ëˆ„ê³ , ê° ê²©ìì˜ í†µê³„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì¸µì ìœ¼ë¡œ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜. ê²©ìëŠ” ì—¬ëŸ¬ ê³„ì¸µìœ¼ë¡œ ë‚˜ë‰˜ë©°, ìƒìœ„ ê³„ì¸µì—ì„œ í•˜ìœ„ ê³„ì¸µìœ¼ë¡œ ë‚´ë ¤ê°€ë©° ë°ì´í„°ì˜ ë°€ë„ë¥¼ ë¶„ì„<br>
â–£ í•„ìš”ì„±: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ êµ°ì§‘í™”í•  ìˆ˜ ìˆìœ¼ë©°, íŠ¹íˆ ë°ì´í„°ì˜ ë°€ë„ ë¶„í¬ë¥¼ ê³ ë ¤í•˜ì—¬ ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ<br>
â–£ ì¥ì : ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ë¹ ë¥´ê²Œ êµ°ì§‘í™”í•  ìˆ˜ ìˆìœ¼ë©°, ê° ê²©ìì˜ í†µê³„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ íš¨ìœ¨ì ì¸ êµ°ì§‘í™”ê°€ ê°€ëŠ¥<br>
â–£ ë‹¨ì : ê²©ì í•´ìƒë„ê°€ ë‚®ì„ ê²½ìš°, ì„¸ë¶€ì ì¸ êµ°ì§‘ì„ íƒì§€í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìœ¼ë©°, ë°€ë„ê°€ ë‚®ì€ ë°ì´í„°ì—ì„œëŠ” íš¨ê³¼ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼: ìœ„ì„± ì´ë¯¸ì§€ ë¶„ì„, ì§€ë¦¬ ë°ì´í„°ì™€ í™˜ê²½ ë°ì´í„°ì˜ êµ°ì§‘í™”, ë°ì´í„° ë§ˆì´ë‹ì—ì„œ ëŒ€ê·œëª¨ ë°ì´í„° ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: ê²©ìë¥¼ ê³„ì¸µì ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ê²©ìì˜ í†µê³„ ì •ë³´(í‰ê· , ë¶„ì‚° ë“±)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘ì„ í˜•ì„±. ê²©ìì˜ í†µê³„ ì •ë³´ëŠ” ìƒìœ„ ê³„ì¸µì—ì„œ í•˜ìœ„ ê³„ì¸µìœ¼ë¡œ ì „íŒŒë˜ë©°, ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# STING êµ°ì§‘í™” í´ë˜ìŠ¤
	class STING:
	    def __init__(self, x_bins=10, y_bins=10, density_threshold=0.05):
	        self.x_bins = x_bins  # Xì¶• ê·¸ë¦¬ë“œ ì…€ ê°œìˆ˜
	        self.y_bins = y_bins  # Yì¶• ê·¸ë¦¬ë“œ ì…€ ê°œìˆ˜
	        self.density_threshold = density_threshold  # êµ°ì§‘ í˜•ì„± ë°€ë„ ì„ê³„ê°’
	
	    def fit_predict(self, X):
	        # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ë§Œ ì‚¬ìš©í•˜ì—¬ 2D ê·¸ë¦¬ë“œ ìƒì„±
	        x_min, x_max = X[:, 0].min(), X[:, 0].max()
	        y_min, y_max = X[:, 1].min(), X[:, 1].max()
	        
	        # ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ ê·¸ë¦¬ë“œ ì…€ ìœ„ì¹˜ ê³„ì‚°
	        x_bins = np.linspace(x_min, x_max, self.x_bins + 1)
	        y_bins = np.linspace(y_min, y_max, self.y_bins + 1)
	        grid = np.zeros((self.x_bins, self.y_bins), dtype=int)
	
	        # ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê·¸ë¦¬ë“œì— ë§¤í•‘í•˜ì—¬ ë°€ë„ ê³„ì‚°
	        labels = -np.ones(X.shape[0], dtype=int)
	        for i, (x, y) in enumerate(X[:, :2]):
	            x_idx = np.digitize(x, x_bins) - 1
	            y_idx = np.digitize(y, y_bins) - 1
	            if x_idx < self.x_bins and y_idx < self.y_bins:
	                grid[x_idx, y_idx] += 1
	        
	        # ë°€ë„ ê¸°ì¤€ìœ¼ë¡œ êµ°ì§‘í™” (density_threshold ì´ìƒì¸ ì…€ì„ êµ°ì§‘ìœ¼ë¡œ ê°„ì£¼)
	        cluster_id = 0
	        for i in range(self.x_bins):
	            for j in range(self.y_bins):
	                if grid[i, j] >= self.density_threshold * X.shape[0]:  # ë°€ë„ ê¸°ì¤€ ë§Œì¡± ì‹œ êµ°ì§‘í™”
	                    for k, (x, y) in enumerate(X[:, :2]):
	                        x_idx = np.digitize(x, x_bins) - 1
	                        y_idx = np.digitize(y, y_bins) - 1
	                        if x_idx == i and y_idx == j:
	                            labels[k] = cluster_id
	                    cluster_id += 1
	
	        self.labels_ = labels
	        return self.labels_
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data[:, :2]  # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ë§Œ ì‚¬ìš©
	true_labels = iris.target
	
	# STING ì•Œê³ ë¦¬ì¦˜ ì ìš©
	sting = STING(x_bins=10, y_bins=10, density_threshold=0.05)
	predicted_labels = sting.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=[iris.feature_names[0], iris.feature_names[1]])
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = predicted_labels != -1
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], predicted_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("STING Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/4-2.PNG)
<br>

# [4-3] CLIQUE(CLustering In QUEst)
â–£ ì •ì˜: ë°ì´í„° ê³µê°„ì„ ê²©ìë¡œ ë‚˜ëˆ„ê³ , ê° ê²©ì ë‚´ì—ì„œ ë°ì´í„°ì˜ ë°€ë„ì— ë”°ë¼ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê³ ì°¨ì› ë°ì´í„°ì—ì„œ êµ°ì§‘ì„ ì‹ë³„í•˜ê¸° ìœ„í•´ ë°€ë„ê°€ ë†’ì€ ë¶€ë¶„ ê³µê°„(subspace)ì„ ì°¾ì•„ êµ°ì§‘ì„ í˜•ì„±<br>
â–£ í•„ìš”ì„±: ê³ ì°¨ì› ë°ì´í„°ì—ì„œ ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•˜ë©°, ë°ì´í„°ì˜ ë‹¤ì–‘í•œ ë¶€ë¶„ ê³µê°„ì—ì„œ êµ°ì§‘ì„ íƒìƒ‰í•  í•„ìš”ê°€ ìˆì„ ë•Œ ìœ ìš©<br>
â–£ ì¥ì : ê³ ì°¨ì› ë°ì´í„°ì—ì„œ ë¶€ë¶„ ê³µê°„ì„ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘ì„ íƒìƒ‰í•  ìˆ˜ ìˆìœ¼ë©° ë°ì´í„°ì˜ ë°€ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ êµ°ì§‘ì„ ì‹ë³„<br>
â–£ ë‹¨ì : ê²©ì í¬ê¸°ì™€ ë°€ë„ ì„ê³„ê°’ ì„¤ì •ì´ ì–´ë µê³ , ê²°ê³¼ê°€ ì„¤ì •ëœ íŒŒë¼ë¯¸í„°ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘<br>
â–£ ì‘ìš©ë¶„ì•¼: ìƒë¬¼í•™ì—ì„œ ìœ ì „ì ë°ì´í„° êµ°ì§‘í™”, ê³ ì°¨ì› ê¸ˆìœµ ë°ì´í„° ë¶„ì„, ì´ë¯¸ì§€ ë¶„í•  ë° í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: ë°ì´í„°ë¥¼ ê²©ìë¡œ ë‚˜ëˆˆ í›„, ë°€ë„ê°€ ë†’ì€ ë¶€ë¶„ ê³µê°„ì„ íƒìƒ‰í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±(êµ°ì§‘ì€ ê° ë¶€ë¶„ ê³µê°„ì—ì„œ ë°€ë„ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê²©ìë“¤ë¡œ êµ¬ì„±)<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# CLIQUE êµ°ì§‘í™” í´ë˜ìŠ¤
	class CLIQUE:
	    def __init__(self, x_bins=10, y_bins=10, density_threshold=0.05):
	        self.x_bins = x_bins  # Xì¶• ê·¸ë¦¬ë“œ ì…€ ê°œìˆ˜
	        self.y_bins = y_bins  # Yì¶• ê·¸ë¦¬ë“œ ì…€ ê°œìˆ˜
	        self.density_threshold = density_threshold  # êµ°ì§‘ í˜•ì„± ë°€ë„ ì„ê³„ê°’
	
	    def fit_predict(self, X):
	        # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ë§Œ ì‚¬ìš©í•˜ì—¬ 2D ê·¸ë¦¬ë“œ ìƒì„±
	        x_min, x_max = X[:, 0].min(), X[:, 0].max()
	        y_min, y_max = X[:, 1].min(), X[:, 1].max()
	        
	        # ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ ê·¸ë¦¬ë“œ ì…€ ìœ„ì¹˜ ê³„ì‚°
	        x_bins = np.linspace(x_min, x_max, self.x_bins + 1)
	        y_bins = np.linspace(y_min, y_max, self.y_bins + 1)
	        grid = np.zeros((self.x_bins, self.y_bins), dtype=int)
	
	        # ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê·¸ë¦¬ë“œì— ë§¤í•‘í•˜ì—¬ ë°€ë„ ê³„ì‚°
	        labels = -np.ones(X.shape[0], dtype=int)
	        for i, (x, y) in enumerate(X[:, :2]):
	            x_idx = np.digitize(x, x_bins) - 1
	            y_idx = np.digitize(y, y_bins) - 1
	            if x_idx < self.x_bins and y_idx < self.y_bins:
	                grid[x_idx, y_idx] += 1
	        
	        # ë°€ë„ ê¸°ì¤€ìœ¼ë¡œ êµ°ì§‘í™” (density_threshold ì´ìƒì¸ ì…€ì„ êµ°ì§‘ìœ¼ë¡œ ê°„ì£¼)
	        cluster_id = 0
	        for i in range(self.x_bins):
	            for j in range(self.y_bins):
	                if grid[i, j] >= self.density_threshold * X.shape[0]:  # ë°€ë„ ê¸°ì¤€ ë§Œì¡± ì‹œ êµ°ì§‘í™”
	                    for k, (x, y) in enumerate(X[:, :2]):
	                        x_idx = np.digitize(x, x_bins) - 1
	                        y_idx = np.digitize(y, y_bins) - 1
	                        if x_idx == i and y_idx == j:
	                            labels[k] = cluster_id
	                    cluster_id += 1
	
	        self.labels_ = labels
	        return self.labels_
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data[:, :2]  # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ë§Œ ì‚¬ìš©
	true_labels = iris.target
	
	# CLIQUE ì•Œê³ ë¦¬ì¦˜ ì ìš©
	clique = CLIQUE(x_bins=10, y_bins=10, density_threshold=0.05)
	predicted_labels = clique.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=[iris.feature_names[0], iris.feature_names[1]])
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚° (ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” ì œì™¸)
	valid_points = predicted_labels != -1
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], predicted_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in np.unique(predicted_labels):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("CLIQUE Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/4-3.PNG)
<br>

# [4-4] OptiGrid
â–£ ì •ì˜: ë°ì´í„° ê³µê°„ì„ ìµœì í™”ëœ ê²©ì í˜•íƒœë¡œ ë¶„í• í•˜ì—¬ ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê° ì°¨ì›ì—ì„œ ìµœì ì˜ ê²©ì ë¶„í• ì„ íƒìƒ‰í•˜ì—¬, ë°€ë„ê°€ ë†’ì€ ì§€ì—­ì„ êµ°ì§‘ìœ¼ë¡œ í˜•ì„±<br>
â–£ í•„ìš”ì„±: ë°ì´í„° ë¶„í¬ì— ë”°ë¼ ìµœì ì˜ ê²©ì ë¶„í• ì„ í†µí•´ êµ°ì§‘ì„ íƒìƒ‰í•˜ë©°, íŠ¹íˆ ë°ì´í„°ì˜ ë°€ë„ê°€ ë¶ˆê· ì¼í•œ ê²½ìš°ì— ìœ ìš©<br>
â–£ ì¥ì : ë°ì´í„° ë°€ë„ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ê²©ìë¥¼ ì¡°ì •í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±í•˜ê³  ë¶ˆê· ì¼í•œ ë°ì´í„°ì—ì„œë„ ì ì‘ì  êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰<br>
â–£ ë‹¨ì : ìµœì ì˜ ê²©ì ë¶„í• ì„ ì°¾ëŠ” ê³¼ì •ì—ì„œ ê³„ì‚° ë¹„ìš©ì´ ë†’ê³  íŒŒë¼ë¯¸í„° ì„¤ì •ì´ ë³µì¡í•˜ê³ , ë°ì´í„° ë¶„í¬ì— ë¯¼ê°<br>
â–£ ì‘ìš©ë¶„ì•¼: ì˜ë£Œ ë°ì´í„°ì˜ êµ°ì§‘í™”, ë°ì´í„° ë§ˆì´ë‹ì—ì„œ ë¶ˆê· ì¼í•œ ë°ì´í„° íƒìƒ‰, ì§€ë¦¬ì  ë°ì´í„°ì—ì„œ ì§€ì—­ì  êµ°ì§‘ íƒìƒ‰<br>
â–£ ëª¨ë¸ì‹: OptiGridëŠ” ê° ì°¨ì›ì—ì„œ ìµœì ì˜ ê²©ì ë¶„í• ì„ íƒìƒ‰í•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±í•©ë‹ˆë‹¤. ê²©ì ë‚´ ë°€ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì ì˜ ë¶„í•  ìœ„ì¹˜ë¥¼ ì°¾ì•„ë‚´ê³ , ë°€ë„ê°€ ë†’ì€ ê²©ìë“¤ì„ êµ°ì§‘ìœ¼ë¡œ í˜•ì„±í•©ë‹ˆë‹¤.

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	
	# OptiGrid êµ°ì§‘í™” í´ë˜ìŠ¤
	class OptiGrid:
	    def __init__(self, x_bins=10, y_bins=10, density_threshold=0.05):
	        self.x_bins = x_bins  # Xì¶• ê·¸ë¦¬ë“œ ì…€ ê°œìˆ˜
	        self.y_bins = y_bins  # Yì¶• ê·¸ë¦¬ë“œ ì…€ ê°œìˆ˜
	        self.density_threshold = density_threshold  # êµ°ì§‘ í˜•ì„± ë°€ë„ ì„ê³„ê°’
	
	    def fit_predict(self, X):
	        # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ë§Œ ì‚¬ìš©í•˜ì—¬ 2D ê·¸ë¦¬ë“œ ìƒì„±
	        x_min, x_max = X[:, 0].min(), X[:, 0].max()
	        y_min, y_max = X[:, 1].min(), X[:, 1].max()
	        
	        # ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ ê·¸ë¦¬ë“œ ì…€ ìœ„ì¹˜ ê³„ì‚°
	        x_bins = np.linspace(x_min, x_max, self.x_bins + 1)
	        y_bins = np.linspace(y_min, y_max, self.y_bins + 1)
	        grid = np.zeros((self.x_bins, self.y_bins), dtype=int)
	
	        # ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê·¸ë¦¬ë“œì— ë§¤í•‘í•˜ì—¬ ë°€ë„ ê³„ì‚°
	        labels = -np.ones(X.shape[0], dtype=int)
	        for i, (x, y) in enumerate(X[:, :2]):
	            x_idx = np.digitize(x, x_bins) - 1
	            y_idx = np.digitize(y, y_bins) - 1
	            if x_idx < self.x_bins and y_idx < self.y_bins:
	                grid[x_idx, y_idx] += 1
	        
	        # ë°€ë„ ê¸°ì¤€ìœ¼ë¡œ êµ°ì§‘í™” (density_threshold ì´ìƒì¸ ì…€ì„ êµ°ì§‘ìœ¼ë¡œ ê°„ì£¼)
	        cluster_id = 0
	        for i in range(self.x_bins):
	            for j in range(self.y_bins):
	                if grid[i, j] >= self.density_threshold * X.shape[0]:  # ë°€ë„ ê¸°ì¤€ ë§Œì¡± ì‹œ êµ°ì§‘í™”
	                    for k, (x, y) in enumerate(X[:, :2]):
	                        x_idx = np.digitize(x, x_bins) - 1
	                        y_idx = np.digitize(y, y_bins) - 1
	                        if x_idx == i and y_idx == j:
	                            labels[k] = cluster_id
	                    cluster_id += 1
	
	        self.labels_ = labels
	        return self.labels_
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data[:, :2]  # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ë§Œ ì‚¬ìš©
	true_labels = iris.target
	
	# OptiGrid ì•Œê³ ë¦¬ì¦˜ ì ìš©
	optigrid = OptiGrid(x_bins=10, y_bins=10, density_threshold=0.05)
	predicted_labels = optigrid.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=[iris.feature_names[0], iris.feature_names[1]])
	df['Cluster'] = predicted_labels
	
	# êµ°ì§‘ í‰ê°€
	# ë…¸ì´ì¦ˆ (-1) ë°ì´í„°ëŠ” ì‹¤ë£¨ì—£ ì ìˆ˜ ê³„ì‚°ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.
	valid_points = predicted_labels != -1
	if np.sum(valid_points) > 1:
	    silhouette_avg = silhouette_score(data[valid_points], predicted_labels[valid_points])
	    print(f"Silhouette Score: {silhouette_avg:.3f}")
	else:
	    print("Silhouette Score: Not enough valid points for calculation.")
	
	# ì •í™•ë„ ê³„ì‚° (ì‹¤ì œ ë ˆì´ë¸”ì´ ìˆëŠ” ê²½ìš°)
	# ì£¼ì˜: êµ°ì§‘í™” ê²°ê³¼ëŠ” ì •ë‹µ ë ˆì´ë¸”ê³¼ ì§ì ‘ì ìœ¼ë¡œ ë§¤ì¹­ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
	if len(np.unique(predicted_labels)) == len(np.unique(true_labels)):
	    accuracy = accuracy_score(true_labels, predicted_labels)
	    print(f"Accuracy: {accuracy:.3f}")
	else:
	    print("Accuracy: Cannot compute due to mismatch in label count.")
	
	# ì‹œê°í™”
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("OptiGrid Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/4-4.PNG)
<br>

---

# [5-1] EM(Expectation-Maximization)
â–£ ì •ì˜: ë°ì´í„°ê°€ ì—¬ëŸ¬ ê°œì˜ ì ì¬ í™•ë¥  ë¶„í¬(ë³´í†µ ê°€ìš°ì‹œì•ˆ)ì—ì„œ ìƒì„±ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ì—¬, ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë¶„í¬ë¡œ ëª¨ë¸ë§í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ì—¬ëŸ¬ êµ°ì§‘ì— ì†í•  í™•ë¥ ì„ ê³„ì‚°í•´ ì†Œí”„íŠ¸ êµ°ì§‘í™”ë¥¼ ì œê³µ<br>
â–£ í•„ìš”ì„±: ë°ì´í„°ê°€ ë‹¤ì–‘í•œ í™•ë¥  ë¶„í¬ë¡œ êµ¬ì„±ë˜ì–´ ìˆì„ ë•Œ, êµ°ì§‘ì˜ ê²½ê³„ë¥¼ ìœ ì—°í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆì–´ ë”ìš± ì •í™•í•œ êµ°ì§‘í™”ê°€ ê°€ëŠ¥<br>
â–£ ì¥ì : ì†Œí”„íŠ¸ êµ°ì§‘í™”ê°€ ê°€ëŠ¥í•˜ì—¬ ë°ì´í„°ê°€ ì—¬ëŸ¬ êµ°ì§‘ì— ì†í•  í™•ë¥ ì„ ì œê³µí•˜ë©° êµ°ì§‘ì˜ í¬ê¸°ì™€ ëª¨ì–‘ì´ ë‹¤ë¥¸ ê²½ìš°ì—ë„ ì í•©<br>
â–£ ë‹¨ì : ì´ˆê¸° ë§¤ê°œë³€ìˆ˜ ì„¤ì •ì— ë”°ë¼ ê²°ê³¼ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©° ê³ ì°¨ì› ë°ì´í„°ì—ì„œëŠ” ê³„ì‚° ë¹„ìš©ì´ ë†’ì•„ì§<br>
â–£ ì‘ìš©ë¶„ì•¼: ìŒì„± ë° ì˜ìƒ ì¸ì‹. ì´ë¯¸ì§€ ì²˜ë¦¬. ê¸ˆìœµ ë° ë§ˆì¼€íŒ…ì—ì„œì˜ ì‚¬ìš©ì ì„¸ë¶„í™”.<br>
â–£ ëª¨ë¸ì‹: E ë‹¨ê³„ì™€ M ë‹¨ê³„ë¥¼ ë°˜ë³µí•˜ì—¬ ìˆ˜ë ´í•  ë•Œê¹Œì§€ ìµœì ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì°¾ì•„ê°„ë‹¤. E ë‹¨ê³„: ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ íŠ¹ì • êµ°ì§‘ì— ì†í•  í™•ë¥ ì„ ê³„ì‚°, M ë‹¨ê³„: ì´ í™•ë¥ ì„ ì‚¬ìš©í•˜ì—¬ ê° êµ°ì§‘ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸<br>
![](./images/EM.png)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.mixture import GaussianMixture
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# Gaussian Mixture (EM ì•Œê³ ë¦¬ì¦˜) ëª¨ë¸ ì ìš©
	gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)
	gmm.fit(data)
	predicted_labels = gmm.predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	# Gaussian Mixture ëª¨ë¸ì˜ êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì€ ë§¤ì¹­ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(3):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Gaussian Mixture Model (EM) Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/5-1.PNG)
<br>

# [5-2] COBWEB
â–£ ì •ì˜: ê°œë… í˜•ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” íŠ¸ë¦¬ê¸°ë°˜ì˜ ê³„ì¸µì  êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ê°ê°ì˜ ë…¸ë“œê°€ ê°œë…ì„ ë‚˜íƒ€ë‚´ëŠ” ë¶„ë¥˜ íŠ¸ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì ì§„ì ìœ¼ë¡œ í•™ìŠµ<br>
â–£ í•„ìš”ì„±: ì ì§„ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³  ë¶„ë¥˜í•´ì•¼ í•˜ëŠ” ê²½ìš°ì— ìœ ìš©í•˜ë©°, ê³„ì¸µ êµ¬ì¡°ë¡œ ë°ì´í„°ë¥¼ êµ°ì§‘í™”í•˜ì—¬ ê°œë… í˜•ì„±ì„ ìˆ˜í–‰<br>
â–£ ì¥ì : ë²”ì£¼í˜• ë°ì´í„° ë° í˜¼í•©í˜• ë°ì´í„°ì— ì í•©. ì ì§„ì ìœ¼ë¡œ í•™ìŠµí•˜ë©°, ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ ê°€ëŠ¥<br>
â–£ ë‹¨ì : ë°ì´í„° ì…ë ¥ ìˆœì„œì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©° ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆê³ , ë…¸ì´ì¦ˆì— ë¯¼ê°<br>
â–£ ì‘ìš©ë¶„ì•¼: ë¬¸ì„œ ë¶„ë¥˜, ê°œë… í˜•ì„±ì„ í†µí•œ ì¸ê³µì§€ëŠ¥ í•™ìŠµ, ì‹œì¥ ì„¸ë¶„í™”ì—ì„œì˜ ê³ ê° ë¶„ë¥˜<br>
â–£ ëª¨ë¸ì‹: COBWEBì€ ê° ë…¸ë“œì˜ ë²”ì£¼ ìœ í‹¸ë¦¬í‹°(Category Utility, CU)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜<br>
![](./images/COBWEB.png)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import AgglomerativeClustering
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# ê³„ì¸µì  êµ°ì§‘í™” ëª¨ë¸ ì„¤ì • (COBWEBì˜ ê°œë…ì— ë§ì¶° ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ê³„ì¸µì  êµ°ì§‘í™” ìˆ˜í–‰)
	# ê³„ì¸µì  êµ°ì§‘í™”ëŠ” íŠ¹ì§•ì´ ìœ ì‚¬í•œ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë³‘í•©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, COBWEBê³¼ ìœ ì‚¬í•˜ê²Œ ì‘ë™
	agglomerative_clustering = AgglomerativeClustering(n_clusters=3, linkage='ward')
	predicted_labels = agglomerative_clustering.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(3):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Hierarchical Clustering (COBWEB-like) on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()
	
![](./images/5-2.PNG)
<br>

# [5-3] CLASSIT
â–£ ì •ì˜: COBWEBì„ í™•ì¥í•˜ì—¬ ìˆ˜ì¹˜í˜• ë°ì´í„°ë¥¼ ì§€ì›í•˜ëŠ” ê³„ì¸µì  êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì ì§„ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ êµ°ì§‘í™”í•˜ì—¬ ê³„ì¸µì ì¸ êµ¬ì¡°ë¥¼ í˜•ì„±<br>
â–£ í•„ìš”ì„±: ë°ì´í„°ì˜ ì†ì„±ì´ ì£¼ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰<br>
â–£ ì¥ì : ìˆ˜ì¹˜í˜• ë°ì´í„°ì™€ ë²”ì£¼í˜• ë°ì´í„° ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©° ì ì§„ì  í•™ìŠµì´ ê°€ëŠ¥í•˜ì—¬ ì‹¤ì‹œê°„ ë°ì´í„°ì— ì í•©<br>
â–£ ë‹¨ì : ë°ì´í„° ì…ë ¥ ìˆœì„œì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©° ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ë–¨ì–´ì§€ê³  ë§¤ê°œë³€ìˆ˜ ì„¤ì •ì´ ì–´ë µë‹¤<br>
â–£ ì‘ìš©ë¶„ì•¼: ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„, ìœ ì „ì ë° ìƒë¬¼í•™ì  ë°ì´í„° ë¶„ì„, ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: COBWEBì˜ Category Utilityë¥¼ ë³€í˜•í•˜ì—¬ ìˆ˜ì¹˜í˜• ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì–´ í‰ê·  ë° ë¶„ì‚°ì„ ê¸°ë°˜ìœ¼ë¡œ êµ°ì§‘ì˜ ê²½ê³„ë¥¼ ì •ì˜í•˜ì—¬ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import AgglomerativeClustering
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# ê³„ì¸µì  êµ°ì§‘í™” ëª¨ë¸ ì„¤ì • (CLASSITì˜ ì¦ë¶„ í•™ìŠµì„ ë°˜ì˜í•œ ê°„ë‹¨í•œ ê³„ì¸µì  êµ°ì§‘í™”)
	agglomerative_clustering = AgglomerativeClustering(n_clusters=3, linkage='ward')
	predicted_labels = agglomerative_clustering.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(3):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("CLASSIT-like Hierarchical Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/5-3.PNG)
<br>

# [5-4] SOMs(Self-Organizing Maps)
â–£ ì •ì˜: ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›(ì£¼ë¡œ 2D) ê³µê°„ì— ë§¤í•‘í•˜ì—¬ ì‹œê°í™”í•˜ëŠ” ì‹ ê²½ë§ ê¸°ë°˜ì˜ êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì…ë ¥ ë°ì´í„° ê°„ì˜ ê´€ê³„ë¥¼ ë³´ì¡´í•˜ë©°, ë¹„ì§€ë„ í•™ìŠµìœ¼ë¡œ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ í•™ìŠµ<br>
â–£ í•„ìš”ì„±: ê³ ì°¨ì› ë°ì´í„°ì˜ ì‹œê°í™”ê°€ í•„ìš”í•  ë•Œ ìœ ìš©í•˜ë©°, ë°ì´í„°ì˜ ë¶„í¬ ë° êµ¬ì¡°ë¥¼ ì´í•´í•˜ëŠ” ë° ì‚¬ìš©<br>
â–£ ì¥ì : ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™”í•  ìˆ˜ ìˆìœ¼ë©° ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ì—¬ íŒ¨í„´ì„ ì¸ì‹í•˜ê¸°ì— ìœ ë¦¬<br>
â–£ ë‹¨ì : í•™ìŠµë¥ , ì´ì›ƒ í¬ê¸° ë“±ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ê¸°ê°€ ì–´ë µê³  ëª…í™•í•œ êµ°ì§‘í™”ë³´ë‹¤ëŠ” ë°ì´í„° ë§µì„ ìƒì„±í•˜ì—¬ êµ°ì§‘ì˜ ê²½ê³„ê°€ ëª¨í˜¸<br>
â–£ ì‘ìš©ë¶„ì•¼: ë°ì´í„° ì‹œê°í™” ë° ì°¨ì› ì¶•ì†Œ, ì´ë¯¸ì§€ ë° íŒ¨í„´ ì¸ì‹, ì‹œì¥ ë¶„ì„ ë° ì†Œë¹„ì í–‰ë™ ë¶„ì„<br>
â–£ ëª¨ë¸ì‹: ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì…ë ¥ ë²¡í„°ì— ê°€ì¥ ê°€ê¹Œìš´ ë…¸ë“œ(ìœ„ë„ˆ)ë¥¼ ì°¾ê³ , ê·¸ ì£¼ë³€ ë…¸ë“œë“¤ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•˜ëŠ” ë°©ì‹<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	class SimpleSOM:
	    def __init__(self, x_size=10, y_size=10, input_len=4, sigma=1.0, learning_rate=0.5, iterations=100):
	        self.x_size = x_size
	        self.y_size = y_size
	        self.input_len = input_len
	        self.sigma = sigma
	        self.learning_rate = learning_rate
	        self.iterations = iterations
	        self.weights = np.random.rand(x_size, y_size, input_len)
	
	    def _neighborhood_function(self, distance, iteration):
	        # ì´ì›ƒ ì˜í–¥ ë°˜ê²½ ê³„ì‚°
	        return np.exp(-distance / (2 * (self.sigma * (1 - iteration / self.iterations)) ** 2))
	
	    def _learning_rate_decay(self, iteration):
	        # í•™ìŠµë¥  ê°ì†Œ
	        return self.learning_rate * (1 - iteration / self.iterations)
	
	    def train(self, data):
	        for iteration in range(self.iterations):
	            for x in data:
	                # ìµœì ì˜ BMU ì°¾ê¸°
	                bmu_idx = self.find_bmu(x)
	                bmu_distance = np.array([[np.linalg.norm(np.array([i, j]) - bmu_idx) for j in range(self.y_size)] for i in range(self.x_size)])
	                
	                # ì´ì›ƒ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
	                learning_rate = self._learning_rate_decay(iteration)
	                neighborhood = self._neighborhood_function(bmu_distance, iteration)
	                self.weights += learning_rate * neighborhood[:, :, np.newaxis] * (x - self.weights)
	
	    def find_bmu(self, x):
	        # ì…ë ¥ ë²¡í„°ì— ê°€ì¥ ê°€ê¹Œìš´ BMU(ê°€ì¤‘ì¹˜)ë¥¼ ì°¾ìŒ
	        distances = np.linalg.norm(self.weights - x, axis=2)
	        return np.unravel_index(np.argmin(distances), (self.x_size, self.y_size))
	
	    def map_vects(self, data):
	        # ë°ì´í„° í¬ì¸íŠ¸ë“¤ì„ SOM ë§µì— ë§¤í•‘
	        return np.array([self.find_bmu(x) for x in data])
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# SOM ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ
	som = SimpleSOM(x_size=10, y_size=10, input_len=data.shape[1], sigma=1.0, learning_rate=0.5, iterations=100)
	som.train(data)
	
	# ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ BMU ì°¾ê¸°
	bmu_indices = som.map_vects(data)
	bmu_labels = np.ravel_multi_index(bmu_indices.T, (10, 10))  # BMUë¥¼ 1D ë ˆì´ë¸”ë¡œ ë³€í™˜
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = bmu_labels
	
	# Silhouette Score ê³„ì‚°
	# Silhouette ScoreëŠ” êµ°ì§‘ì˜ ì¼ê´€ì„±ì„ í‰ê°€í•˜ë©°, ê°’ì´ ë†’ì„ìˆ˜ë¡ êµ°ì§‘ì´ ì˜ ë¶„ë¦¬ë¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
	silhouette_avg = silhouette_score(data, bmu_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	# SOMì˜ êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì€ ë§¤ì¹­ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê° êµ°ì§‘ì— ëŒ€í•´ ê°€ì¥ ë¹ˆë„ ë†’ì€ ì‹¤ì œ ë ˆì´ë¸”ì„ ì°¾ìŠµë‹ˆë‹¤.
	mapped_labels = np.zeros_like(bmu_labels)
	for i in np.unique(bmu_labels):
	    mask = (bmu_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Self-Organizing Maps (SOM) Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()
	
![](./images/5-4.PNG)
<br>

# [5-5] GMM(Gaussian Mixture Model)
â–£ ì •ì˜ : ì—¬ëŸ¬ ê°€ìš°ì‹œì•ˆ ë¶„í¬(Gaussian Distribution)ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ëª¨ë¸ë§í•˜ê³ , ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ê° ë¶„í¬ì— ì†í•  í™•ë¥ ì„ ê³„ì‚°í•˜ëŠ” êµ°ì§‘í™” ë°©ë²•<br>
â–£ í•„ìš”ì„± : ë³µì¡í•œ ë°ì´í„° ë¶„í¬ë¥¼ ìœ ì—°í•˜ê²Œ ëª¨ë¸ë§í•˜ì—¬ êµ°ì§‘ ê²½ê³„ë¥¼ í™•ë¥ ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒ<br>
â–£ ì¥ì  : ë°ì´í„°ê°€ ì—¬ëŸ¬ ë¶„í¬ë¥¼ ë”°ë¥¼ ë•Œ ì í•©í•˜ë©°, êµ°ì§‘ ê°„ì˜ ê²½ê³„ê°€ í™•ë¥ ì ìœ¼ë¡œ ì²˜ë¦¬<br>
â–£ ë‹¨ì  : ì´ˆê¸°í™”ì— ë¯¼ê°í•˜ê³  ê³„ì‚° ë¹„ìš©ì´ ë†’ìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼ : íŒ¨í„´ ì¸ì‹, ì´ë¯¸ì§€ ì„¸ë¶„í™”<br>
â–£ ëª¨ë¸ì‹ : $Ï€_k$ëŠ” ê°€ìš°ì‹œì•ˆì˜ ê°€ì¤‘ì¹˜, $ğœ‡_ğ‘˜$, $Î£_ğ‘˜$ëŠ” ê°ê° í‰ê· ê³¼ ê³µë¶„ì‚°<br>
![](./images/GMM.PNG)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.mixture import GaussianMixture
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# GMM ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ
	gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)
	predicted_labels = gmm.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(3):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Gaussian Mixture Model (GMM) Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/5-5.PNG)
<br>

---

# [6-1] Spectral Clustering
â–£ ì •ì˜ : ê·¸ë˜í”„ ì´ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ì˜ ìœ ì‚¬ë„ í–‰ë ¬(Similarity Matrix)ì„ ì‚¬ìš©í•´ ì €ì°¨ì› ê³µê°„ì—ì„œ êµ°ì§‘ì„ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜<br>
â–£ í•„ìš”ì„± : ë³µì¡í•œ êµ¬ì¡°ë¥¼ ê°€ì§„ ë°ì´í„°ì—ì„œ ë¹„ì„ í˜•ì ì¸ ê²½ê³„ë¥¼ ì •ì˜í•  ìˆ˜ ìˆëŠ” êµ°ì§‘í™” ë°©ë²•ì´ í•„ìš”í•  ë•Œ ìœ ìš©<br>
â–£ ì¥ì  : ë¹„ì„ í˜•ì ì¸ ë°ì´í„°ì—ë„ ìœ ìš©í•˜ë©°, ì „í†µì ì¸ êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ë³µì¡í•œ ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬ ê°€ëŠ¥<br>
â–£ ë‹¨ì  : ìœ ì‚¬ë„ í–‰ë ¬ì„ ê³„ì‚°í•´ì•¼ í•˜ë¯€ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í¬ê³ , ëŒ€ê·œëª¨ ë°ì´í„°ì— ë¹„íš¨ìœ¨ì <br>
â–£ ì‘ìš©ë¶„ì•¼ : ì´ë¯¸ì§€ ë¶„í• , ë„¤íŠ¸ì›Œí¬ ë¶„ì„<br>
â–£ ëª¨ë¸ì‹ : ğ¿ì€ ë¼í”Œë¼ì‹œì•ˆ í–‰ë ¬, ğ·ëŠ” ëŒ€ê° í–‰ë ¬(ê° ë…¸ë“œì˜ ì°¨ìˆ˜), ğ´ëŠ” ì¸ì ‘ í–‰ë ¬(ì´ ë¼í”Œë¼ì‹œì•ˆ í–‰ë ¬ì˜ ê³ ìœ ë²¡í„°ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ êµ°ì§‘í™”)<br>
$ğ¿=ğ·âˆ’ğ´$<br>

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import SpectralClustering
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# Spectral Clustering ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ
	spectral_clustering = SpectralClustering(n_clusters=3, affinity='nearest_neighbors', random_state=0)
	predicted_labels = spectral_clustering.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤í•‘í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(3):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Spectral Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/6-1.PNG)
<br>

# [6-2] ì¹œí™”ë„ ì „íŒŒ(Affinity Propagation)
â–£ ì •ì˜ : ë°ì´í„° ê°„ì˜ ìœ ì‚¬ë„(similarity) í–‰ë ¬ì„ ì‚¬ìš©í•´ ê°€ì¥ ì í•©í•œ ì¤‘ì‹¬(exemplar)ì„ ì„ íƒí•˜ì—¬ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜<br>
â–£ í•„ìš”ì„± : êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ ì •í•  í•„ìš” ì—†ì´ ë°ì´í„°ì˜ ìœ ì‚¬ë„ì— ê¸°ë°˜í•´ ìì—°ìŠ¤ëŸ½ê²Œ êµ°ì§‘ì„ ì°¾ì„ ìˆ˜ ìˆìŒ<br>
â–£ ì¥ì  : êµ°ì§‘ ê°œìˆ˜ë¥¼ ì‚¬ì „ì— ì •ì˜í•  í•„ìš” ì—†ìœ¼ë©°, ìœ ì‚¬ë„ì— ê¸°ë°˜í•œ êµ°ì§‘í™”ë¡œ êµ°ì§‘ ê²½ê³„ê°€ ë” ëª…í™•í•  ìˆ˜ ìˆìŒ<br>
â–£ ë‹¨ì  : ê³„ì‚° ë¹„ìš©ì´ í¬ê³  í° ë°ì´í„°ì…‹ì—ì„œëŠ” ëŠë¦´ ìˆ˜ ìˆìŒ<br>
â–£ ì‘ìš©ë¶„ì•¼ : ì´ë¯¸ì§€ ë¶„í• , ë¬¸ì„œ ë¶„ë¥˜<br>
â–£ ëª¨ë¸ì‹: ê° ë°ì´í„° í¬ì¸íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ğ‘ (ğ‘–,ğ‘˜)ì™€ ì±…ì„ ğ‘Ÿ(ğ‘–,ğ‘˜), ê°€ìš©ë„ ğ‘(ğ‘–,ğ‘˜)ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê³„ì‚°í•´ ì¤‘ì‹¬ì ì„ ê²°ì •<br>
![](./images/AP.PNG)

	import numpy as np
	from sklearn.datasets import load_iris
	from sklearn.cluster import AffinityPropagation
	from sklearn.metrics import silhouette_score, accuracy_score
	import matplotlib.pyplot as plt
	import seaborn as sns
	import pandas as pd
	from scipy.stats import mode
	
	# Iris ë°ì´í„°ì…‹ ë¡œë“œ
	iris = load_iris()
	data = iris.data
	true_labels = iris.target
	
	# Affinity Propagation ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ
	affinity_propagation = AffinityPropagation(random_state=0)
	predicted_labels = affinity_propagation.fit_predict(data)
	
	# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™” ì¤€ë¹„
	df = pd.DataFrame(data, columns=iris.feature_names)
	df['Cluster'] = predicted_labels
	
	# Silhouette Score ê³„ì‚°
	silhouette_avg = silhouette_score(data, predicted_labels)
	print(f"Silhouette Score: {silhouette_avg:.3f}")
	
	# Accuracy ê³„ì‚° (êµ°ì§‘ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì„ ë§¤í•‘í•˜ì—¬ ì •í™•ë„ ê³„ì‚°)
	mapped_labels = np.zeros_like(predicted_labels)
	for i in range(len(np.unique(predicted_labels))):
	    mask = (predicted_labels == i)
	    mapped_labels[mask] = mode(true_labels[mask])[0]
	
	accuracy = accuracy_score(true_labels, mapped_labels)
	print(f"Accuracy: {accuracy:.3f}")
	
	# ì‹œê°í™” (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í”¼ì²˜ ì‚¬ìš©)
	plt.figure(figsize=(10, 5))
	sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue='Cluster', data=df, palette='viridis', s=100)
	plt.title("Affinity Propagation Clustering on Iris Dataset")
	plt.xlabel(iris.feature_names[0])  # ì²« ë²ˆì§¸ í”¼ì²˜ (sepal length)
	plt.ylabel(iris.feature_names[1])  # ë‘ ë²ˆì§¸ í”¼ì²˜ (sepal width)
	plt.legend(title='Cluster')
	plt.show()

![](./images/6-2.PNG)
<br>

![](./images/CA.PNG)
<br>

**êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ ë¹„êµ(scikit-learn)** 
https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py%20%EC%B6%9C%EC%B2%98:%20https://rfriend.tistory.com/587%20[R,%20Python%20%EB%B6%84%EC%84%9D%EA%B3%BC%20%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D%EC%9D%98%20%EC%B9%9C%EA%B5%AC%20(by%20R%20Friend):%ED%8B%B0%EC%8A%A4%ED%86%A0%EB%A6%AC]







