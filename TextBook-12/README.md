
![](./images/NSML.png)


![](./images/SML.png)


#  12-1 : íšŒê·€ í‰ê°€ ì§€í‘œ

---

	[1] í‰ê·  ì˜¤ì°¨ (Mean Error, ME)
 	[2] í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (Mean Absolute Error, MAE)
	[3] í‰ê·  ì œê³± ì˜¤ì°¨ (Mean Squared Error, MSE)
	[4] í‰ê·  ì œê³± ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Mean Squared Log Error, MSLE)
	[5] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (Root Mean Squared Error, RMSE)
	[6] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Root Mean Squared Log Error, RMSLE)
 	[7] í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (Mean Percentage Error, MPE)
	[8] í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (Mean Absolute Percentage Error, MAPE)
	[9] í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (Mean Absolute Scaled Error, MASE)
	[10] R2 score
	  
---

# [1] í‰ê·  ì˜¤ì°¨ (Mean Error, ME)
![](./images/ME.svg)
<br>
â–£ ì •ì˜: ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´ë¥¼ í‰ê· ë‚¸ ê°’ìœ¼ë¡œ, ì˜¤ì°¨ì˜ ë°©í–¥ì„±ì„ í¬í•¨í•œ ì˜ˆì¸¡ì˜¤ì°¨ì˜ ì‚°ìˆ í‰ê· ì„ ì˜ë¯¸<br>
â–£ í•„ìš”ì„±: ì˜¤ì°¨ê°€ ì–‘ìˆ˜ì¸ì§€ ìŒìˆ˜ì¸ì§€, í‰ê· ì ìœ¼ë¡œ ê³¼ëŒ€í‰ê°€ ë˜ëŠ” ê³¼ì†Œí‰ê°€ë˜ëŠ”ì§€ë¥¼ íŒŒì•…<br>
â–£ ì¥ì : ì˜¤ì°¨ì˜ ë°©í–¥ì„±ì„ ë°˜ì˜í•˜ì—¬ ëª¨ë¸ì˜ í¸í–¥(bias)ì„ ë¶„ì„<br>
â–£ ë‹¨ì : ì–‘ìˆ˜ì™€ ìŒìˆ˜ê°€ ìƒì‡„ë˜ë¯€ë¡œ, ì‹¤ì œ ì˜¤ì°¨ì˜ í¬ê¸°ë¥¼ íŒë‹¨í•˜ê¸° ì–´ë µë‹¤<br>

	def ME(y_true, y_pred):
		return (y_true - y_pred).mean(axis=None)

<br>

# [2] í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (Mean Absolute Error, MAE)
![](./images/MAE.svg)
<br>
â–£ ì •ì˜: ì‹¤ì œ ì •ë‹µ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ ì°¨ì´ë¥¼ ì ˆëŒ“ê°’ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ í•©ì‚°í•˜ì—¬ í‰ê· ì„ êµ¬í•œë‹¤.<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì˜ í‰ê· ì ì¸ ì˜ˆì¸¡ ì˜¤ì°¨ í¬ê¸°ë¥¼ ì§ê´€ì ìœ¼ë¡œ íŒŒì•…, íŠ¹ì´ê°’ì´ ë§ì€ ê²½ìš°ì— ì£¼ë¡œ ì‚¬ìš©<br>
â–£ ì¥ì : ì§ê´€ì ì´ê³  ì •ë‹µ ë° ì˜ˆì¸¡ ê°’ê³¼ ê°™ì€ ë‹¨ìœ„ë¥¼ ê°€ì§€ê³ , MSE, RMSEì— ë¹„í•´ ê·¹ë‹¨ê°’(outlier)ì— ëœ ë¯¼ê°<br>
â–£ ë‹¨ì : ì ˆëŒ“ê°’ì„ ì·¨í•˜ë¯€ë¡œ underestimates/overestimatesì¸ì§€ì— ëŒ€í•œ íŒë‹¨ì„ í•  ìˆ˜ ì—†ìœ¼ë©°, ìŠ¤ì¼€ì¼ ì˜ì¡´ì (scal dependency)ìœ¼ë¡œ ëª¨ë¸ë§ˆë‹¤ ì—ëŸ¬ í¬ê¸°ê°€ ë™ì¼í•´ë„ ì—ëŸ¬ìœ¨ì€ ë™ì¼í•˜ì§€ ì•Šê³ , ì˜¤ì°¨ì˜ ë°©í–¥ì„±ì„ ì•Œ ìˆ˜ ì—†ë‹¤<br>

	def MAE(y_true, y_pred):
    	return (abs(y_true - y_pred)).mean(axis=None)

<br>

	from sklearn.metrics import mean_absolute_error
	
	mae = mean_absolute_error(y_true, y_pred)
   
<br>

# [3] í‰ê·  ì œê³± ì˜¤ì°¨ (Mean Squared Error, MSE)
![](./images/MSE.svg)
<br>
â–£ ì •ì˜: ì‹¤ì œ ì •ë‹µ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ ì°¨ì´ë¥¼ ì œê³±(ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì°¨ì´ì˜ ë©´ì )í•œ ë’¤ í‰ê· ì„ êµ¬í•œë‹¤.<br>
â–£ í•„ìš”ì„±: ì˜¤ì°¨ì˜ í¬ê¸°ë¥¼ ê°•ì¡°í•´ í° ì˜¤ì°¨ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘<br>
â–£ ì¥ì : ì§ê´€ì ì´ë©°, ëª¨ë¸ì˜ í° ì˜¤ì°¨ë¥¼ ë” ì˜ ì‹ë³„ ê°€ëŠ¥<br>
â–£ ë‹¨ì : ì˜ˆì¸¡ ë³€ìˆ˜ì™€ ë‹¨ìœ„ê°€ ë‹¤ë¥´ë©°, ì˜¤ì°¨ë¥¼ ì œê³±í•˜ê¸° ë•Œë¬¸ì— ì´ìƒì¹˜ì— ë¯¼ê°(ì œê³±í•˜ê¸° ë•Œë¬¸ì— 1ë¯¸ë§Œì˜ ì—ëŸ¬ëŠ” ì‘ì•„ì§€ê³  ê·¸ ì´ìƒì˜ ì—ëŸ¬ëŠ” ì»¤ì§), ì œê³±ì„ ì”Œìš°ê²Œ ë˜ì–´ underestimates/overestimatesì¸ì§€ íŒŒì•…í•˜ê¸° í˜ë“¤ë©°, ìŠ¤ì¼€ì¼ ì˜ì¡´ì (scal dependency)ì´ë¼ ëª¨ë¸ë§ˆë‹¤ ì—ëŸ¬ëŸ¬ í¬ê¸°ê°€ ë™ì¼í•´ë„ ì—ëŸ¬ìœ¨ì€ ë™ì¼í•˜ì§€ ì•Šì€ ë‹¨ì . ì˜¤ì°¨ì œê³±í•©(SSE)ì™€ ìœ ì‚¬í•˜ì§€ë§Œ ì˜¤ì°¨ì œê³±í•©ìœ¼ë¡œëŠ” ì‹¤ì œ ì˜¤ì°¨ê°€ ì»¤ì„œ ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì¸ì§€ ë°ì´í„°ì˜ ì–‘ì´ ë§ì•„ì„œ ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì¸ì§€ë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ê²Œ ëœë‹¤.<br>

	def MSE(y_true, y_pred):
    	return ((y_true - y_pred)**2).mean(axis=None)

<br>

	from sklearn.metrics import mean_squared_error
	
	mse = mean_squared_error(y_true, y_pred)

<br>

# [4] í‰ê·  ì œê³± ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Mean Squared Log Error, MSLE)
![](./images/MSLE.svg)
<br>
â–£ ì •ì˜: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ ë¡œê·¸ ì°¨ì´ì— ëŒ€í•œ ì œê³± í‰ê· ìœ¼ë¡œ MSEì— ë¡œê·¸ë¥¼ ì ìš©<br> 
â–£ í•„ìš”ì„±: ì‘ì€ ê°’ì˜ ìƒëŒ€ì ì¸ ì°¨ì´ë¥¼ ê°•ì¡°í•˜ë©° í° ê°’ì˜ ì°¨ì´ë¥¼ ì™„í™”<br>
â–£ ì¥ì : ì‘ì€ ê°’ì— ì§‘ì¤‘í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì— ì í•©(ê²°ì • ê°’ì´ í´ìˆ˜ë¡ ì˜¤ë¥˜ê°’ë„ ì»¤ì§€ê¸° ë•Œë¬¸ì— ì¼ë¶€ í° ì˜¤ë¥˜ê°’ë“¤ë¡œ ì¸í•´ ì „ì²´ ì˜¤ë¥˜ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤)<br>
â–£ ë‹¨ì : ë¡œê·¸ ì—°ì‚°ìœ¼ë¡œ ì¸í•´ ìŒìˆ˜ ê°’ì€ ì²˜ë¦¬ ë¶ˆê°€ëŠ¥<br>

	def MSLE(y_true, y_pred):
		return np.log((y_true - y_pred)**2).mean(axis=None)

<br>

	from sklearn.metrics import mean_squared_log_error

	msle = mean_squared_log_error(y_true, y_pred)

<br>

# [5] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (Root Mean Squared Error, RMSE)
![](./images/RMSE.svg)
<br>
â–£ ì •ì˜: MSEì˜ ì œê³±ê·¼ìœ¼ë¡œ, ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ê°„ì˜ í‰ê· ì  ì°¨ì´ë¥¼ ì› ë‹¨ìœ„ë¡œ í™˜ì‚°<br>
â–£ í•„ìš”ì„±: ë‹¨ìœ„ë¥¼ ì‹¤ì œ ë°ì´í„°ì™€ ë™ì¼í•˜ê²Œ ì¡°ì •<br>
â–£ ì¥ì : í•´ì„ì´ ì‰¬ìš°ë©°, í° ì˜¤ì°¨ë¥¼ ê°•ì¡°(MSEì— ë£¨íŠ¸ëŠ” ì”Œì›Œì„œ ì—ëŸ¬ë¥¼ ì œê³±í•´ì„œ ìƒê¸°ëŠ” ê°’ì˜ ì™œê³¡ì´ ì¤„ì–´ë“ ë‹¤)<br>
â–£ ë‹¨ì : ê·¹ë‹¨ê°’ì— ë¯¼ê°í•˜ê³ , ì œê³± í›„ ë£¨íŠ¸ë¥¼ ì”Œìš°ê¸° ë•Œë¬¸ì— MAEì²˜ëŸ¼ ì‹¤ì œ ê°’ì— ëŒ€í•´ underestimates/overestimatesì¸ì§€ íŒŒì•…í•˜ê¸° í˜ë“¤ê³ , ìŠ¤ì¼€ì¼ ì˜ì¡´ì (scal dependency)ìœ¼ë¡œ ëª¨ë¸ë§ˆë‹¤ ì—ëŸ¬ í¬ê¸°ê°€ ë™ì¼í•´ë„ ì—ëŸ¬ìœ¨ì€ ë™ì¼í•˜ì§€ ì•Šì€ ë‹¨ì <br>

	def RMSE(y_true, y_pred):
		return np.sqrt(((y_true - y_pred) ** 2).mean(axis=None))

<br>

# [6] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Root Mean Squared Log Error, RMSLE)
![](./images/RMSLE.svg)
<br>
â–£ ì •ì˜: MSLEì˜ ì œê³±ê·¼ ê°’ìœ¼ë¡œ, ë¡œê·¸ ì°¨ì´ë¥¼ ì› ë‹¨ìœ„ë¡œ í™˜ì‚°í•œ ê°’ìœ¼ë¡œ RMSEê°’ì— ë¡œê·¸ë¥¼ ì·¨í•œ ê°’<br>
â–£ í•„ìš”ì„±: ì‘ì€ ê°’ì˜ ìƒëŒ€ì  ì°¨ì´ë¥¼ í‰ê°€<br>
â–£ ì¥ì : ìƒëŒ€ì  ì˜¤ì°¨ì— ê°•ì (ê²°ì • ê°’ì´ í´ ìˆ˜ë¡ ì˜¤ë¥˜ ê°’ë„ ì»¤ì§€ê¸° ë•Œë¬¸ì— ì¼ë¶€ í° ì˜¤ë¥˜ ê°’ë“¤ë¡œì¸í•´ ì „ì²´ ì˜¤ë¥˜ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤)<br>
â–£ ë‹¨ì : ìŒìˆ˜ ê°’ ë¶ˆê°€<br>

	def RMSLE(y_true, y_pred):
		return np.log(np.sqrt(((y_true - y_pred) ** 2).mean(axis=None)))

<br>

# [7] í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (Mean Percentage Error, MPE)
![](./images/MPE.svg)
<br>
â–£ ì •ì˜: ì˜¤ì°¨ë¥¼ ì‹¤ì œê°’ì— ëŒ€í•œ ë°±ë¶„ìœ¨ë¡œ ê³„ì‚°í•´ í‰ê· <br>
â–£ í•„ìš”ì„±: ì˜ˆì¸¡ ì˜¤ì°¨ì˜ ë°©í–¥ì„±ê³¼ ë°±ë¶„ìœ¨ í¬ê¸°ë¥¼ íŒŒì•…, ì ˆëŒ€ì ì¸ ì˜ë¯¸ì˜ ì˜ˆì¸¡ì˜¤ì°¨ë¿ ì•„ë‹ˆë¼ ìƒëŒ€ì ì¸ ì˜ë¯¸ì˜ ì˜ˆì¸¡ì˜¤ì°¨ê°€ í•„ìš”í•  ê²½ìš°ì— ê³„ì‚°<br>
â–£ ì¥ì : ìƒëŒ€ì  í¬ê¸° ë¹„êµ ê°€ëŠ¥(ìŒìˆ˜ë©´ overperformance, ì–‘ìˆ˜ë©´ underperformanceìœ¼ë¡œ íŒë‹¨), ëª¨ë¸ì´ underestimates/overestimatesì¸ì§€ íŒë‹¨í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì <br>
â–£ ë‹¨ì : ì‹¤ì œê°’ì´ 0ì¼ ë•Œ ê³„ì‚° ë¶ˆê°€<br>

	def MPE(y_true, y_pred):
		return (((y_true - y_pred)/y_true)*100).mean(axis=None)

<br>

# [8] í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (Mean Absolute Percentage Error, MAPE)
![](./images/MAPE.svg)
<br>
â–£ ì •ì˜: ì ˆëŒ€ ì˜¤ì°¨ë¥¼ ë°±ë¶„ìœ¨ë¡œ ê³„ì‚°í•´ í‰ê· (MAEë¥¼ ë¹„ìœ¨, í¼ì„¼íŠ¸ë¡œ í‘œí˜„í•˜ì—¬ ìŠ¤ì¼€ì¸ ì˜ì¡´ì  ì—ëŸ¬ì˜ ë¬¸ì œì ì„ ê°œì„ )<br>
â–£ í•„ìš”ì„±: ì˜¤ì°¨ë¥¼ ìƒëŒ€ì ìœ¼ë¡œ í‰ê°€<br>
â–£ ì¥ì  : ì§ê´€ì ì´ê³ , ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì—ëŸ¬ìœ¨ ë¹„êµê°€ ì‰¬ìš´ ì¥ì <br>
â–£ ë‹¨ì : 0ê°’ ë¬¸ì œì™€ ê·¹ë‹¨ê°’ì— ë¯¼ê°(ì‹¤ì œ ì •ë‹µë³´ë‹¤ ë‚®ê²Œ ì˜ˆì¸¡í–ˆëŠ”ì§€, ë†’ê²Œ í–ˆëŠ”ì§€ë¥¼ íŒŒì•…í•˜ê¸° í˜ë“¤ê³  ì‹¤ì œ ì •ë‹µì´ 1ë³´ë‹¤ì‘ì„ ê²½ìš°,ë¬´í•œëŒ€ì˜ ê°’ìœ¼ë¡œ ìˆ˜ë ´)<br>

	def MAPE(y_true, y_pred):
		return ((abs((y_true - y_pred)/y_true))*100).mean(axis=None)

<br>
	
	from sklearn.metrics import mean_absolute_percentage_error
	
	mape = mean_absolute_percentage_error(y_true, y_pred)

<br>

# [9] í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (Mean Absolute Scaled Error, MASE)
<!-- ![](./images/MASE.svg) ![](./images/MASE1.svg) -->
![](./images/[9].png)
<br>
â–£ ì •ì˜: ì˜ˆì¸¡ê°’ì˜ ì˜¤ì°¨ë¥¼ ê¸°ì¤€ ì‹œì ì˜ ì˜¤ì°¨ì™€ ë¹„êµí•˜ì—¬ ë¹„ìœ¨í™”(ë°ì´í„°ë¥¼ ì²™ë„í™”í•˜ì—¬ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ì˜¤ì°¨ì˜ ì ˆëŒ€ê°’ì— ëŒ€í•œ í‰ê· )<br>
â–£ í•„ìš”ì„±: ë°ì´í„°ì— ë”°ë¼ ìœ ì—°í•œ í‰ê°€ ê°€ëŠ¥<br>
â–£ ì¥ì : ìŠ¤ì¼€ì¼ì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë‚®ì•„ì„œ ì•ˆì •ì ìœ¼ë¡œ ë¹„êµ ê°€ëŠ¥<br>
â–£ ë‹¨ì : í•´ì„ì´ ìƒëŒ€ì ìœ¼ë¡œ ì–´ë µë‹¤<br>

	def MASE(y_true, y_pred):
    	mae = np.mean(np.abs(y_true - y_pred))
    	naive_mae = np.mean(np.abs(y_true[1:] - y_true[:-1]))
    	return mae / naive_mae

	mase = MASE(y_true, y_pred)

<br>

# [10] R2 score
â–£ ì •ì˜: ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œë¡œ **SST(Total Sum of Squares)** ê´€ì¸¡ê°’ì—ì„œ ê´€ì¸¡ê°’ì˜ í‰ê· (í˜¹ì€ ì¶”ì •ì¹˜ì˜ í‰ê· )ì„ ëº€ ê²°ê³¼ì˜ ì´í•©ì¸ ì´ ì œê³±í•©<br>
â–£ í•„ìš”ì„±: ì „ì²´(Total)ì— ëŒ€í•œ ë³€ë™ì„±ì„ ë‚˜íƒ€ëƒ„ìœ¼ë¡œì¨ ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ íŒŒì•…<br>
â–£ ì¥ì : ì§ê´€ì <br>
â–£ ë‹¨ì : ëª¨ë¸ì´ ìµœì†Œí•œì˜ ê¸°ì¤€ë„ ë§Œì¡±í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ëŠ” ìŒìˆ˜ê°€ ë  ìˆ˜ ìˆìŒ<br>
![](./images/f_R2.png)
<br>
![](./images/ff_SST.png)
<br>


	from sklearn.metrics import r2_score

	r2 = r2_score(y_true, y_pred)





![](./images/SST.png)
<br>
ì¶œì²˜ : https://medium.com/coders-mojo/data-science-and-machine-learning-projects-mega-compilation-part-5-e50baa2faa85<br>

## SST(Total Sum of Squares) : ì´ ë³€ë™
â–£ ì •ì˜ : ë°ì´í„°ì˜ ì´ ë³€ë™ëŸ‰ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œë¡œ, ì‹¤ì œê°’($ğ‘¦_ğ‘–$)ê³¼ í‰ê· ê°’($\overline{y}$) ê°„ì˜ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í•©í•œ ê°’ìœ¼ë¡œ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ë¶„ì‚°ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„<br>
â–£ í•„ìš”ì„± : íšŒê·€ ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ê¸°ì¤€ì„ ì´ ë˜ê³ , ëª¨ë¸ ì—†ì´ë„ ë°ì´í„°ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë³€ë™ì„±ì„ ê³„ì‚°<br>
â–£ ì¥ì  : ë°ì´í„°ì˜ ì „ì²´ ë³€ë™ëŸ‰ì„ ëª…í™•íˆ ê³„ì‚°í•˜ì—¬ ëª¨ë¸ í‰ê°€ì˜ ê¸°ë³¸ ì²™ë„ê°€ ë˜ë©°, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ SSR, SSEì™€ í•¨ê»˜ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨<br>
â–£ ë‹¨ì  : ì‹¤ì œê°’ì˜ ë³€ë™ëŸ‰ë§Œ ì¸¡ì •í•  ë¿, ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ëŠ” ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ì´ ì—†ìœ¼ë©°, ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ì´ë‚˜ ë‹¨ìœ„ì— ë¯¼ê°í•˜ì—¬ í¬ê¸°ê°€ í¬ê²Œ ë³€í•  ìˆ˜ ìˆìŒ<br>
![](./images/f_SST.png)
<br>


## SSR(Sum of Squares due to Regression) : íšŒê·€ì— ì˜í•œ ë³€ë™
â–£ ì •ì˜ : ì˜ˆì¸¡ê°’(ğ‘¦^ğ‘–)ê³¼ í‰ê· ê°’($\overline{y}$)ì˜ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í•©í•œ ê°’ìœ¼ë¡œ ëª¨ë¸ì´ ì‹¤ì œ ë°ì´í„°ì˜ ë³€ë™ ì¤‘ì—ì„œ ì„¤ëª…í•œ ë³€ë™ëŸ‰ì„ ë‚˜íƒ€ëƒ„<br>
â–£ í•„ìš”ì„± : ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ë°ì´í„°ë¥¼ ì„¤ëª…í–ˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ì²™ë„ë¡œ, RÂ² Score ê³„ì‚°ì—ì„œ í•µì‹¬ ì—­í• ì„ í•˜ë©°, ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤Œ<br>
â–£ ì¥ì  : ëª¨ë¸ì´ ë°ì´í„° íŒ¨í„´ì„ ì–¼ë§ˆë‚˜ ì˜ íŒŒì•…í–ˆëŠ”ì§€ ëª…í™•íˆ ë‚˜íƒ€ë‚´ë©°, ğ‘†ğ‘†ğ‘…ì´ í´ìˆ˜ë¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ìš°ìˆ˜í•¨ì„ ì˜ë¯¸<br>
â–£ ë‹¨ì  : ë‹¨ë…ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ ê³¼ì í•© ì—¬ë¶€ë¥¼ í‰ê°€í•˜ê¸° ì–´ë µê³ , ë°ì´í„°ì— ì¡ìŒ(noise)ì´ ë§ì„ ê²½ìš° ì˜ëª»ëœ ì„¤ëª…ë ¥ì„ ì¸¡ì •<br>
![](./images/f_SSR.png)
<br>


## SSE(Sum of Squares Residual of Error) : ì”ì°¨ ì œê³±í•©
â–£ ì •ì˜ : ì‹¤ì œê°’($ğ‘¦_ğ‘–$)ê³¼ ì˜ˆì¸¡ê°’($\widehat{y_i}$)ì˜ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í•©í•œ ê°’ìœ¼ë¡œ ëª¨ë¸ì´ ì„¤ëª…í•˜ì§€ ëª»í•œ ë°ì´í„°ì˜ ë³€ë™ëŸ‰(ì”ì°¨)ì„ ë‚˜íƒ€ëƒ„<br>
â–£ í•„ìš”ì„± : ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ë©°, ì”ì°¨ ë¶„ì„ì„ í†µí•´ ëª¨ë¸ ê°œì„  ë°©í–¥ì„ ì œì‹œ<br>
â–£ ì¥ì  : ëª¨ë¸ì˜ í•œê³„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆìœ¼ë©°, SSEê°€ ì‘ì„ìˆ˜ë¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ìŒì„ ì˜ë¯¸<br>
â–£ ë‹¨ì  : SSEì˜ í¬ê¸°ê°€ ë°ì´í„°ì˜ í¬ê¸°ì™€ ë‹¨ìœ„ì— ë”°ë¼ í¬ê²Œ ë³€í•˜ë©°, ê·¹ë‹¨ê°’(outliers)ì— ë¯¼ê°í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì´ ì™œê³¡ë  ìˆ˜ ìˆìŒ<br>
![](./images/f_SSE.png)
<br>


![](./images/ff_R2.png)
<br>

---

**(íšŒê·€ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤)**

	# ============================================
	# Iris ë°ì´í„° ê¸°ë°˜ íšŒê·€ í‰ê°€ì§€í‘œ 10ê°œ + í•´ì„í‘œ ì¶œë ¥ ì½”ë“œ
	#  - íƒ€ê¹ƒ: sepal length (ì²« ë²ˆì§¸ ì»¬ëŸ¼)
	#  - íŠ¹ì§•: ë‚˜ë¨¸ì§€ 3ê°œ(sepal width, petal length, petal width)
	# ============================================
	import numpy as np	
	from sklearn.metrics import (
	    mean_absolute_error,
	    mean_squared_error,
	    mean_squared_log_error,
	    mean_absolute_percentage_error,
	    r2_score)
	from sklearn.linear_model import LinearRegression
	from sklearn.model_selection import train_test_split
	from sklearn.datasets import load_iris
		
	# ------------------------------------------------------------------
	# 1. ì‚¬ìš©ì ì •ì˜ í‰ê°€ì§€í‘œ í•¨ìˆ˜ë“¤
	# ------------------------------------------------------------------
	# [1] í‰ê·  ì˜¤ì°¨ (ME, Mean Error)
	def mean_error(y_true, y_pred):	    
	    y_true = np.asarray(y_true)
	    y_pred = np.asarray(y_pred)
	    return np.mean(y_true - y_pred)
	
	# [5] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE)
	def rmse(y_true, y_pred):	    
	    return np.sqrt(mean_squared_error(y_true, y_pred))

	# [6] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸ì ìš©) (RMSLE)	
	def rmsle(y_true, y_pred):
	    return np.sqrt(mean_squared_log_error(y_true, y_pred))
	
	# [7] í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (MPE, Mean Percentage Error)
	def mean_percentage_error(y_true, y_pred):
	    y_true = np.asarray(y_true)
	    y_pred = np.asarray(y_pred)
	    return np.mean((y_true - y_pred) / y_true)
	
	# [9] í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (MASE, Mean Absolute Scaled Error)
	#     ë³¸ë˜ëŠ” ì‹œê³„ì—´(time series)ì—ì„œ ë§ì´ ì‚¬ìš©
	#     ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¥¼ ìœ„í•´ ìƒ˜í”Œ ìˆœì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ naive forecast ì‚¬ìš©
	def mase(y_true, y_pred):
	    y_true = np.asarray(y_true)
	    y_pred = np.asarray(y_pred)
	    mae = np.mean(np.abs(y_true - y_pred))
	    # naive forecast: í•œ ì‹œì  ì „ ê°’(y_{t-1})ì„ ì˜ˆì¸¡ìœ¼ë¡œ ì‚¬ìš©
	    naive_mae = np.mean(np.abs(y_true[1:] - y_true[:-1]))
	    return mae / naive_mae
	
	# ------------------------------------------------------------------
	# 2. í•´ì„ í•¨ìˆ˜ë“¤ (ì¢‹ìŒ / ë³´í†µ / ë‚˜ì¨) + ê¸°ì¤€ ë¬¸ìì—´
	# ------------------------------------------------------------------
	CRITERIA_ERROR_RELATIVE = "ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨"
	CRITERIA_MSLE_RMSLE     = "RMSLE<0.1:ì¢‹ìŒ, 0.1â‰¤RMSLE<0.2:ë³´í†µ, RMSLEâ‰¥0.2:ë‚˜ì¨"
	CRITERIA_PERCENTAGE     = "|ì˜¤ì°¨|<10%:ì¢‹ìŒ, 10~20%:ë³´í†µ, 20% ì´ˆê³¼:ë‚˜ì¨"
	CRITERIA_MASE           = "MASE<1:ì¢‹ìŒ, 1â‰¤MASE<2:ë³´í†µ, MASEâ‰¥2:ë‚˜ì¨"
	CRITERIA_R2             = "R2â‰¥0.8:ì¢‹ìŒ, 0.5â‰¤R2<0.8:ë³´í†µ, R2<0.5:ë‚˜ì¨"
		
	def interpret_error_relative(value, scale):
	    if scale == 0: return "í‰ê°€ë¶ˆê°€"
	
	    ratio = abs(value) / scale  # ìƒëŒ€ì˜¤ì°¨ ë¹„ìœ¨	
	    if ratio < 0.25: return "ì¢‹ìŒ"
	    elif ratio < 0.5: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_msle_rmsle(rmsle_value):
	    if rmsle_value < 0.1: return "ì¢‹ìŒ"
	    elif rmsle_value < 0.2: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_percentage_metric(perc_value):
	    perc = abs(perc_value) * 100  # %	
	    if perc < 10: return "ì¢‹ìŒ"
	    elif perc < 20: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_mase(mase_value):
	    if mase_value < 1: return "ì¢‹ìŒ"
	    elif mase_value < 2: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_r2(r2_value):	
	    if r2_value >= 0.8: return "ì¢‹ìŒ"
	    elif r2_value >= 0.5: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# ------------------------------------------------------------------
	# 3. Iris ë°ì´í„° ë¡œë“œ ë° íšŒê·€ ë¬¸ì œë¡œ êµ¬ì„±
	# ------------------------------------------------------------------	
	iris = load_iris()
	X_all = iris.data  # shape: (150, 4) -> [sepal length, sepal width, petal length, petal width]
	
	# íƒ€ê¹ƒ: sepal length (0ë²ˆì§¸ ì»¬ëŸ¼)
	y = X_all[:, 0]
	
	# íŠ¹ì§•: ë‚˜ë¨¸ì§€ 3ê°œ (sepal width, petal length, petal width)
	X = X_all[:, 1:]   # shape: (150, 3)
	
	# train / test ë¶„í• 
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
	
	# ì„ í˜•íšŒê·€ ëª¨ë¸ í•™ìŠµ
	model = LinearRegression()
	model.fit(X_train, y_train)
	
	# ì˜ˆì¸¡ê°’
	y_pred = model.predict(X_test)
	
	# íƒ€ê¹ƒ ìŠ¤ì¼€ì¼(í‘œì¤€í¸ì°¨) ê³„ì‚° (ì˜¤ì°¨ ê³„ì—´ í•´ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©)
	y_std = np.std(y_test)
		
	# ------------------------------------------------------------------
	# 4. 10ê°œ í‰ê°€ì§€í‘œ ê³„ì‚°
	# ------------------------------------------------------------------
	# [1] ME
	ME = mean_error(y_test, y_pred)
	# [2] MAE
	MAE = mean_absolute_error(y_test, y_pred)
	# [3] MSE
	MSE = mean_squared_error(y_test, y_pred)
	# [4] MSLE
	MSLE = mean_squared_log_error(y_test, y_pred)
	# [5] RMSE
	RMSE = rmse(y_test, y_pred)
	# [6] RMSLE
	RMSLE = rmsle(y_test, y_pred)
	# [7] MPE
	MPE = mean_percentage_error(y_test, y_pred)
	# [8] MAPE
	MAPE = mean_absolute_percentage_error(y_test, y_pred)
	# [9] MASE
	MASE = mase(y_test, y_pred)
	# [10] R2 score
	R2 = r2_score(y_test, y_pred)
		
	# ------------------------------------------------------------------
	# 5. í•´ì„ í…Œì´ë¸” êµ¬ì„± (ì§€í‘œëª…, ê°’, í•´ì„, ê¸°ì¤€)
	# ------------------------------------------------------------------
	rows = []	
	rows.append(("[1] ME",ME,interpret_error_relative(ME, y_std), CRITERIA_ERROR_RELATIVE))
	rows.append(("[2] MAE",MAE,interpret_error_relative(MAE, y_std),CRITERIA_ERROR_RELATIVE))
	# MSEëŠ” ì œê³± ë‹¨ìœ„ì´ë¯€ë¡œ í•´ì„ì€ RMSE ê¸°ì¤€ ì‚¬ìš©
	rows.append(("[3] MSE",MSE,interpret_error_relative(np.sqrt(MSE), y_std), CRITERIA_ERROR_RELATIVE + " (RMSE ê¸°ì¤€)"))
	rows.append(("[4] MSLE",MSLE,interpret_msle_rmsle(np.sqrt(MSLE)), CRITERIA_MSLE_RMSLE))
	rows.append(("[5] RMSE",RMSE,interpret_error_relative(RMSE, y_std), CRITERIA_ERROR_RELATIVE))
	rows.append(("[6] RMSLE",RMSLE,interpret_msle_rmsle(RMSLE), CRITERIA_MSLE_RMSLE))
	rows.append(("[7] MPE",MPE,interpret_percentage_metric(MPE), CRITERIA_PERCENTAGE))
	rows.append(("[8] MAPE",MAPE,interpret_percentage_metric(MAPE), CRITERIA_PERCENTAGE))
	rows.append(("[9] MASE",MASE,interpret_mase(MASE), CRITERIA_MASE))
	rows.append(("[10] R2",R2,interpret_r2(R2), CRITERIA_R2))
		
	# ------------------------------------------------------------------
	# 6. ê²°ê³¼ ì¶œë ¥
	# ------------------------------------------------------------------	
	print("=== Regression Metrics on Iris (Target: Sepal Length) ===\n")
	# ì„¸ë¶€ ê°’ ë¨¼ì € ì¶œë ¥
	print(">> Raw Metric Values")
	print(f"[1]  Mean Error (ME)                     : {ME:.4f}")
	print(f"[2]  Mean Absolute Error (MAE)           : {MAE:.4f}")
	print(f"[3]  Mean Squared Error (MSE)            : {MSE:.4f}")
	print(f"[4]  Mean Squared Log Error (MSLE)       : {MSLE:.4f}")
	print(f"[5]  Root Mean Squared Error (RMSE)      : {RMSE:.4f}")
	print(f"[6]  Root Mean Squared Log Error (RMSLE) : {RMSLE:.4f}")
	print(f"[7]  Mean Percentage Error (MPE)         : {MPE:.4f}")
	print(f"[8]  Mean Abs Percentage Error (MAPE)    : {MAPE:.4f}")
	print(f"[9]  Mean Abs Scaled Error (MASE)        : {MASE:.4f}")
	print(f"[10] R2 Score                             : {R2:.4f}")
	print()

	# í•´ì„ í‘œ ì¶œë ¥
	print(">> í•´ì„ í…Œì´ë¸” (íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€, ë°ì´í„° ìŠ¤ì¼€ì¼ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)")
	print("-" * 110)
	print(f"{'ì§€í‘œ':<10}{'ê°’':>12}{'í•´ì„(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)':>16}{'ê¸°ì¤€':>70}")
	print("-" * 110)
	for name, value, interp, crit in rows:
    # ê¸°ì¤€ ë¬¸ìì—´ì´ ê¸¸ì–´ì„œ ê·¸ëŒ€ë¡œ ë’¤ì— ë¶™ì—¬ì¤Œ
    	print(f"{name:<10}{value:>12.4f}{interp:>16}  {crit}")
	print("-" * 110)

<br>

**(íšŒê·€ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤ ì‹¤í–‰ ê²°ê³¼)**
	
	=== Regression Metrics on Iris (Target: Sepal Length) ===
	>> Raw Metric Values
	[1]  Mean Error (ME)                     : 0.0892
	[2]  Mean Absolute Error (MAE)           : 0.2469
	[3]  Mean Squared Error (MSE)            : 0.0981
	[4]  Mean Squared Log Error (MSLE)       : 0.0021
	[5]  Root Mean Squared Error (RMSE)      : 0.3132
	[6]  Root Mean Squared Log Error (RMSLE) : 0.0454
	[7]  Mean Percentage Error (MPE)         : 0.0123
	[8]  Mean Abs Percentage Error (MAPE)    : 0.0419
	[9]  Mean Abs Scaled Error (MASE)        : 0.2912
	[10] R2 Score                             : 0.8526

	>> í•´ì„ í…Œì´ë¸” (íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€, ë°ì´í„° ìŠ¤ì¼€ì¼ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
	--------------------------------------------------------------------------------------------------------------
	ì§€í‘œ            ê°’    í•´ì„(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)  ê¸°ì¤€
	--------------------------------------------------------------------------------------------------------------
	[1] ME          0.0892              ì¢‹ìŒ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨
	[2] MAE         0.2469              ë³´í†µ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨
	[3] MSE         0.0981              ë³´í†µ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨ (RMSE ê¸°ì¤€)
	[4] MSLE        0.0021              ì¢‹ìŒ  RMSLE<0.1:ì¢‹ìŒ, 0.1â‰¤RMSLE<0.2:ë³´í†µ, RMSLEâ‰¥0.2:ë‚˜ì¨
	[5] RMSE        0.3132              ë³´í†µ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨
	[6] RMSLE       0.0454              ì¢‹ìŒ  RMSLE<0.1:ì¢‹ìŒ, 0.1â‰¤RMSLE<0.2:ë³´í†µ, RMSLEâ‰¥0.2:ë‚˜ì¨
	[7] MPE         0.0123              ì¢‹ìŒ  |ì˜¤ì°¨|<10%:ì¢‹ìŒ, 10~20%:ë³´í†µ, 20% ì´ˆê³¼:ë‚˜ì¨
	[8] MAPE        0.0419              ì¢‹ìŒ  |ì˜¤ì°¨|<10%:ì¢‹ìŒ, 10~20%:ë³´í†µ, 20% ì´ˆê³¼:ë‚˜ì¨
	[9] MASE        0.2912              ì¢‹ìŒ  MASE<1:ì¢‹ìŒ, 1â‰¤MASE<2:ë³´í†µ, MASEâ‰¥2:ë‚˜ì¨
	[10] R2         0.8526              ì¢‹ìŒ  R2â‰¥0.8:ì¢‹ìŒ, 0.5â‰¤R2<0.8:ë³´í†µ, R2<0.5:ë‚˜ì¨
	--------------------------------------------------------------------------------------------------------------

<br>

**(íšŒê·€ í‰ê°€ì§€í‘œ í‰ê°€ê¸°ì¤€)**

|  í‰ê°€ì§€í‘œ           | ì¢‹ìŒ                             | ë³´í†µ                          | ë‚˜ì¨     |
|--------------------|----------------------------------|-------------------------------|----------|
| **[1] ME** í‰ê·  ì˜¤ì°¨           | &#124;ME&#124; / Ïƒ(y) < 0.25       | 0.25 â‰¤ &#124;ME&#124;/Ïƒ < 0.5     | â‰¥ 0.5    |
| **[2] MAE** í‰ê·  ì ˆëŒ€ ì˜¤ì°¨     | MAE / Ïƒ(y) < 0.25                 | 0.25 â‰¤ MAE/Ïƒ < 0.5            | â‰¥ 0.5    |
| **[3] MSE** í‰ê·  ì œê³± ì˜¤ì°¨     | âˆšMSE / Ïƒ(y) < 0.25                | 0.25 â‰¤ âˆšMSE/Ïƒ < 0.5           | â‰¥ 0.5    |
| **[4] MSLE** í‰ê·  ì œê³± ì˜¤ì°¨(ë¡œê·¸) | RMSLE < 0.10                      | 0.10 ~ 0.20                    | â‰¥ 0.20   |
| **[5] RMSE** í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨  | RMSE / Ïƒ(y) < 0.25                | 0.25 â‰¤ RMSE/Ïƒ < 0.5           | â‰¥ 0.5    |
| **[6] RMSLE** í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸) | RMSLE < 0.10                      | 0.10 ~ 0.20                    | â‰¥ 0.20   |
| **[7] MPE** í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨     | &#124;MPE&#124; < 10%              | 10% ~ 20%                      | â‰¥ 20%    |
| **[8] MAPE** í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ | MAPE < 10%                         | 10% ~ 20%                      | > 20%    |
| **[9] MASE** í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ | MASE < 1                           | 1 ~ 2                          | â‰¥ 2      |
| **[10] RÂ²** ê²°ì •ê³„ìˆ˜            | RÂ² â‰¥ 0.80                          | 0.50 â‰¤ RÂ² < 0.80              | < 0.50   |




---

**(ë°ì´í„°êµ¬ì¡°)** ![](./images/db.png)
<br>
**(ë°ì´í„°ì…‹)** https://github.com/YangGuiBee/ML/blob/main/TextBook-12/insurance.csv
<br>

	################################################################################
	# ë°ì´í„° ì‹œê°í™”
	################################################################################
	
	import pandas as pd
	import seaborn as sns
	import matplotlib.pyplot as plt
	
	# Load dataset from URL
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/insurance.csv"
	df = pd.read_csv(data_url)
	
	# Ensure categorical columns are treated as categories
	df['sex'] = df['sex'].astype('category')
	df['smoker'] = df['smoker'].astype('category')
	df['region'] = df['region'].astype('category')
	
	# Basic information about the dataset
	print("Dataset Information:")
	print(df.info())
	print("\nBasic Statistics:")
	print(df.describe())
	
	# Visualizations
	plt.figure(figsize=(14, 10))
	
	# Distribution of Charges
	plt.subplot(3, 2, 1)
	sns.histplot(df['charges'], kde=True, bins=30, color='blue')
	plt.title('Distribution of Charges')
	plt.xlabel('Charges')
	plt.ylabel('Frequency')
	
	# Age Distribution
	plt.subplot(3, 2, 2)
	sns.histplot(df['age'], kde=True, bins=20, color='green')
	plt.title('Age Distribution')
	plt.xlabel('Age')
	plt.ylabel('Frequency')
	
	# BMI vs Charges
	plt.subplot(3, 2, 3)
	sns.scatterplot(x='bmi', y='charges', data=df, hue='smoker', palette='Set1', alpha=0.7)
	plt.title('BMI vs Charges')
	plt.xlabel('BMI')
	plt.ylabel('Charges')
	
	# Region Counts
	plt.subplot(3, 2, 4)
	sns.countplot(x='region', data=df, palette='Set2')
	plt.title('Region Counts')
	plt.xlabel('Region')
	plt.ylabel('Count')
	
	# Charges by Smoker
	plt.subplot(3, 2, 5)
	sns.boxplot(x='smoker', y='charges', data=df, palette='Set1')
	plt.title('Charges by Smoker')
	plt.xlabel('Smoker')
	plt.ylabel('Charges')
	
	# Children Distribution
	plt.subplot(3, 2, 6)
	sns.countplot(x='children', data=df, palette='Set3')
	plt.title('Children Distribution')
	plt.xlabel('Number of Children')
	plt.ylabel('Count')
	
	plt.tight_layout()
	plt.show()
	
	# Correlation Heatmap (Numerical Columns Only)
	plt.figure(figsize=(10, 8))
	numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
	sns.heatmap(df[numerical_columns].corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
	plt.title('Correlation Heatmap')
	plt.show()

<br>

![](./images/data.png)
<br>

![](./images/data2.png)
<br>

	################################################################################
	# ë³´í—˜ë£Œ(Charges)ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ë‹¤ì¤‘ì„ í˜•íšŒê·€+ê²°ì •íŠ¸ë¦¬ íšŒê·€ëª¨ë¸ ë¹„êµ ì‹¤ìŠµ
	################################################################################
	# í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ pipë¡œ ì„¤ì¹˜í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
	import subprocess  # íŒŒì´ì¬ì—ì„œ ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤(pip ëª…ë ¹ ë“±)ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©
	import sys         # í˜„ì¬ íŒŒì´ì¬ ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ(sys.executable) ë“±ì„ ì–»ê¸° ìœ„í•´ ì‚¬ìš©
	
	# íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ë‹´ë‹¹í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
	def install(package):
	    try:
	        __import__(package)      # íŒ¨í‚¤ì§€ë¥¼ ì„í¬íŠ¸í•´ë³´ê³ 
	    except ImportError:          # ì„í¬íŠ¸ê°€ ì‹¤íŒ¨í•˜ë©´ (íŒ¨í‚¤ì§€ê°€ ì—†ìœ¼ë©´)
	        print(f"Installing {package}...")
	        # í˜„ì¬ íŒŒì´ì¬ ì‹¤í–‰ íŒŒì¼ë¡œ pip ëª¨ë“ˆì„ í˜¸ì¶œí•´ í•´ë‹¹ íŒ¨í‚¤ì§€ ì„¤ì¹˜
	        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
	
	# í•„ìš”í•œ íŒ¨í‚¤ì§€ ë¦¬ìŠ¤íŠ¸ ì •ì˜
	required_packages = ['pandas', 'scikit-learn', 'xgboost', 'lightgbm', 'numpy']
	
	# í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì´ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ install() ì‹¤í–‰
	for package in required_packages:
	    install(package)
	
	# ------------------------------------------------------------------------------
	# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
	# ------------------------------------------------------------------------------
	import pandas as pd  # ë°ì´í„°í”„ë ˆì„ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬
	import numpy as np   # ìˆ˜ì¹˜ ê³„ì‚° ë° ë°°ì—´ ì²˜ë¦¬
	from sklearn.model_selection import train_test_split  # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
	from sklearn.preprocessing import OneHotEncoder       # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
	from sklearn.linear_model import LinearRegression     # ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸
	from sklearn.tree import DecisionTreeRegressor        # ê²°ì • íŠ¸ë¦¬ íšŒê·€ ëª¨ë¸
	from sklearn.metrics import (                         # íšŒê·€ í‰ê°€ ì§€í‘œë“¤
	    mean_absolute_error,
	    mean_squared_error,
	    r2_score,
	    mean_absolute_percentage_error)
	
	# ------------------------------------------------------------------------------
	# 1. ë°ì´í„° ë¡œë”©
	# ------------------------------------------------------------------------------
	# GitHubì— ì˜¬ë¼ê°€ ìˆëŠ” ë³´í—˜ ë°ì´í„°ì…‹(csv)ì˜ URL
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/insurance.csv"
	
	# URLì—ì„œ csv íŒŒì¼ì„ ì½ì–´ì™€ DataFrameìœ¼ë¡œ ë¡œë”©
	df = pd.read_csv(data_url)
	
	# ------------------------------------------------------------------------------
	# 2. ê²°ì¸¡ì¹˜ í™•ì¸
	# ------------------------------------------------------------------------------
	print("Checking for missing values...")
	# ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜(NaN)ì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥
	print(df.isnull().sum())
	
	# ì „ì²´ ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ AssertionError ë°œìƒ
	assert not df.isnull().values.any(), "Data contains missing values!"
	
	# ------------------------------------------------------------------------------
	# 3. ì…ë ¥(X) / íƒ€ê¹ƒ(y) ë¶„ë¦¬ ë° ì „ì²˜ë¦¬
	# ------------------------------------------------------------------------------
	# ì˜ˆì¸¡ ëŒ€ìƒì¸ 'charges' ì»¬ëŸ¼ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ì„ ì„¤ëª… ë³€ìˆ˜ Xë¡œ ì‚¬ìš©
	X = df.drop("charges", axis=1)
	
	# 'charges' ì»¬ëŸ¼ì„ íƒ€ê¹ƒ yë¡œ ì‚¬ìš©
	y = df["charges"]
	
	# ë²”ì£¼í˜• ë³€ìˆ˜ ëª©ë¡ (ë¬¸ìì—´ë¡œ í‘œí˜„ëœ ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜)
	categorical_features = ["sex", "smoker", "region"]	
	# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ëª©ë¡
	numerical_features = ["age", "bmi", "children"]
	
	# OneHotEncoder ì„¤ì •
	# - sparse_output=False : í¬ì†Œ í–‰ë ¬ì´ ì•„ë‹Œ ì¼ë°˜ ë°°ì—´ ë°˜í™˜
	# - drop="first"        : ê° ë²”ì£¼í˜• ë³€ìˆ˜ì—ì„œ ì²« ë²ˆì§¸ ë²”ì£¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì œê±°(ë”ë¯¸ ë³€ìˆ˜ í•¨ì • ë°©ì§€)
	encoder = OneHotEncoder(sparse_output=False, drop="first")
	
	# ë²”ì£¼í˜• ë³€ìˆ˜ì— ëŒ€í•´ One-Hot ì¸ì½”ë”© ìˆ˜í–‰ (fit + transform)
	X_encoded = encoder.fit_transform(X[categorical_features])
	
	# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
	X_numerical = X[numerical_features]
	
	# ìˆ˜ì¹˜í˜• + ì¸ì½”ë”©ëœ ë²”ì£¼í˜•ì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ìˆ˜í‰ ê²°í•©
	X_merged = np.hstack([X_numerical, X_encoded])
	
	# ê²°í•© ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì»¬ëŸ¼ ì´ë¦„ ì§€ì •
	X_preprocessed = pd.DataFrame(
	    X_merged, columns=numerical_features + encoder.get_feature_names_out().tolist()	)
	
	# ------------------------------------------------------------------------------
	# 4. í•™ìŠµìš© / í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë¶„í• 
	# ------------------------------------------------------------------------------
	# train_test_splitì„ ì‚¬ìš©í•´ í•™ìŠµ(80%) / í…ŒìŠ¤íŠ¸(20%) ë°ì´í„°ë¡œ ë¶„í• 
	# random_state=42 : ë§¤ë²ˆ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë¶„í• ë˜ë„ë¡ ì‹œë“œ ê³ ì •
	X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)
	
	# ------------------------------------------------------------------------------
	# 5. íšŒê·€ í‰ê°€ ì§€í‘œ í•¨ìˆ˜ ì •ì˜
    # y_true : ì‹¤ì œ ê°’ (ì •ë‹µ)
	# y_pred : ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’
	# 10ê°œì˜ íšŒê·€ í‰ê°€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
	# [1] ME, [2] MAE, [3] MSE, [4] MSLE, [5] RMSE, [6] RMSLE, [7] MPE, [8] MAPE, [9] MASE, [10] R2
	# ------------------------------------------------------------------------------	
	def evaluate_model(y_true, y_pred):
	    # í‰ê·  ì˜¤ì°¨ (Mean Error) : ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’ì˜ í‰ê· 
	    me = np.mean(y_true - y_pred )
	
	    # í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE)
	    mae = mean_absolute_error(y_true, y_pred)
	
	    # í‰ê·  ì œê³± ì˜¤ì°¨ (MSE)
	    mse = mean_squared_error(y_true, y_pred)
	
	    # í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE) = MSEì˜ ì œê³±ê·¼
	    rmse = np.sqrt(mse)
	
	    # -------------------- ë¡œê·¸ ê¸°ë°˜ ì§€í‘œ (MSLE, RMSLE) --------------------
	    # ëª¨ë“  ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì´ ì–‘ìˆ˜ì¼ ë•Œë§Œ ë¡œê·¸ë¥¼ ì ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¡°ê±´ ê²€ì‚¬
	    if (y_true > 0).all() and (y_pred > 0).all():
	        # log1p(x) = log(1 + x), 0 ê·¼ì²˜ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ë¡œê·¸ ì‚¬ìš© ê°€ëŠ¥
	        msle = mean_squared_error(np.log1p(y_true), np.log1p(y_pred))
	        rmsle = np.sqrt(msle)
	    else:
	        # í•˜ë‚˜ë¼ë„ 0 ì´í•˜ ê°’ì´ ìˆìœ¼ë©´ ê³„ì‚°í•˜ì§€ ì•Šê³  NaNìœ¼ë¡œ ì²˜ë¦¬
	        msle = np.nan
	        rmsle = np.nan
	
	    # í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (MPE, %) : (ì‹¤ì œ - ì˜ˆì¸¡) / ì‹¤ì œ ì˜ í‰ê· ì— 100ì„ ê³±í•´ %
	    mpe = np.mean((y_true - y_pred) / y_true) * 100
	
	    # í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (MAPE, %) : ì ˆëŒ€ê°’ ê¸°ì¤€ ë¹„ìœ¨ ì˜¤ì°¨ í‰ê· 
	    mape = mean_absolute_percentage_error(y_true, y_pred) * 100
	
	    # -------------------- í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (MASE) --------------------
	    # ìŠ¤ì¼€ì¼ë§ ê¸°ì¤€(scale)ì€ y_trueì˜ ì—°ì† ì°¨ì´ |y_t - y_{t-1}|ì˜ í‰ê· ìœ¼ë¡œ ì •ì˜
	    #  -> ì‹œê³„ì—´ì—ì„œ "ë‚˜ì´ë¸Œ ì˜ˆì¸¡(y_{t-1})"ì˜ MAEì™€ ë™ì¼í•œ ì—­í• 
	    if len(y_true) > 1:
	        scale = np.mean(np.abs(np.diff(y_true)))  # ì—°ì† ì°¨ì´ì˜ ì ˆëŒ€ê°’ í‰ê· 
	        if scale == 0:
	            mase = np.nan                         # ìŠ¤ì¼€ì¼ì´ 0ì´ë©´ ì •ì˜ ë¶ˆê°€ â†’ NaN
	        else:
	            mase = mae / scale                    # MASE = MAE / scale
	    else:
	        mase = np.nan                             # ë°ì´í„°ê°€ 1ê°œ ì´í•˜ë©´ ê³„ì‚° ë¶ˆê°€
	
	    # ê²°ì •ê³„ìˆ˜ R2 : ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)
	    r2 = r2_score(y_true, y_pred)
	
	    # ê³„ì‚°í•œ ëª¨ë“  ì§€í‘œë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜
	    return {
	        "ME": me,
	        "MAE": mae,
	        "MSE": mse,
	        "MSLE": msle,
	        "RMSE": rmse,
	        "RMSLE": rmsle,
	        "MPE": mpe,
	        "MAPE": mape,
	        "MASE": mase,
	        "R2": r2  }
	
	# ------------------------------------------------------------------------------
	# 6. ì‚¬ìš©í•  íšŒê·€ ëª¨ë¸ ì •ì˜ (ë‹¤ì¤‘ ì„ í˜•íšŒê·€ / ê²°ì •íŠ¸ë¦¬ íšŒê·€)
	# ------------------------------------------------------------------------------	
	models = {
	    "Multiple Linear Regression": LinearRegression(),
	    "Decision Tree Regression": DecisionTreeRegressor()	}
	
	# ------------------------------------------------------------------------------
	# 7. ê° ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
	# ------------------------------------------------------------------------------	
	# ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ëª¨ë¸ ì´ë¦„ë³„ í‰ê°€ ì§€í‘œ)
	results = {}
	
	# ë”•ì…”ë„ˆë¦¬ì— ë“¤ì–´ìˆëŠ” ê° ëª¨ë¸ì— ëŒ€í•´ ë°˜ë³µ
	for name, model in models.items():
	    # í•™ìŠµìš© ë°ì´í„°ë¡œ ëª¨ë¸ í›ˆë ¨
	    model.fit(X_train, y_train)
	
	    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰
	    y_pred = model.predict(X_test)
	
	    # ì˜ˆì¸¡ ê²°ê³¼ ì¤‘ ìŒìˆ˜ ê°’ì´ ìˆëŠ” ê²½ìš° ê²½ê³  ì¶œë ¥ í›„ 0ìœ¼ë¡œ ë³´ì •
	    if (y_pred < 0).any():
	        print(f"Warning: Model {name} produced negative predictions. Adjusting values to zero.")
	        # ìŒìˆ˜ì¸ ì˜ˆì¸¡ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´ (ë³´í—˜ë£ŒëŠ” ìŒìˆ˜ê°€ ë  ìˆ˜ ì—†ê¸° ë•Œë¬¸)
	        y_pred = np.maximum(y_pred, 0)
	
	    # ìœ„ì—ì„œ ì •ì˜í•œ evaluate_model() í•¨ìˆ˜ë¡œ ê°ì¢… í‰ê°€ ì§€í‘œ ê³„ì‚°
	    results[name] = evaluate_model(y_test, y_pred)
	
	# ------------------------------------------------------------------------------
	# 8. í‰ê°€ ê²°ê³¼ë¥¼ í‘œ í˜•íƒœë¡œ ì •ë¦¬ ë° ì¶œë ¥
	# ------------------------------------------------------------------------------	
	# results ë”•ì…”ë„ˆë¦¬ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (í–‰: ì§€í‘œ, ì—´: ëª¨ë¸ëª…)
	evaluation_results = pd.DataFrame(results)
	
	# ëª¨ë“  ê°’ì„ ì†Œìˆ˜ì  6ìë¦¬ê¹Œì§€ ë¬¸ìì—´ë¡œ í¬ë§· (NaNì€ ê·¸ëŒ€ë¡œ 'NaN')
	evaluation_results = evaluation_results.applymap(lambda x: f"{x:.6f}" if pd.notnull(x) else "NaN")
	
	# ëª¨ë¸ë³„ í‰ê°€ ê²°ê³¼ ì¶œë ¥
	print("\nModel Evaluation Results:")
	print(evaluation_results)
	
	# ------------------------------------------------------------------------------
	# 9. ê° ì§€í‘œì— ëŒ€í•œ í•œê¸€ ì„¤ëª… ì‚¬ì „ ì¤€ë¹„
	# ------------------------------------------------------------------------------	
	metric_explanations = {
	    "ME":   "í‰ê·  ì˜¤ì°¨ (Mean Error, ME): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ í‰ê·  ì°¨ì´. 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MAE":  "í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (Mean Absolute Error, MAE): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì ˆëŒ€ì  ì°¨ì´ì˜ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MSE":  "í‰ê·  ì œê³± ì˜¤ì°¨ (Mean Squared Error, MSE): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì œê³± ì°¨ì´ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MSLE": "í‰ê·  ì œê³± ì˜¤ì°¨ (ë¡œê·¸ ì ìš©, Mean Squared Log Error, MSLE): ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œì˜ í‰ê·  ì œê³± ì˜¤ì°¨. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "RMSE": "í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (Root Mean Squared Error, RMSE): í‰ê·  ì œê³± ì˜¤ì°¨ì˜ ì œê³±ê·¼. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "RMSLE":"í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (ë¡œê·¸ ì ìš©, Root Mean Squared Log Error, RMSLE): ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œì˜ ì œê³±ê·¼ ì˜¤ì°¨. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MPE":  "í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (Mean Percentage Error, MPE): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ë¹„ìœ¨ ì˜¤ì°¨ í‰ê· . 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MAPE": "í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (Mean Absolute Percentage Error, MAPE): ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ì˜ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MASE": "í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (Mean Absolute Scaled Error, MASE): ë‚˜ì´ë¸Œ ì˜ˆì¸¡ ëŒ€ë¹„ ìƒëŒ€ì ì¸ MAE. 1ë³´ë‹¤ ì‘ìœ¼ë©´ ë‚˜ì´ë¸Œë³´ë‹¤ ìš°ìˆ˜.",
	    "R2":   "R2 ì ìˆ˜ (Coefficient of Determination, R2): ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë‚˜íƒ€ëƒ„. 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.",
	}
	
	# ------------------------------------------------------------------------------
	# 10. ì§€í‘œ ì„¤ëª… + ëª¨ë¸ë³„ ê°’ í•¨ê»˜ ì¶œë ¥
	# ------------------------------------------------------------------------------	
	print("\nModel Evaluation Results with Explanations:")
	
	# metric_explanations ì‚¬ì „ì„ ìˆœíšŒí•˜ë©´ì„œ
	for metric, explanation in metric_explanations.items():
	    # ë¨¼ì € ì§€í‘œ ì„¤ëª… ì¶œë ¥
	    print(f"{metric}: {explanation}")
	    # ì´ì–´ì„œ í•´ë‹¹ ì§€í‘œì— ëŒ€í•œ ê° ëª¨ë¸ì˜ ê°’(í–‰) ì¶œë ¥
	    print(evaluation_results.loc[metric])
	    print()  # ë³´ê¸° ì¢‹ê²Œ ë¹ˆ ì¤„
	
	# ------------------------------------------------------------------------------
	# 11. ìƒˆë¡œìš´ í•œ ëª…ì˜ ê³ ê° ë°ì´í„°ì— ëŒ€í•œ ë³´í—˜ë£Œ ì˜ˆì¸¡
	# ------------------------------------------------------------------------------	
	# ì˜ˆì¸¡ì— ì‚¬ìš©í•  í…ŒìŠ¤íŠ¸ ì…ë ¥ í•œ ê±´ ìƒì„±
	# [ë‚˜ì´, BMI, ìë…€ ìˆ˜, ì„±ë³„, í¡ì—° ì—¬ë¶€, ì§€ì—­]
	test_input = pd.DataFrame( [[55, 21, 2, "female", "no", "northeast"]],
	    columns=["age", "bmi", "children", "sex", "smoker", "region"]	)
	
	# test_inputì—ì„œ ë²”ì£¼í˜• ì»¬ëŸ¼ë§Œ ë½‘ì•„ ê¸°ì¡´ ì¸ì½”ë”ë¡œ ë³€í™˜ (fit ì•„ë‹˜, transformë§Œ ìˆ˜í–‰)
	test_encoded = encoder.transform(test_input[categorical_features])
	
	# test_inputì—ì„œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ë³„ë„ë¡œ ì¶”ì¶œ
	test_numerical = test_input[numerical_features]
	
	# ìˆ˜ì¹˜í˜• + ì¸ì½”ë”©ëœ ë²”ì£¼í˜•ì„ ìˆ˜í‰ ê²°í•©í•˜ì—¬ ìµœì¢… ì…ë ¥ íŠ¹ì§•í–‰ë ¬ ìƒì„±
	test_preprocessed = pd.DataFrame(
	    np.hstack([test_numerical, test_encoded]),
	    columns=numerical_features + encoder.get_feature_names_out().tolist()	)
	
	# ------------------------------------------------------------------------------
	# 12. ê° ëª¨ë¸ë¡œë¶€í„° ì˜ˆì¸¡ê°’ ì–»ê¸°
	# ------------------------------------------------------------------------------	
	# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ëª¨ë¸ëª…: ì˜ˆì¸¡ê°’)
	predictions = {}
	
	# ì•ì„œ ì •ì˜í•œ models ë”•ì…”ë„ˆë¦¬ì˜ ê° ëª¨ë¸ì— ëŒ€í•´
	for name, model in models.items():
	    # í•˜ë‚˜ì˜ ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì€ ë°°ì—´ í˜•íƒœë¡œ ë‚˜ì˜¤ë¯€ë¡œ [0]ìœ¼ë¡œ ìŠ¤ì¹¼ë¼ ì¶”ì¶œ
	    predictions[name] = model.predict(test_preprocessed)[0]
	
	# ì˜ˆì¸¡ê°’ ë”•ì…”ë„ˆë¦¬ë¥¼ DataFrameìœ¼ë¡œ ë§Œë“¤ì–´ ë³´ê¸° ì¢‹ê²Œ í¬ë§·
	predictions_df = pd.DataFrame(predictions, index=["Predicted Charges"]).applymap(
	    lambda x: f"{x:.6f}")
	
	# ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
	print("\nPredicted Charges for Input:")
	print(predictions_df)

<br>

	Installing scikit-learn...
	Checking for missing values...
	age         0
	sex         0
	bmi         0
	children    0
	smoker      0
	region      0
	charges     0
	dtype: int64
	Warning: Model Multiple Linear Regression produced negative predictions. Adjusting values to zero.
	
	Model Evaluation Results:
	      Multiple Linear Regression Decision Tree Regression
	ME                    230.390130               954.400887
	MAE                  4170.045013              3194.668083
	MSE              33542077.406786          43411840.706491
	MSLE                         NaN                 0.321182
	RMSE                 5791.552245              6588.766251
	RMSLE                        NaN                 0.566729
	MPE                    23.612385                32.447466
	MAPE                   46.264515                45.261403
	MASE                    0.337699                 0.258711
	R2                      0.783946                 0.720372
	
	Model Evaluation Results with Explanations:
	ME: í‰ê·  ì˜¤ì°¨ (Mean Error, ME): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ í‰ê·  ì°¨ì´. 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression    230.390130
	Decision Tree Regression      954.400887
	Name: ME, dtype: object
	
	MAE: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (Mean Absolute Error, MAE): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì ˆëŒ€ì  ì°¨ì´ì˜ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression    4170.045013
	Decision Tree Regression      3194.668083
	Name: MAE, dtype: object
	
	MSE: í‰ê·  ì œê³± ì˜¤ì°¨ (Mean Squared Error, MSE): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì œê³± ì°¨ì´ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression    33542077.406786
	Decision Tree Regression      43411840.706491
	Name: MSE, dtype: object
	
	MSLE: í‰ê·  ì œê³± ì˜¤ì°¨ (ë¡œê·¸ ì ìš©, Mean Squared Log Error, MSLE): ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œì˜ í‰ê·  ì œê³± ì˜¤ì°¨. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression         NaN
	Decision Tree Regression      0.321182
	Name: MSLE, dtype: object
	
	RMSE: í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (Root Mean Squared Error, RMSE): í‰ê·  ì œê³± ì˜¤ì°¨ì˜ ì œê³±ê·¼. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression    5791.552245
	Decision Tree Regression      6588.766251
	Name: RMSE, dtype: object
	
	RMSLE: í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (ë¡œê·¸ ì ìš©, Root Mean Squared Log Error, RMSLE): ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œì˜ ì œê³±ê·¼ ì˜¤ì°¨. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression         NaN
	Decision Tree Regression      0.566729
	Name: RMSLE, dtype: object
	
	MPE: í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (Mean Percentage Error, MPE): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ë¹„ìœ¨ ì˜¤ì°¨ í‰ê· . 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression    23.612385
	Decision Tree Regression      32.447466
	Name: MPE, dtype: object
	
	MAPE: í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (Mean Absolute Percentage Error, MAPE): ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ì˜ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression    46.264515
	Decision Tree Regression      45.261403
	Name: MAPE, dtype: object
	
	MASE: í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (Mean Absolute Scaled Error, MASE): ë‚˜ì´ë¸Œ ì˜ˆì¸¡ ëŒ€ë¹„ ìƒëŒ€ì ì¸ MAE. 1ë³´ë‹¤ ì‘ìœ¼ë©´ ë‚˜ì´ë¸Œë³´ë‹¤ ìš°ìˆ˜.
	Multiple Linear Regression    0.337699
	Decision Tree Regression      0.258711
	Name: MASE, dtype: object
	
	R2: R2 ì ìˆ˜ (Coefficient of Determination, R2): ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë‚˜íƒ€ëƒ„. 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.
	Multiple Linear Regression    0.783946
	Decision Tree Regression      0.720372
	Name: R2, dtype: object
	
	
	Predicted Charges for Input:
	                  Multiple Linear Regression Decision Tree Regression
	Predicted Charges               10131.945928             11881.969600
	
<br>


	################################################################################
	# ë³´í—˜ë£Œ(charges)ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ 6ê°œì˜ íšŒê·€ëª¨ë¸ì„ í•™ìŠµÂ·í‰ê°€Â·ì˜ˆì¸¡í•˜ëŠ” ì „ì²´ ì½”ë“œ
	# Ridge / Lasso / ElasticNet Regression / Random Forest Regression / XGBoost / LightGBM
	################################################################################
	# ------------------------------ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë¶€ë¶„ ------------------------------
	import subprocess   # pip install ë“± ì™¸ë¶€ ëª…ë ¹ í˜¸ì¶œ
	import sys          # python ì‹¤í–‰ íŒŒì¼ ìœ„ì¹˜ í™•ì¸
	
	def install(package):
	    try:
	        __import__(package)  # Import ì‹œë„
	    except ImportError:
	        print(f"Installing {package}...")
	        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
	
	required_packages = ['pandas', 'scikit-learn', 'xgboost', 'lightgbm', 'numpy']	
	for pkg in required_packages:
	    install(pkg)
	
	import pandas as pd
	import numpy as np
	from sklearn.model_selection import train_test_split
	from sklearn.preprocessing import OneHotEncoder	
	from sklearn.linear_model import Ridge, Lasso, ElasticNet	# ì„ í˜• ê¸°ë°˜ íšŒê·€	
	from sklearn.ensemble import RandomForestRegressor			# ì•™ìƒë¸” ê¸°ë°˜ íšŒê·€	
	from xgboost import XGBRegressor							# ë¶€ìŠ¤íŒ… ê¸°ë°˜ íšŒê·€
	from lightgbm import LGBMRegressor							# ë¶€ìŠ¤íŒ… ê¸°ë°˜ íšŒê·€	
	# íšŒê·€ í‰ê°€ì§€í‘œ
	from sklearn.metrics import (
	    mean_absolute_error,
	    mean_squared_error,
	    r2_score,
	    mean_absolute_percentage_error	)
		
	# ------------------------------ 1. ë°ì´í„° ë¡œë”© ------------------------------
	# GitHubì˜ ë³´í—˜ë£Œ ë°ì´í„°(csv) URL
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/insurance.csv"
	# CSV íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë¡œë“œ
	df = pd.read_csv(data_url)
	
	# ------------------------------ 2. ê²°ì¸¡ì¹˜ ê²€ì‚¬ ------------------------------
	print("Checking for missing values...")
	print(df.isnull().sum())        # ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜
	assert not df.isnull().values.any(), "ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤!"
		
	# ------------------------------ 3. ì „ì²˜ë¦¬: ë…ë¦½ë³€ìˆ˜/íƒ€ê¹ƒ ë¶„ë¦¬ ------------------------------
	# charges(ë³´í—˜ë£Œ) = íƒ€ê¹ƒ y, ë‚˜ë¨¸ì§€ = X
	X = df.drop("charges", axis=1)
	y = df["charges"]
	
	# ë²”ì£¼í˜• ë³€ìˆ˜ ëª©ë¡ (ë¬¸ìì—´ â†’ ì›í•«)
	categorical_features = ["sex", "smoker", "region"]	
	# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ëª©ë¡
	numerical_features = ["age", "bmi", "children"]	
	
	# ------------------------------ 4. ì›-í•« ì¸ì½”ë”© ------------------------------
	# sparse_output=False : í¬ì†Œí–‰ë ¬ ëŒ€ì‹  dense array ë°˜í™˜
	# drop="first" : ê° ë²”ì£¼ì˜ ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì œê±° â†’ ë‹¤ì¤‘ê³µì„ ì„± ë°©ì§€
	encoder = OneHotEncoder(sparse_output=False, drop="first")
	
	# ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
	X_encoded = encoder.fit_transform(X[categorical_features])	
	# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ê¸°
	X_numerical = X[numerical_features]
	
	# ìµœì¢… ì…ë ¥ë°ì´í„°(X) êµ¬ì„±
	X_preprocessed = pd.DataFrame(
	    np.hstack([X_numerical, X_encoded]),
	    columns=numerical_features + encoder.get_feature_names_out().tolist()	)
		
	# ------------------------------ 5. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  ------------------------------
	X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)
		
	# ------------------------------ 6. íšŒê·€ í‰ê°€ì§€í‘œ í•¨ìˆ˜ ------------------------------
	#    10ê°œ íšŒê·€ í‰ê°€ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•œë‹¤.
	#    [1] ME, [2] MAE, [3] MSE, [4] MSLE, [5] RMSE, [6] RMSLE, [7] MPE, [8] MAPE, [9] MASE, [10] R2
	def evaluate_model(y_true, y_pred):
	
	    # 1) Mean Error (í¸í–¥ ì¸¡ì •: ì‹¤ì œ-ì˜ˆì¸¡)
	    me = np.mean(y_true - y_pred)
	
	    # 2) Mean Absolute Error (ì ˆëŒ€ ì˜¤ì°¨)
	    mae = mean_absolute_error(y_true, y_pred)
	
	    # 3) Mean Squared Error (ì œê³± ì˜¤ì°¨)
	    mse = mean_squared_error(y_true, y_pred)
	
	    # 5) Root Mean Squared Error
	    rmse = np.sqrt(mse)
	
	    # 4 & 6) ë¡œê·¸ ê¸°ë°˜ ì˜¤ì°¨ (0 ì´ìƒì¼ ë•Œ ê°€ëŠ¥)
	    if (y_true >= 0).all() and (y_pred >= 0).all():
	        msle = mean_squared_error(np.log1p(y_true), np.log1p(y_pred))
	        rmsle = np.sqrt(msle)
	    else:
	        msle = np.nan
	        rmsle = np.nan
	
	    # 7) Mean Percentage Error (%)
	    mpe = np.mean((y_true - y_pred) / y_true) * 100
	
	    # 8) Mean Absolute Percentage Error (%)
	    mape = mean_absolute_percentage_error(y_true, y_pred) * 100
	
	    # 9) Mean Absolute Scaled Error (MASE)
	    #    ìŠ¤ì¼€ì¼ = ì‹¤ì œê°’ì˜ ì—°ì† ì°¨ì´(|y_t - y_(t-1)|) í‰ê· 
	    if len(y_true) > 1:
	        scale = np.mean(np.abs(np.diff(y_true)))
	        if scale == 0:
	            mase = np.nan
	        else:
	            mase = mae / scale
	    else:
	        mase = np.nan
	
	    # 10) RÂ²
	    r2 = r2_score(y_true, y_pred)
	
	    return {
	        "ME": me,
	        "MAE": mae,
	        "MSE": mse,
	        "MSLE": msle,
	        "RMSE": rmse,
	        "RMSLE": rmsle,
	        "MPE": mpe,
	        "MAPE": mape,
	        "MASE": mase,
	        "R2": r2    }
		
	# ------------------------------ 7. ëª¨ë¸ ì •ì˜ ------------------------------
	models = {
	    "Ridge Regression": Ridge(),
	    "Lasso Regression": Lasso(),
	    "Elastic Net Regression": ElasticNet(),
	
	    # n_jobs=1 â†’ joblibì˜ physical core detection ê²½ê³  ì œê±°
	    "Random Forest Regression": RandomForestRegressor( random_state=42, n_jobs=1 ),
	
	    # eval_metric="rmse" â†’ XGB ê²½ê³  ê°ì†Œ
	    "XGBoost": XGBRegressor(random_state=42,eval_metric="rmse" ),
	
	    "LightGBM": LGBMRegressor( random_state=42)	}
		
	# ------------------------------ 8. ëª¨ë¸ í•™ìŠµ & í‰ê°€ ------------------------------
	results = {}   # ê° ëª¨ë¸ì˜ ì§€í‘œ ì €ì¥	
	for name, model in models.items():
	
	    # 1) ëª¨ë¸ í•™ìŠµ
	    model.fit(X_train, y_train)
	
	    # 2) í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
	    y_pred = model.predict(X_test)
	
	    # 3) ì˜ˆì¸¡ê°’ ì¤‘ ìŒìˆ˜ ì œê±° (ë³´í—˜ë£ŒëŠ” ìŒìˆ˜ê°€ ë¶ˆê°€ëŠ¥)
	    if (y_pred < 0).any():
	        print(f"Warning: Model {name} produced negative predictions. Adjusting to zero.")
	        y_pred = np.maximum(y_pred, 0)
	
	    # 4) í‰ê°€
	    results[name] = evaluate_model(y_test, y_pred)
		
	# ------------------------------ 9. í‰ê°€ ê²°ê³¼ DataFrame ë³€í™˜ ------------------------------
	evaluation_results = pd.DataFrame(results)
	
	# pandas 3.0+ : applymap ëŒ€ì‹  map ì‚¬ìš©
	evaluation_results = evaluation_results.map(lambda x: f"{x:.6f}" if pd.notnull(x) else "NaN")
	
	print("\nModel Evaluation Results:")
	print(evaluation_results)
		
	# ------------------------------ 10. ìƒˆë¡œìš´ ì…ë ¥ 1ê±´ì— ëŒ€í•œ ì˜ˆì¸¡ ------------------------------
	test_input = pd.DataFrame( [[55, 21, 2, "female", "no", "northeast"]],
	    columns=["age", "bmi", "children", "sex", "smoker", "region"])
	
	# ë²”ì£¼í˜• ì›í•« ì¸ì½”ë”©
	test_encoded = encoder.transform(test_input[categorical_features])
	test_numerical = test_input[numerical_features]
	
	test_preprocessed = pd.DataFrame(
	    np.hstack([test_numerical, test_encoded]),
	    columns=numerical_features + encoder.get_feature_names_out().tolist()	)
	
	# ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
	predictions = {}
	for name, model in models.items():
	    predictions[name] = model.predict(test_preprocessed)[0]
	
	# DataFrame ë³€í™˜ + í¬ë§·íŒ…
	predictions_df = pd.DataFrame(
	    predictions, index=["Predicted Charges"]
	).map(lambda x: f"{x:.6f}")
	
	print("\nPredicted Charges for Input:")
	print(predictions_df)

<br>

	Installing scikit-learn...
	Checking for missing values...
	age         0
	sex         0
	bmi         0
	children    0
	smoker      0
	region      0
	charges     0
	dtype: int64
	Warning: Model Ridge Regression produced negative predictions. Adjusting to zero.
	Warning: Model Lasso Regression produced negative predictions. Adjusting to zero.
	Warning: Model XGBoost produced negative predictions. Adjusting to zero.
	[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
	You can set `force_col_wise=true` to remove the overhead.
	[LightGBM] [Info] Total Bins 319
	[LightGBM] [Info] Number of data points in the train set: 1070, number of used features: 8
	[LightGBM] [Info] Start training from score 13346.089733
	
	Model Evaluation Results:
	      Ridge Regression Lasso Regression Elastic Net Regression  \
	ME          230.704197       230.811984             318.771925   
	MAE        4182.886840      4171.281194            7423.855423   
	MSE    33592686.228366  33550700.878862        90268049.602763   
	MSLE          1.138902         1.141031               0.609497   
	RMSE       5795.919791      5792.296684            9500.949932   
	RMSLE         1.067194         1.068191               0.780703   
	MPE          24.045376        23.659480              82.541930   
	MAPE         46.542872        46.308404             103.785761   
	MASE          0.338739         0.337799               0.601199   
	R2            0.783620         0.783891               0.418559   
	
	      Random Forest Regression          XGBoost         LightGBM  
	ME                  476.141596       148.515254       160.277564  
	MAE                2550.078471      2761.822751      2623.205455  
	MSE            20942520.922620  23413960.743659  20557383.062015  
	MSLE                  0.195473         0.475891         0.243531  
	RMSE               4576.299916      4838.797448      4534.025040  
	RMSLE                 0.442123         0.689848         0.493489  
	MPE                  23.540036        16.037576        19.873116  
	MAPE                 32.492433        34.807561        34.442284  
	MASE                  0.206510         0.223658         0.212432  
	R2                    0.865103         0.849184         0.867584  
	
	Predicted Charges for Input:
	                  Ridge Regression Lasso Regression Elastic Net Regression  \
	Predicted Charges     10149.160698     10119.933271           12916.033857   
	
	                  Random Forest Regression       XGBoost      LightGBM  
	Predicted Charges             12901.765317  10175.989258  11811.794421  


---

![](./images/tscore2.png)
<br>

---
#  12-2 : ë¶„ë¥˜ í‰ê°€ ì§€í‘œ
---
	
 	[1] ì˜¤ì°¨í–‰ë ¬, í˜¼ë™í–‰ë ¬ (Confusion Matrix) : ê° ëª¨ë¸ì´ í´ë˜ìŠ¤ ê°„ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë¶„ë¥˜í–ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„
  	[2] ì •í™•ë„ (Accuracy) : ê°€ì¥ ê°„ë‹¨í•œ ê¸°ì¤€ìœ¼ë¡œ, ì „ì²´ ë°ì´í„° ì¤‘ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ë¹„ìœ¨
	[3] ì •ë°€ë„ (Precision), PPV (Positive Predictive Value) : ëª¨ë¸ì´ ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ ë°ì´í„° ì¤‘ ì‹¤ì œë¡œ ì–‘ì„±ì¸ ë¹„ìœ¨
	[4] ì¬í˜„ìœ¨ (Recall), ë¯¼ê°ë„ (Sensitivity), TPR (True Positive Rate) : ì‹¤ì œ ì–‘ì„± ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ íƒì§€í–ˆëŠ”ì§€ ë‚˜íƒ€ëƒ„
	[5] F1 score : ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· ìœ¼ë¡œ, ë‘ ì§€í‘œì˜ ê· í˜•ì„ í‰ê°€
 	[6] ì˜¤ë¶„ë¥˜ìœ¨ (Error Rate) : ì •í™•ë„ì˜ ë³´ì™„ ì§€í‘œë¡œ, ì „ì²´ ë°ì´í„° ì¤‘ ëª¨ë¸ì´ ì˜ëª» ì˜ˆì¸¡í•œ ë¹„ìœ¨
  	[7] íŠ¹ì´ë„ (Specificity), TNR(True Negative Rate) : ì‹¤ì œ ìŒì„± ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ íƒì§€í–ˆëŠ”ì§€ ë‚˜íƒ€ëƒ„
   	[8] ìœ„ì–‘ì„±ë¥  (Fall Out), FPR(False Positive Rate) : ìŒì„± ë°ì´í„°ë¥¼ ì–‘ì„± ë°ì´í„°ë¡œ ì˜ëª» ë¶„ë¥˜í•œ ë¹„ìœ¨
	[9] ROC curve : ëª¨ë“  ì„ê³„ê°’(threshold)ì— ëŒ€í•´ TPR(ë¯¼ê°ë„, Recall)ì™€ FPR(ìœ„ì–‘ì„±ë¥ )ì˜ ê´€ê³„ ì‹œê°í™”
	[10]AUC score : ëª¨ë¸ì´ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ë¶„ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ
	  
---

# [1] ì˜¤ì°¨í–‰ë ¬, í˜¼ë™í–‰ë ¬ (Confusion Matrix)

![](./images/CM_table.PNG)<br>
â–£ ì •ì˜: ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ê°„ì˜ ë¶„ë¥˜ ê²°ê³¼ë¥¼ í–‰ë ¬ í˜•íƒœë¡œ í‘œí˜„<br>
â–£ í•„ìš”ì„±: ë¶„ë¥˜ ëª¨ë¸ì˜ ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ ê³„ì‚°ì˜ ê¸°ì´ˆ<br>
â–£ ì¥ì : ì˜ˆì¸¡ì˜ ì „ì²´ì ì¸ ë¶„í¬ë¥¼ í•œëˆˆì— íŒŒì•…<br>
â–£ ë‹¨ì : ì´ì§„ ë¶„ë¥˜ì— ì í•©í•˜ë©° ë‹¤ì¤‘ í´ë˜ìŠ¤ì— ì ìš© ì‹œ ë³µì¡ë„ê°€ ì¦ê°€<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html<br>

TP(True Positive): ëª¨ë¸ì´ positiveë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ positive (ì •ë‹µ)<br>
TN(True Negative): ëª¨ë¸ì´ negativeë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ negative (ì •ë‹µ)<br>
FP(False Positive): ëª¨ë¸ì´ positiveë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ negative (ì˜¤ë‹µ)<br>
FN(False Negative): ëª¨ë¸ì´ negativeë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ positive (ì˜¤ë‹µ)<br>
<br>
**scikit-learnì˜ confusion_matrix ê¸°ë°˜**
<br>
![](./images/CM_table_real.PNG)

<br>

	from sklearn.metrics import confusion_matrix

	cm = confusion_matrix(y_true, y_pred)

<br>

# [2] ì •í™•ë„ (Accuracy)

$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$<br><br>
â–£ ì •ì˜: ì „ì²´ ë°ì´í„° ì¤‘ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡ëœ ë¹„ìœ¨(ë°ì´í„°ê°€ ë¶ˆê· í˜•í•  ë•Œ(positive:negative=9:1)ëŠ” Accuracyë§Œìœ¼ë¡œ ì œëŒ€ë¡œ ë¶„ë¥˜í–ˆëŠ”ì§€ëŠ” ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— Recallê³¼ Precisionì„ ì‚¬ìš©)<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ì‘ë™í•˜ëŠ”ì§€ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ í‰ê°€<br>
â–£ ì¥ì : ë‹¨ìˆœí•˜ê³  ì´í•´ê°€ ìš©ì´<br>
â–£ ë‹¨ì : ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì„ ì˜ëª» í‰ê°€í•  ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html<br>

<br>

	from sklearn.metrics import accuracy_score

	acc = accuracy_score(y_true, y_pred)

<br>

# [3] ì •ë°€ë„ (Precision), PPV(Positive Predictive Value)

$Precision = \frac{TP}{TP + FP}$<br><br>
â–£ ì •ì˜: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê¸ì •(positive) í´ë˜ìŠ¤ ì¤‘ ì‹¤ì œë¡œ ê¸ì •(positive) í´ë˜ìŠ¤ì¸ ë¹„ìœ¨ë¡œ, ì‹¤ì œ ì •ë‹µì´ negativeì¸ ë°ì´í„°ë¥¼ positiveë¼ê³  ì˜ëª» ì˜ˆì¸¡í•˜ë©´ ì•ˆ ë˜ëŠ” ê²½ìš°ì— ì¤‘ìš”í•œ ì§€í‘œê°€ ë  ìˆ˜ ìˆìœ¼ë©° Precisionì„ ë†’ì´ê¸° ìœ„í•´ì„  FP(ëª¨ë¸ì´ positiveë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì •ë‹µì€ negativeì¸ ê²½ìš°)ë¥¼ ë‚®ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”<br>
â–£ í•„ìš”ì„±: ì˜ëª»ëœ ê¸ì • ì˜ˆì¸¡(FP)ì„ ì¤„ì´ëŠ” ë° ì¤‘ìš”í•œ ì§€í‘œ<br>
â–£ ì¥ì : ì •í™•í•œ ì˜ˆì¸¡ì„ ê°•ì¡°<br>
â–£ ë‹¨ì : FNì€ ê³ ë ¤í•˜ì§€ ì•Šì•„ ì¬í˜„ìœ¨ê³¼ í•¨ê»˜ ì‚¬ìš© í•„ìš”<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html<br>

<br>

	from sklearn.metrics import precision_score
	
	precision = precision_score(y_true, y_pred)

<br>

# [4] ì¬í˜„ìœ¨ (Recall), ë¯¼ê°ë„ (Sensitivity), TPR (True Positive Rate)

$Recall = \frac{TP}{TP + FN}$<br><br>
â–£ ì •ì˜: ì‹¤ì œë¡œ ì •ë‹µì´ ê¸ì •(positive)ì¸ ê²ƒë“¤ ì¤‘ì—ì„œ ëª¨ë¸ì´ ê¸ì •(positive)ì´ë¼ê³  ì˜ˆì¸¡í•œ ë¹„ìœ¨ë¡œ, ì‹¤ì œ ì •ë‹µì´ positiveì¸ ë°ì´í„°ë¥¼ negativeë¼ê³  ì˜ëª» ì˜ˆì¸¡í•˜ë©´ ì•ˆ ë˜ëŠ” ê²½ìš°ì— ì¤‘ìš”í•œ ì§€í‘œê°€ ë  ìˆ˜ ìˆìœ¼ë©°, Recallë¥¼ ë†’ì´ê¸° ìœ„í•´ì„  FN(ëª¨ë¸ì´ negativeë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì •ë‹µì´ positiveì¸ ê²½ìš°)ì„ ë‚®ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”<br>
â–£ í•„ìš”ì„±: ë†“ì¹œ ê¸ì • ì˜ˆì¸¡(FN)ì„ ì¤„ì´ëŠ” ë° ì¤‘ìš”<br>
â–£ ì¥ì : ì‹¤ì œ ê¸ì • í´ë˜ìŠ¤ì— ëŒ€í•œ ëª¨ë¸ì˜ ë¯¼ê°ì„±ì„ ë‚˜íƒ€ëƒ„<br>
â–£ ë‹¨ì : FPëŠ” ê³ ë ¤í•˜ì§€ ì•Šì•„ Precisionê³¼ í•¨ê»˜ ì‚¬ìš© í•„ìš”<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html<br>

<br>

	from sklearn.metrics import recall_score
	
	recall = recall_score(y_true, y_pred)

<br>

# [5] F1 score

$F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}$<br><br>
â–£ ì •ì˜: Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· ìœ¼ë¡œ ë‘ ê°’ì˜ ê· í˜•ì„ í‰ê°€. Recallê³¼ Precisionì€ ìƒí˜¸ ë³´ì™„ì ì¸ í‰ê°€ ì§€í‘œì´ê¸° ë•Œë¬¸ì— F1 scoreë¥¼ ì‚¬ìš©í•˜ë©°, Precisionê³¼ Recallì´ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì³ì§€ì§€ ì•Šê³  ëª¨ë‘ í´ ë•Œ í° ê°’<br>
â–£ í•„ìš”ì„±: ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ Precisionê³¼ Recall ê°„ì˜ ê· í˜•ì„ í‰ê°€<br>
â–£ ì¥ì : ë‘ ì§€í‘œ ê°„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ë°˜ì˜<br>
â–£ ë‹¨ì : ê°œë³„ì ì¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ<br>
â–£ ì˜ˆì œ:https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html<br>

<br>

	from sklearn.metrics import f1_score

	f1 = f1_score(y_true, y_pred)

<br>

# [6] ì˜¤ë¶„ë¥˜ìœ¨ (Error Rate)

$Error Rate = \frac{FP + FN}{TP + TN + FP + FN}$<br><br>
â–£ ì •ì˜: ì „ì²´ ë°ì´í„° ì¤‘ ì˜ëª» ì˜ˆì¸¡ëœ ë¹„ìœ¨<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì˜ ë¶€ì •í™•ë„ë¥¼ ë‚˜íƒ€ëƒ„<br>
â–£ ì¥ì : ì •í™•ë„ì˜ ë³´ì™„ ì§€í‘œë¡œ í™œìš© ê°€ëŠ¥<br>
â–£ ë‹¨ì : ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” ìœ ì˜ë¯¸í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ : https://scikit-learn.org/stable/auto_examples/model_selection/plot_train_error_vs_test_error.html<br>

<br>

	error_rate = 1 - accuracy_score(y_true, y_pred)

<br>

# [7] íŠ¹ì´ë„ (Specificity), TNR(True Negative Rate)

$Specificity = \frac{TN}{TN + FP}$<br><br>
â–£ ì •ì˜: ì‹¤ì œ ë¶€ì • ë°ì´í„° ì¤‘ì—ì„œ ì˜¬ë°”ë¥´ê²Œ ë¶€ì •ìœ¼ë¡œ ì˜ˆì¸¡í•œ ë¹„ìœ¨<br>
â–£ í•„ìš”ì„±: ë¶€ì • í´ë˜ìŠ¤ë¥¼ ì •í™•íˆ ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€<br>
â–£ ì¥ì : Negative classì— ì´ˆì ì„ ë§ì¶˜ ë¶„ì„ì´ ê°€ëŠ¥<br>
â–£ ë‹¨ì : Positive classì˜ ì„±ëŠ¥ì€ ê³ ë ¤í•˜ì§€ ì•ŠìŒ<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html<br>

<br>

	tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
	
	specificity = tn / (tn + fp)

<br>

# [8] ìœ„ì–‘ì„±ë¥  (Fall Out), FPR(False Positive Rate)

$Fall Out = 1 - Specificity = 1 - \frac{TN}{TN + FP} = \frac{FP}{FP + TN}$<br><br>
â–£ ì •ì˜: ì‹¤ì œ ë¶€ì •(negative) ë°ì´í„° ì¤‘ì—ì„œ ê¸ì •(positive)ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ë¹„ìœ¨<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì´ ì˜ëª»ëœ ê¸ì •ì„ ì–¼ë§ˆë‚˜ ìƒì„±í•˜ëŠ”ì§€ í‰ê°€<br>
â–£ ì¥ì : íŠ¹ì´ë„ì˜ ë³´ì™„ ì§€í‘œë¡œ ì‚¬ìš©<br>
â–£ ë‹¨ì : ê¸ì • í´ë˜ìŠ¤ì˜ ì„±ëŠ¥ì€ í‰ê°€í•˜ì§€ ëª»í•¨<br>
â–£ ì˜ˆì œ1 (FPR ì œê³µë˜ëŠ” ROC ì»¤ë¸Œ API):https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html<br>
â–£ ì˜ˆì œ2 (ROC ê³¡ì„  = FPR vs TPR):https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html<br>

<br>

	tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
	
	fpr = fp / (fp + tn)

<br>

# [9] ROC curve
â–£ ì •ì˜: TPR(ì¬í˜„ìœ¨) Yì¶•ê³¼ FPR(ìœ„ì–‘ì„±ë¥ ) Xì¶•ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚¸ ê³¡ì„ ìœ¼ë¡œ ë‹¤ì–‘í•œ ì„ê³„ê°’ì—ì„œ Recall-Falloutì˜ ë³€í™”ë¥¼ ì‹œê°í™”í•œ ê²ƒ(Falloutì€ ì‹¤ì œ Falseì¸ data ì¤‘ì—ì„œ ëª¨ë¸ì´ Trueë¡œ ë¶„ë¥˜í•­ ë¹„ìœ¨ì„, Recallì€ ì‹¤ì œ Trueì¸ data ì¤‘ì—ì„œ ëª¨ë¸ì´ Trueë¡œ ë¶„ë¥˜í•œ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ„)<br>
â–£ í•„ìš”ì„±: ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì‹œê°ì ìœ¼ë¡œ í‰ê°€<br>
â–£ ì¥ì : Thresholdì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” í™•ì¸ì´ ê°€ëŠ¥<br>
â–£ ë‹¨ì : ê³¡ì„ ì´ ë‹¨ì¼ ìˆ«ìë¡œ ìš”ì•½ë˜ì§€ ì•Šì•„ ë¹„êµê°€ ì–´ë ¤ìš¸ ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html<br>

<br>

	from sklearn.metrics import roc_curve

	y_score = model.predict_proba(X_test)[:, 1]
	fpr, tpr, thresholds = roc_curve(y_true, y_score)


<br>	


# [10] AUC (Area Under Curve) score
â–£ ì •ì˜: ROC Curveì˜ ì•„ë˜ ë©´ì ìœ¼ë¡œ, 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì˜ ë¶„ë¥˜ ì„±ëŠ¥ì„ ìˆ«ìë¡œ ê°„ë‹¨íˆ ë‚˜íƒ€ëƒ„<br>
â–£ ì¥ì : Thresholdì— ê´€ê³„ì—†ì´ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€<br>
â–£ ë‹¨ì : ë°ì´í„° ë¶ˆê· í˜•ì´ ì‹¬í•œ ê²½ìš° ì™œê³¡ë  ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html<br>

<br>

	from sklearn.metrics import roc_auc_score

	auc = roc_auc_score(y_true, y_score)

<br>



**(ë¶„ë¥˜ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤)**

	# ============================================
	# Iris ê¸°ë°˜ ì´ì§„ë¶„ë¥˜ + í‰ê°€ì§€í‘œ 10ê°œ & í•´ì„í‘œ
	#  - ë ˆì´ë¸”: setosa(1) vs not-setosa(0)
	# ============================================
	import numpy as np
	
	from sklearn.datasets import load_iris
	from sklearn.model_selection import train_test_split
	from sklearn.linear_model import LogisticRegression
	from sklearn.metrics import (
	    confusion_matrix,
	    accuracy_score,
	    precision_score,
	    recall_score,
	    f1_score,
	    roc_curve,
	    roc_auc_score,
	)
	
	# ---------------------------------------------------------
	# 1. í•´ì„ ê¸°ì¤€ ë¬¸ìì—´ ì •ì˜
	# ---------------------------------------------------------
	CRIT_HIGH_09 = "ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨"
	CRIT_LOW_01  = "ê°’ â‰¤ 0.10:ì¢‹ìŒ, 0.10 < ê°’ â‰¤ 0.30:ë³´í†µ, ê°’ > 0.30:ë‚˜ì¨"
	CRIT_AUC     = "AUC â‰¥ 0.90:ì¢‹ìŒ, 0.80 â‰¤ AUC < 0.90:ë³´í†µ, AUC < 0.80:ë‚˜ì¨"
	CRIT_ROC     = "ê³¡ì„ ì´ ì¢Œìƒë‹¨ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ (AUC ê¸°ì¤€: " + CRIT_AUC + ")"
	
	# ---------------------------------------------------------
	# 2. í•´ì„ í•¨ìˆ˜ë“¤
	# ---------------------------------------------------------
	# ê°’ì´ í´ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ(Acc, Precision, Recall, F1, TPR, TNR ë“±)
	def interpret_high_good(v):
	    if v >= 0.90: return "ì¢‹ìŒ"
	    elif v >= 0.70: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ(Error Rate, FPR ë“±)
	def interpret_low_good(v):
	    if v <= 0.10: return "ì¢‹ìŒ"
	    elif v <= 0.30: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# AUC ë° ROC í•´ì„ìš©
	def interpret_auc(v):
	    if v >= 0.90: return "ì¢‹ìŒ"
	    elif v >= 0.80: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# ---------------------------------------------------------
	# 3. ë°ì´í„° ë¡œë“œ & ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ êµ¬ì„±
	# ---------------------------------------------------------
	iris = load_iris()
	X = iris.data               # (150, 4)
	y_multi = iris.target       # 0:setosa, 1:versicolor, 2:virginica
	
	# ì´ì§„ ë¶„ë¥˜: setosa(1) vs ë‚˜ë¨¸ì§€(0)
	y = (y_multi == 0).astype(int)
	
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
	
	# ê°„ë‹¨í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ë¥˜ê¸°
	clf = LogisticRegression(solver="liblinear")
	clf.fit(X_train, y_train)
	
	# ì˜ˆì¸¡ (ë ˆì´ë¸”, í™•ë¥ )
	y_pred = clf.predict(X_test)
	y_score = clf.predict_proba(X_test)[:, 1]   # ì–‘ì„±(1)ì¼ í™•ë¥ 
	
	# ---------------------------------------------------------
	# 4. ë¶„ë¥˜ í‰ê°€ì§€í‘œ 10ê°œ ê³„ì‚°
	# ---------------------------------------------------------
	# [1] Confusion Matrix
	cm = confusion_matrix(y_test, y_pred)
	tn, fp, fn, tp = cm.ravel()
	
	# [2] Accuracy
	acc = accuracy_score(y_test, y_pred)
	
	# [3] Precision (PPV)
	precision = precision_score(y_test, y_pred)
	
	# [4] Recall / Sensitivity / TPR
	recall = recall_score(y_test, y_pred)  # TPR
	
	# [5] F1 score
	f1 = f1_score(y_test, y_pred)
	
	# [6] Error Rate
	error_rate = 1 - acc
	
	# [7] Specificity / TNR
	specificity = tn / (tn + fp)
	
	# [8] FPR (Fall-out)
	fpr_value = fp / (fp + tn)
	
	# [9] ROC curve
	fpr, tpr, thresholds = roc_curve(y_test, y_score)  # ê³¡ì„ ìš© ì¢Œí‘œ
	
	# [10] AUC score
	auc = roc_auc_score(y_test, y_score)
	
	# ---------------------------------------------------------
	# 5. Raw ê°’ ì¶œë ¥
	# ---------------------------------------------------------
	print("=== Classification Metrics on Iris (setosa vs others) ===\n")	
	print(">> Raw Metric Values")
	print(f"[1] Confusion Matrix:\n{cm}")
	print(f"[2] Accuracy                : {acc:.4f}")
	print(f"[3] Precision (PPV)         : {precision:.4f}")
	print(f"[4] Recall (Sensitivity/TPR): {recall:.4f}")
	print(f"[5] F1-score                : {f1:.4f}")
	print(f"[6] Error Rate              : {error_rate:.4f}")
	print(f"[7] Specificity (TNR)       : {specificity:.4f}")
	print(f"[8] FPR (Fall-out)          : {fpr_value:.4f}")
	print(f"[9] ROC curve points        : fpr.shape={fpr.shape}, tpr.shape={tpr.shape}")
	print(f"[10] AUC score              : {auc:.4f}\n")
	
	# ---------------------------------------------------------
	# 6. í•´ì„ìš© í…Œì´ë¸” êµ¬ì„± (ì§€í‘œëª…, ê°’, í•´ì„, ê¸°ì¤€)
	# ---------------------------------------------------------
	rows = []
	
	# [1] Confusion Matrix â†’ ì •í™•ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´ì„
	rows.append(("[1] Confusion Matrix", f"TN={tn}, FP={fp}, FN={fn}, TP={tp}",
	    interpret_high_good(acc), "ëŒ€ê°í•© ë¹„ìœ¨(Accuracy) ê¸°ì¤€: " + CRIT_HIGH_09))	
	rows.append(("[2] Accuracy", f"{acc:.4f}", interpret_high_good(acc), CRIT_HIGH_09))	
	rows.append(("[3] Precision (PPV)", f"{precision:.4f}", interpret_high_good(precision), CRIT_HIGH_09))	
	rows.append(("[4] Recall (Sensitivity/TPR)",f"{recall:.4f}", interpret_high_good(recall), CRIT_HIGH_09))	
	rows.append(("[5] F1-score",f"{f1:.4f}", interpret_high_good(f1), CRIT_HIGH_09))	
	rows.append(("[6] Error Rate", f"{error_rate:.4f}", interpret_low_good(error_rate), CRIT_LOW_01))	
	rows.append(("[7] Specificity (TNR)", f"{specificity:.4f}", interpret_high_good(specificity), CRIT_HIGH_09))	
	rows.append(("[8] FPR (Fall-out)", f"{fpr_value:.4f}", interpret_low_good(fpr_value), CRIT_LOW_01))	
	rows.append(("[9] ROC curve", f"points={len(fpr)}ê°œ", interpret_auc(auc), CRIT_ROC))
	rows.append(("[10] AUC score", f"{auc:.4f}", interpret_auc(auc), CRIT_AUC))
	
	# ---------------------------------------------------------
	# 7. í•´ì„ í…Œì´ë¸” ì¶œë ¥
	# ---------------------------------------------------------
	print(">> í•´ì„ í…Œì´ë¸” (íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€, ë°ì´í„°/ë„ë©”ì¸ì— ë”°ë¼ ì¡°ì • ê¶Œì¥)")
	print("-" * 120)
	print(f"{'ì§€í‘œ':<28}{'ê°’':<24}{'í•´ì„':<10}{'ê¸°ì¤€'}")
	print("-" * 120)
	
	for name, value, interp, crit in rows:
	    print(f"{name:<28}{value:<24}{interp:<10}{crit}")	
	print("-" * 120)
	

**(ë¶„ë¥˜ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤ ì‹¤í–‰ ê²°ê³¼)**

	=== Classification Metrics on Iris (setosa vs others) ===
	>> Raw Metric Values
	[1] Confusion Matrix:
	[[30  0]
 	 [ 0 15]]
	[2] Accuracy                : 1.0000
	[3] Precision (PPV)         : 1.0000
	[4] Recall (Sensitivity/TPR): 1.0000
	[5] F1-score                : 1.0000
	[6] Error Rate              : 0.0000
	[7] Specificity (TNR)       : 1.0000
	[8] FPR (Fall-out)          : 0.0000
	[9] ROC curve points        : fpr.shape=(6,), tpr.shape=(6,)
	[10] AUC score              : 1.0000

	>> í•´ì„ í…Œì´ë¸” (íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€, ë°ì´í„°/ë„ë©”ì¸ì— ë”°ë¼ ì¡°ì • ê¶Œì¥)
	------------------------------------------------------------------------------------------------------------------------
	ì§€í‘œ                         ê°’                      í•´ì„        ê¸°ì¤€
	------------------------------------------------------------------------------------------------------------------------
	[1] Confusion Matrix        TN=30, FP=0, FN=0, TP=15ì¢‹ìŒ        ëŒ€ê°í•© ë¹„ìœ¨(Accuracy) ê¸°ì¤€: ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨
	[2] Accuracy                1.0000                  ì¢‹ìŒ        ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨
	[3] Precision (PPV)         1.0000                  ì¢‹ìŒ        ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨
	[4] Recall (Sensitivity/TPR)1.0000                  ì¢‹ìŒ        ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨
	[5] F1-score                1.0000                  ì¢‹ìŒ        ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨
	[6] Error Rate              0.0000                  ì¢‹ìŒ        ê°’ â‰¤ 0.10:ì¢‹ìŒ, 0.10 < ê°’ â‰¤ 0.30:ë³´í†µ, ê°’ > 0.30:ë‚˜ì¨
	[7] Specificity (TNR)       1.0000                  ì¢‹ìŒ        ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨
	[8] FPR (Fall-out)          0.0000                  ì¢‹ìŒ        ê°’ â‰¤ 0.10:ì¢‹ìŒ, 0.10 < ê°’ â‰¤ 0.30:ë³´í†µ, ê°’ > 0.30:ë‚˜ì¨
	[9] ROC curve               points=6ê°œ               ì¢‹ìŒ        ê³¡ì„ ì´ ì¢Œìƒë‹¨ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ (AUC ê¸°ì¤€: AUC â‰¥ 0.90:ì¢‹ìŒ, 0.80 â‰¤ AUC < 0.90:ë³´í†µ, AUC < 0.80:ë‚˜ì¨)
	[10] AUC score              1.0000                  ì¢‹ìŒ        AUC â‰¥ 0.90:ì¢‹ìŒ, 0.80 â‰¤ AUC < 0.90:ë³´í†µ, AUC < 0.80:ë‚˜ì¨
	------------------------------------------------------------------------------------------------------------------------

<br>

**(ë¶„ë¥˜ í‰ê°€ì§€í‘œ í‰ê°€ê¸°ì¤€)**

| í‰ê°€ì§€í‘œ | ì¢‹ìŒ | ë³´í†µ | ë‚˜ì¨ |
|----------|------|------|------|
| [1] ì˜¤ì°¨í–‰ë ¬ (Confusion Matrix) | TP, TN ë¹„ìœ¨ì´ ë§¤ìš° ë†’ê³  FP, FNì´ ê±°ì˜ ì—†ìŒ | TP, TNì´ ì ë‹¹íˆ ë†’ê³  FP, FNì´ ì–´ëŠ ì •ë„ ì¡´ì¬ | FP, FNì´ ë§ê³  TP, TNì´ ë‚®ìŒ (ëŒ€ê°ì„±ë¶„ë³´ë‹¤ ë¹„ëŒ€ê° ì„±ë¶„ì´ í¬ê±°ë‚˜ ë¹„ìŠ·) |
| [2] ì •í™•ë„ (Accuracy) | Accuracy â‰¥ 0.90 | 0.70 â‰¤ Accuracy < 0.90 | Accuracy < 0.70 |
| [3] ì •ë°€ë„ (Precision, PPV) | Precision â‰¥ 0.90 | 0.70 â‰¤ Precision < 0.90 | Precision < 0.70 |
| [4] ì¬í˜„ìœ¨ (Recall, Sensitivity, TPR) | Recall â‰¥ 0.90 | 0.70 â‰¤ Recall < 0.90 | Recall < 0.70 |
| [5] F1 score | F1 â‰¥ 0.90 | 0.70 â‰¤ F1 < 0.90 | F1 < 0.70 |
| [6] ì˜¤ë¶„ë¥˜ìœ¨ (Error Rate) | Error Rate â‰¤ 0.10 | 0.10 < Error Rate â‰¤ 0.30 | Error Rate > 0.30 |
| [7] íŠ¹ì´ë„ (Specificity, TNR) | TNR â‰¥ 0.90 | 0.70 â‰¤ TNR < 0.90 | TNR < 0.70 |
| [8] ìœ„ì–‘ì„±ë¥  (Fall-out, FPR) | FPR â‰¤ 0.10 | 0.10 < FPR â‰¤ 0.30 | FPR > 0.30 |
| [9] ROC curve | ëŒ€ë¶€ë¶„ êµ¬ê°„ì—ì„œ TPRì´ ë†’ê³  FPRì´ ë‚®ì•„ ê³¡ì„ ì´ ì¢Œìƒë‹¨ì— ë°€ì§‘ (ëŒ€ê°ì„ ì—ì„œ ì¶©ë¶„íˆ ìœ„ìª½) | ê³¡ì„ ì´ ëŒ€ê°ì„ ë³´ë‹¤ ì•½ê°„ ìœ„, ì¼ë¶€ êµ¬ê°„ë§Œ ëšœë ·í•œ êµ¬ë¶„ | ê³¡ì„ ì´ ëŒ€ê°ì„ ì— ê±°ì˜ ë¶™ê±°ë‚˜ ì•„ë˜ì— ìœ„ì¹˜ (ë¬´ì‘ìœ„ ë¶„ë¥˜ì™€ ë¹„ìŠ·/ì—´ë“±) |
| [10] AUC score | AUC â‰¥ 0.90 | 0.80 â‰¤ AUC < 0.90 | AUC < 0.80 |




---

**(ë°ì´í„° ì¶œì²˜)** https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data/data
<br>
**(ë°ì´í„°êµ¬ì¡°)** ![](./images/heart_disease_uci.png)
<br>
**(ë°ì´í„°ì…‹)** https://github.com/YangGuiBee/ML/blob/main/TextBook-12/heart_disease_uci.csv


	import pandas as pd
	import numpy as np
	from sklearn.model_selection import train_test_split
	from sklearn.preprocessing import StandardScaler, LabelEncoder
	from sklearn.linear_model import LogisticRegression
	from sklearn.naive_bayes import GaussianNB
	from sklearn.neighbors import KNeighborsClassifier
	from sklearn.svm import SVC
	from sklearn.tree import DecisionTreeClassifier
	from sklearn.ensemble import RandomForestClassifier
	from sklearn.metrics import (
	    confusion_matrix, accuracy_score, precision_score, recall_score,
	    f1_score, roc_auc_score, roc_curve
	)
	import matplotlib.pyplot as plt
	
	# -----------------------------
	# 1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
	# Class 0 â†’ ì‹¬ì¥ì§ˆí™˜ ì—†ìŒ(No heart disease)
	# Class 1 â†’ ê²½ë„ ì‹¬ì¥ì§ˆí™˜(Mild heart disease)
	# Class 2 â†’ ì¤‘ê°„ ì‹¬ì¥ì§ˆí™˜(Moderate)
	# Class 3 â†’ ì‹¬í•¨(Severe)
	# Class 4 â†’ ë§¤ìš° ì‹¬í•¨(Very severe)
	# -----------------------------
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/heart_disease_uci.csv"
	df = pd.read_csv(data_url)
	
	# -----------------------------
	# 2. ê²°ì¸¡ê°’ ì²˜ë¦¬
	# -----------------------------
	for col in df.columns:
	    if df[col].dtype == 'object':
	        df[col].fillna(df[col].mode()[0], inplace=True)
	    else:
	        df[col].fillna(df[col].mean(), inplace=True)
	
	# -----------------------------
	# 3. ì»¬ëŸ¼ ì •ë¦¬
	# -----------------------------
	df.rename(columns={"num": "target"}, inplace=True)
	df["target"] = df["target"].astype(int)
	
	# -----------------------------
	# 4. Train/Test Split
	# -----------------------------
	X = df.drop(["target", "id", "dataset"], axis=1)
	y = df["target"]
	
	X_train, X_test, y_train, y_test = train_test_split(
	    X, y, test_size=0.2, random_state=42, stratify=y
	)
	
	# -----------------------------
	# 5. Label Encoding
	# -----------------------------
	categorical_columns = ['sex', 'cp', 'restecg', 'slope', 'thal']
	for col in categorical_columns:
	    le = LabelEncoder()
	    X_train[col] = le.fit_transform(X_train[col])
	    X_test[col] = le.transform(X_test[col])
	
	# -----------------------------
	# 6. ìŠ¤ì¼€ì¼ë§
	# -----------------------------
	scaler = StandardScaler()
	X_train_scaled = scaler.fit_transform(X_train)
	X_test_scaled = scaler.transform(X_test)
	
	# -----------------------------
	# 7. ëª¨ë¸ ì •ì˜
	# -----------------------------
	models = {
	    "Logistic Regression": LogisticRegression(max_iter=1000),
	    "Naive Bayes": GaussianNB(),
	    "k-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5),
	    "Support Vector Classifier": SVC(probability=True),
	    "Decision Tree": DecisionTreeClassifier(),
	    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
	}
	
	# -----------------------------
	# 8. ëª¨ë¸ í•™ìŠµ + í‰ê°€ì§€í‘œ ê³„ì‚°
	# -----------------------------
	results = {}
	n_classes = len(np.unique(y_test))
	
	for name, model in models.items():
	
	    # ìŠ¤ì¼€ì¼ë§ ì ìš© ëª¨ë¸
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        model.fit(X_train_scaled, y_train)
	        y_pred = model.predict(X_test_scaled)
	        y_prob = model.predict_proba(X_test_scaled)
	    else:
	        model.fit(X_train, y_train)
	        y_pred = model.predict(X_test)
	        y_prob = model.predict_proba(X_test)
	
	    # í˜¼ë™í–‰ë ¬
	    cm = confusion_matrix(y_test, y_pred)
	
	    # Accuracy, Precision, Recall, F1
	    accuracy = accuracy_score(y_test, y_pred)
	    precision = precision_score(y_test, y_pred, average="macro")
	    recall_macro = recall_score(y_test, y_pred, average="macro")
	    f1 = f1_score(y_test, y_pred, average="macro")
	    error_rate = 1 - accuracy
	    auc_score = roc_auc_score(y_test, y_prob, multi_class="ovr")
	
	    # TP/FP/FN/TN (One-vs-Rest)
	    TP = np.zeros(n_classes)
	    FP = np.zeros(n_classes)
	    FN = np.zeros(n_classes)
	    TN = np.zeros(n_classes)
	
	    for i in range(n_classes):
	        TP[i] = cm[i, i]
	        FP[i] = cm[:, i].sum() - TP[i]
	        FN[i] = cm[i, :].sum() - TP[i]
	        TN[i] = cm.sum() - (TP[i] + FP[i] + FN[i])
	
	    # Specificity (TNR), Fall-Out (FPR)
	    specificity = (TN / (TN + FP)).mean()
	    fall_out = (FP / (FP + TN)).mean()
	
	    results[name] = {
	        "Confusion Matrix": cm.tolist(),
	        "Accuracy": accuracy,
	        "Precision (PPV)": precision,
	        "Recall (TPR)": recall_macro,
	        "F1 Score": f1,
	        "Error Rate": error_rate,
	        "Specificity (TNR)": specificity,
	        "Fall-Out (FPR)": fall_out,
	        "AUC Score": auc_score,
	    }
	
	# -----------------------------
	# 9. í‰ê°€ì§€í‘œ ì¶œë ¥
	# -----------------------------
	for name, metrics in results.items():
	    print(f"\n{name} Evaluation Results:")
	    for metric, value in metrics.items():
	        if metric == "Confusion Matrix":
	            print(f"{metric}:\n{value}")
	        else:
	            print(f"{metric}: {value:.4f}")
	
	# -----------------------------
	# 10. ROC Curve (ëª¨ë¸ ë™ì¼ìƒ‰ + í´ë˜ìŠ¤ë³„ ì„ ìŠ¤íƒ€ì¼)
	# -----------------------------
	plt.figure(figsize=(12, 8))
	
	model_colors = {
	    "Logistic Regression": "blue",
	    "Naive Bayes": "orange",
	    "k-Nearest Neighbors": "green",
	    "Support Vector Classifier": "red",
	    "Decision Tree": "purple",
	    "Random Forest": "brown"
	}
	
	linestyles = ['-', '--', '-.', ':', (0, (3, 1, 1, 1))]
	
	for name, model in models.items():
	    # í™•ë¥ ê°’ ê³„ì‚°
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        y_prob = model.predict_proba(X_test_scaled)
	    else:
	        y_prob = model.predict_proba(X_test)
	
	    model_color = model_colors[name]
	
	    for i in range(n_classes):
	        fpr, tpr, _ = roc_curve(y_test, y_prob[:, i], pos_label=i)
	        plt.plot(
	            fpr, tpr,
	            color=model_color,
	            linestyle=linestyles[i % len(linestyles)],
	            linewidth=1.7,
	            label=f"{name} (Class {i})"
	        )
	
	plt.plot([0, 1], [0, 1], "k--", label="Random Guess")
	
	plt.xlabel("False Positive Rate")
	plt.ylabel("True Positive Rate")
	plt.title("ROC Curve (Model-colors unified)")
	plt.legend(loc="center left", bbox_to_anchor=(1, 0.5))
	plt.tight_layout()
	plt.show()

<br>

![](./images/ROC_result2.png)

<br>
	
![](./images/Classification.png)
<br>

ROCë¡œë§Œ í‰ê°€ í–ˆì„ë•Œ ë¶„ë¥˜ëª¨ë¸ì˜ í‰ê°€ìˆœìœ„<br>
(1ìœ„) Logistic Regression<br>
(2ìœ„) Support Vector Classifier<br>
(3ìœ„) Random Forest<br>
(4ìœ„) kNN<br>
(5ìœ„) Naive Bayes<br>
(6ìœ„) Decision Tree<br>

ë‚˜ë¨¸ì§€ ì „ì²´ í‰ê°€ì§€í‘œì˜ ë¶„ë¥˜ëª¨ë¸ì˜ í‰ê°€ìˆœìœ„<br>
(1ìœ„)	Random Forest :	AUCÂ·AccuracyÂ·Specificity ëª¨ë‘ ìƒìœ„ê¶Œ, ì•ˆì •ì <br>
(2ìœ„)	SVC :	AUC ìµœê³ , Accuracy ë†’ìŒ<br>
(3ìœ„)	Logistic Regression : ë‹¨ìˆœí•˜ì§€ë§Œ ì„±ëŠ¥ ì•ˆì •ì <br>
(4ìœ„)	Naive Bayes : AUC ë†’ìœ¼ë‚˜ Accuracy/F1 ë‚®ìŒ<br>
(5ìœ„)	kNN : AUC ë‚®ê³  ë°ì´í„° ìŠ¤ì¼€ì¼ ë¯¼ê°<br>
(6ìœ„)	Decision Tree : AUC/Accuracy ìµœí•˜ìœ„, ê³¼ì í•©<br>

=> ì¢…í•© íŒë‹¨ ê²°ê³¼ : Random Forestê°€ 1ìœ„<br>

---

**ë°ì´í„° ì „ì²˜ë¦¬** <br>
**num = 0 â†’ target = 0 (ì‹¬ì¥ë³‘ ì—†ìŒ)** <br>
**num = 1, 2, 3, 4 â†’ target = 1 (ì‹¬ì¥ë³‘ ìˆìŒ)** <br>

	import pandas as pd
	import numpy as np
	from sklearn.model_selection import train_test_split
	from sklearn.preprocessing import StandardScaler, LabelEncoder
	from sklearn.linear_model import LogisticRegression
	from sklearn.naive_bayes import GaussianNB
	from sklearn.neighbors import KNeighborsClassifier
	from sklearn.svm import SVC
	from sklearn.tree import DecisionTreeClassifier
	from sklearn.ensemble import RandomForestClassifier
	from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score, 
	                             f1_score, roc_auc_score, roc_curve)
	import matplotlib.pyplot as plt
	
	# 1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/heart_disease_uci.csv"
	df = pd.read_csv(data_url)
	
	# 2. ê²°ì¸¡ê°’ í™•ì¸ ë° ì²˜ë¦¬
	print("Missing values in dataset before processing:\n", df.isnull().sum())  # ê²°ì¸¡ê°’ í™•ì¸
	
	# ê²°ì¸¡ê°’ ì²˜ë¦¬
	for col in df.columns:
	    if df[col].dtype == 'object':  # ë²”ì£¼í˜• ë°ì´í„°
	        df[col].fillna(df[col].mode()[0], inplace=True)  # ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´
	    else:  # ìˆ˜ì¹˜í˜• ë°ì´í„°
	        df[col].fillna(df[col].mean(), inplace=True)  # í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
	
	print("Missing values in dataset after processing:\n", df.isnull().sum())  # ê²°ì¸¡ê°’ í™•ì¸
	
	# 3. íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸ ë° ì´ì§„ ë¶„ë¥˜ë¡œ ë³€í™˜
	if 'target' not in df.columns:
	    df.rename(columns={"num": "target"}, inplace=True)  # 'num' ì—´ì„ 'target'ìœ¼ë¡œ ë³€ê²½
	assert 'target' in df.columns, "The dataset does not contain a 'target' column."
	
	if df['target'].nunique() > 2:
	    print("Warning: Detected multiclass target. Converting to binary classification (0/1).")
	    df['target'] = (df['target'] > 0).astype(int)  # 0: ì‹¬ì¥ë³‘ ì—†ìŒ, 1: ì‹¬ì¥ë³‘ ìˆìŒ
	
	# ë…ë¦½ ë³€ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ë¶„ë¦¬
	X = df.drop(["target"], axis=1)  # íƒ€ê²Ÿ ì—´ ì œê±°
	y = df["target"]
	
	# ë²”ì£¼í˜• ì—´ í™•ì¸ ë° ê³ ìœ ê°’ í™•ì¸
	print("\nUnique values in categorical columns before encoding:")
	for col in X.columns:
	    if X[col].dtype == 'object':
	        print(f"{col}: {X[col].unique()}")
	
	# 4. ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
	label_encoders = {}
	categorical_columns = [col for col in X.columns if X[col].dtype == 'object']  # ë¬¸ìì—´ ì»¬ëŸ¼ ìë™ íƒì§€
	for col in categorical_columns:
	    le = LabelEncoder()
	    X[col] = le.fit_transform(X[col])  # ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
	    label_encoders[col] = le
	
	# ë²”ì£¼í˜• ì²˜ë¦¬ í›„ í™•ì¸
	print("\nUnique values in categorical columns after encoding:")
	for col in categorical_columns:
	    print(f"{col}: {X[col].unique()}")
	
	# 5. Train-Test Split
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
	
	# 6. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (k-NN, SVMì—ì„œ í•„ìš”)
	scaler = StandardScaler()
	X_train_scaled = scaler.fit_transform(X_train)
	X_test_scaled = scaler.transform(X_test)
	
	# 7. ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”
	models = {
	    "Logistic Regression": LogisticRegression(),
	    "Naive Bayes": GaussianNB(),
	    "k-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5),
	    "Support Vector Classifier": SVC(probability=True),
	    "Decision Tree": DecisionTreeClassifier(),
	    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
	}
	
	# ê²°ê³¼ ì €ì¥ìš©
	results = {}
	
	# 8. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
	for name, model in models.items():
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        model.fit(X_train_scaled, y_train)  # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©
	        y_pred = model.predict(X_test_scaled)
	        y_prob = model.predict_proba(X_test_scaled)[:, 1]
	    else:
	        model.fit(X_train, y_train)
	        y_pred = model.predict(X_test)
	        y_prob = model.predict_proba(X_test)[:, 1]
	    
	    # í‰ê°€
	    cm = confusion_matrix(y_test, y_pred)
	    acc = accuracy_score(y_test, y_pred)
	    prec = precision_score(y_test, y_pred)
	    rec = recall_score(y_test, y_pred)
	    f1 = f1_score(y_test, y_pred)
	    error_rate = 1 - acc
	    auc = roc_auc_score(y_test, y_prob)
	
	    # ê²°ê³¼ ì €ì¥
	    results[name] = {
	        "Confusion Matrix": cm.tolist(),
	        "Accuracy": acc,
	        "Precision": prec,
	        "Recall (TPR)": rec,
	        "F1 Score": f1,
	        "Error Rate": error_rate,
	        "AUC": auc
	    }
	
	# ê²°ê³¼ ì¶œë ¥
	for name, metrics in results.items():
	    print(f"\n{name} Results:")
	    for metric, value in metrics.items():
	        if metric == "Confusion Matrix":
	            print(f"{metric}:\n{value}")
	        else:
	            print(f"{metric}: {value:.4f}")
	
	# 9. ROC Curve ì‹œê°í™”
	plt.figure(figsize=(10, 6))
	for name, model in models.items():
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        y_prob = model.predict_proba(X_test_scaled)[:, 1]
	    else:
	        y_prob = model.predict_proba(X_test)[:, 1]
	    fpr, tpr, _ = roc_curve(y_test, y_prob)
	    plt.plot(fpr, tpr, label=f"{name} (AUC: {roc_auc_score(y_test, y_prob):.2f})")
	
	plt.plot([0, 1], [0, 1], "k--", label="Random Guess")
	plt.xlabel("False Positive Rate")
	plt.ylabel("True Positive Rate")
	plt.title("ROC Curve")
	plt.legend()
	plt.show()


![](./images/result2.PNG)
<br><br> 


---



