#  12-1 : íšŒê·€ í‰ê°€ ì§€í‘œ

---

	[1] í‰ê·  ì˜¤ì°¨ (Mean Error, ME)
 	[2] í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (Mean Absolute Error, MAE)
	[3] í‰ê·  ì œê³± ì˜¤ì°¨ (Mean Squared Error, MSE)
	[4] í‰ê·  ì œê³± ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Mean Squared Log Error, MSLE)
	[5] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (Root Mean Squared Error, RMSE)
	[6] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Root Mean Squared Log Error, RMSLE)
 	[7] í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (Mean Percentage Error, MPE)
	[8] í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (Mean Absolute Percentage Error, MAPE)
	[9] í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (Mean Absolute Scaled Error, MASE)
	[10] R2 score
	  
---

# [1] í‰ê·  ì˜¤ì°¨ (Mean Error, ME)
![](./images/ME.svg)
<br>
â–£ ì •ì˜: ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´ë¥¼ í‰ê· ë‚¸ ê°’ìœ¼ë¡œ, ì˜¤ì°¨ì˜ ë°©í–¥ì„±ì„ í¬í•¨í•œ ì˜ˆì¸¡ì˜¤ì°¨ì˜ ì‚°ìˆ í‰ê· ì„ ì˜ë¯¸<br>
â–£ í•„ìš”ì„±: ì˜¤ì°¨ê°€ ì–‘ìˆ˜ì¸ì§€ ìŒìˆ˜ì¸ì§€, í‰ê· ì ìœ¼ë¡œ ê³¼ëŒ€í‰ê°€ ë˜ëŠ” ê³¼ì†Œí‰ê°€ë˜ëŠ”ì§€ë¥¼ íŒŒì•…<br>
â–£ ì¥ì : ì˜¤ì°¨ì˜ ë°©í–¥ì„±ì„ ë°˜ì˜í•˜ì—¬ ëª¨ë¸ì˜ í¸í–¥(bias)ì„ ë¶„ì„<br>
â–£ ë‹¨ì : ì–‘ìˆ˜ì™€ ìŒìˆ˜ê°€ ìƒì‡„ë˜ë¯€ë¡œ, ì‹¤ì œ ì˜¤ì°¨ì˜ í¬ê¸°ë¥¼ íŒë‹¨í•˜ê¸° ì–´ë µë‹¤<br>

	def ME(y_true, y_pred):
		return (y_true - y_pred).mean(axis=None)

<br>

# [2] í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (Mean Absolute Error, MAE)
![](./images/MAE.svg)
<br>
â–£ ì •ì˜: ì‹¤ì œ ì •ë‹µ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ ì°¨ì´ë¥¼ ì ˆëŒ“ê°’ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ í•©ì‚°í•˜ì—¬ í‰ê· ì„ êµ¬í•œë‹¤.<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì˜ í‰ê· ì ì¸ ì˜ˆì¸¡ ì˜¤ì°¨ í¬ê¸°ë¥¼ ì§ê´€ì ìœ¼ë¡œ íŒŒì•…, íŠ¹ì´ê°’ì´ ë§ì€ ê²½ìš°ì— ì£¼ë¡œ ì‚¬ìš©<br>
â–£ ì¥ì : ì§ê´€ì ì´ê³  ì •ë‹µ ë° ì˜ˆì¸¡ ê°’ê³¼ ê°™ì€ ë‹¨ìœ„ë¥¼ ê°€ì§€ê³ , MSE, RMSEì— ë¹„í•´ ê·¹ë‹¨ê°’(outlier)ì— ëœ ë¯¼ê°<br>
â–£ ë‹¨ì : ì ˆëŒ“ê°’ì„ ì·¨í•˜ë¯€ë¡œ underestimates/overestimatesì¸ì§€ì— ëŒ€í•œ íŒë‹¨ì„ í•  ìˆ˜ ì—†ìœ¼ë©°, ìŠ¤ì¼€ì¼ ì˜ì¡´ì (scal dependency)ìœ¼ë¡œ ëª¨ë¸ë§ˆë‹¤ ì—ëŸ¬ í¬ê¸°ê°€ ë™ì¼í•´ë„ ì—ëŸ¬ìœ¨ì€ ë™ì¼í•˜ì§€ ì•Šê³ , ì˜¤ì°¨ì˜ ë°©í–¥ì„±ì„ ì•Œ ìˆ˜ ì—†ë‹¤<br>

	def MAE(y_true, y_pred):
    	return (abs(y_true - y_pred)).mean(axis=None)

<br>

	from sklearn.metrics import mean_absolute_error
	
	mae = mean_absolute_error(y_true, y_pred)
   
<br>

# [3] í‰ê·  ì œê³± ì˜¤ì°¨ (Mean Squared Error, MSE)
![](./images/MSE.svg)
<br>
â–£ ì •ì˜: ì‹¤ì œ ì •ë‹µ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ ì°¨ì´ë¥¼ ì œê³±(ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì°¨ì´ì˜ ë©´ì )í•œ ë’¤ í‰ê· ì„ êµ¬í•œë‹¤.<br>
â–£ í•„ìš”ì„±: ì˜¤ì°¨ì˜ í¬ê¸°ë¥¼ ê°•ì¡°í•´ í° ì˜¤ì°¨ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘<br>
â–£ ì¥ì : ì§ê´€ì ì´ë©°, ëª¨ë¸ì˜ í° ì˜¤ì°¨ë¥¼ ë” ì˜ ì‹ë³„ ê°€ëŠ¥<br>
â–£ ë‹¨ì : ì˜ˆì¸¡ ë³€ìˆ˜ì™€ ë‹¨ìœ„ê°€ ë‹¤ë¥´ë©°, ì˜¤ì°¨ë¥¼ ì œê³±í•˜ê¸° ë•Œë¬¸ì— ì´ìƒì¹˜ì— ë¯¼ê°(ì œê³±í•˜ê¸° ë•Œë¬¸ì— 1ë¯¸ë§Œì˜ ì—ëŸ¬ëŠ” ì‘ì•„ì§€ê³  ê·¸ ì´ìƒì˜ ì—ëŸ¬ëŠ” ì»¤ì§), ì œê³±ì„ ì”Œìš°ê²Œ ë˜ì–´ underestimates/overestimatesì¸ì§€ íŒŒì•…í•˜ê¸° í˜ë“¤ë©°, ìŠ¤ì¼€ì¼ ì˜ì¡´ì (scal dependency)ì´ë¼ ëª¨ë¸ë§ˆë‹¤ ì—ëŸ¬ëŸ¬ í¬ê¸°ê°€ ë™ì¼í•´ë„ ì—ëŸ¬ìœ¨ì€ ë™ì¼í•˜ì§€ ì•Šì€ ë‹¨ì . ì˜¤ì°¨ì œê³±í•©(SSE)ì™€ ìœ ì‚¬í•˜ì§€ë§Œ ì˜¤ì°¨ì œê³±í•©ìœ¼ë¡œëŠ” ì‹¤ì œ ì˜¤ì°¨ê°€ ì»¤ì„œ ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì¸ì§€ ë°ì´í„°ì˜ ì–‘ì´ ë§ì•„ì„œ ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì¸ì§€ë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ê²Œ ëœë‹¤.<br>

	def MSE(y_true, y_pred):
    	return ((y_true - y_pred)**2).mean(axis=None)

<br>

	from sklearn.metrics import mean_squared_error
	
	mse = mean_squared_error(y_true, y_pred)

<br>

# [4] í‰ê·  ì œê³± ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Mean Squared Log Error, MSLE)
![](./images/MSLE.svg)
<br>
â–£ ì •ì˜: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ ë¡œê·¸ ì°¨ì´ì— ëŒ€í•œ ì œê³± í‰ê· ìœ¼ë¡œ MSEì— ë¡œê·¸ë¥¼ ì ìš©<br> 
â–£ í•„ìš”ì„±: ì‘ì€ ê°’ì˜ ìƒëŒ€ì ì¸ ì°¨ì´ë¥¼ ê°•ì¡°í•˜ë©° í° ê°’ì˜ ì°¨ì´ë¥¼ ì™„í™”<br>
â–£ ì¥ì : ì‘ì€ ê°’ì— ì§‘ì¤‘í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì— ì í•©(ê²°ì • ê°’ì´ í´ìˆ˜ë¡ ì˜¤ë¥˜ê°’ë„ ì»¤ì§€ê¸° ë•Œë¬¸ì— ì¼ë¶€ í° ì˜¤ë¥˜ê°’ë“¤ë¡œ ì¸í•´ ì „ì²´ ì˜¤ë¥˜ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤)<br>
â–£ ë‹¨ì : ë¡œê·¸ ì—°ì‚°ìœ¼ë¡œ ì¸í•´ ìŒìˆ˜ ê°’ì€ ì²˜ë¦¬ ë¶ˆê°€ëŠ¥<br>

	def MSLE(y_true, y_pred):
		return np.log((y_true - y_pred)**2).mean(axis=None)

<br>

	from sklearn.metrics import mean_squared_log_error

	msle = mean_squared_log_error(y_true, y_pred)

<br>

# [5] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (Root Mean Squared Error, RMSE)
![](./images/RMSE.svg)
<br>
â–£ ì •ì˜: MSEì˜ ì œê³±ê·¼ìœ¼ë¡œ, ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ê°„ì˜ í‰ê· ì  ì°¨ì´ë¥¼ ì› ë‹¨ìœ„ë¡œ í™˜ì‚°<br>
â–£ í•„ìš”ì„±: ë‹¨ìœ„ë¥¼ ì‹¤ì œ ë°ì´í„°ì™€ ë™ì¼í•˜ê²Œ ì¡°ì •<br>
â–£ ì¥ì : í•´ì„ì´ ì‰¬ìš°ë©°, í° ì˜¤ì°¨ë¥¼ ê°•ì¡°(MSEì— ë£¨íŠ¸ëŠ” ì”Œì›Œì„œ ì—ëŸ¬ë¥¼ ì œê³±í•´ì„œ ìƒê¸°ëŠ” ê°’ì˜ ì™œê³¡ì´ ì¤„ì–´ë“ ë‹¤)<br>
â–£ ë‹¨ì : ê·¹ë‹¨ê°’ì— ë¯¼ê°í•˜ê³ , ì œê³± í›„ ë£¨íŠ¸ë¥¼ ì”Œìš°ê¸° ë•Œë¬¸ì— MAEì²˜ëŸ¼ ì‹¤ì œ ê°’ì— ëŒ€í•´ underestimates/overestimatesì¸ì§€ íŒŒì•…í•˜ê¸° í˜ë“¤ê³ , ìŠ¤ì¼€ì¼ ì˜ì¡´ì (scal dependency)ìœ¼ë¡œ ëª¨ë¸ë§ˆë‹¤ ì—ëŸ¬ í¬ê¸°ê°€ ë™ì¼í•´ë„ ì—ëŸ¬ìœ¨ì€ ë™ì¼í•˜ì§€ ì•Šì€ ë‹¨ì <br>

	def RMSE(y_true, y_pred):
		return np.sqrt(((y_true - y_pred) ** 2).mean(axis=None))

<br>

# [6] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸ì ìš©) (Root Mean Squared Log Error, RMSLE)
![](./images/RMSLE.svg)
<br>
â–£ ì •ì˜: MSLEì˜ ì œê³±ê·¼ ê°’ìœ¼ë¡œ, ë¡œê·¸ ì°¨ì´ë¥¼ ì› ë‹¨ìœ„ë¡œ í™˜ì‚°í•œ ê°’ìœ¼ë¡œ RMSEê°’ì— ë¡œê·¸ë¥¼ ì·¨í•œ ê°’<br>
â–£ í•„ìš”ì„±: ì‘ì€ ê°’ì˜ ìƒëŒ€ì  ì°¨ì´ë¥¼ í‰ê°€<br>
â–£ ì¥ì : ìƒëŒ€ì  ì˜¤ì°¨ì— ê°•ì (ê²°ì • ê°’ì´ í´ ìˆ˜ë¡ ì˜¤ë¥˜ ê°’ë„ ì»¤ì§€ê¸° ë•Œë¬¸ì— ì¼ë¶€ í° ì˜¤ë¥˜ ê°’ë“¤ë¡œì¸í•´ ì „ì²´ ì˜¤ë¥˜ê°’ì´ ì»¤ì§€ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤)<br>
â–£ ë‹¨ì : ìŒìˆ˜ ê°’ ë¶ˆê°€<br>

	def RMSLE(y_true, y_pred):
		return np.log(np.sqrt(((y_true - y_pred) ** 2).mean(axis=None)))

<br>

# [7] í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (Mean Percentage Error, MPE)
![](./images/MPE.svg)
<br>
â–£ ì •ì˜: ì˜¤ì°¨ë¥¼ ì‹¤ì œê°’ì— ëŒ€í•œ ë°±ë¶„ìœ¨ë¡œ ê³„ì‚°í•´ í‰ê· <br>
â–£ í•„ìš”ì„±: ì˜ˆì¸¡ ì˜¤ì°¨ì˜ ë°©í–¥ì„±ê³¼ ë°±ë¶„ìœ¨ í¬ê¸°ë¥¼ íŒŒì•…, ì ˆëŒ€ì ì¸ ì˜ë¯¸ì˜ ì˜ˆì¸¡ì˜¤ì°¨ë¿ ì•„ë‹ˆë¼ ìƒëŒ€ì ì¸ ì˜ë¯¸ì˜ ì˜ˆì¸¡ì˜¤ì°¨ê°€ í•„ìš”í•  ê²½ìš°ì— ê³„ì‚°<br>
â–£ ì¥ì : ìƒëŒ€ì  í¬ê¸° ë¹„êµ ê°€ëŠ¥(ìŒìˆ˜ë©´ overperformance, ì–‘ìˆ˜ë©´ underperformanceìœ¼ë¡œ íŒë‹¨), ëª¨ë¸ì´ underestimates/overestimatesì¸ì§€ íŒë‹¨í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì <br>
â–£ ë‹¨ì : ì‹¤ì œê°’ì´ 0ì¼ ë•Œ ê³„ì‚° ë¶ˆê°€<br>

	def MPE(y_true, y_pred):
		return (((y_true - y_pred)/y_true)*100).mean(axis=None)

<br>

# [8] í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (Mean Absolute Percentage Error, MAPE)
![](./images/MAPE.svg)
<br>
â–£ ì •ì˜: ì ˆëŒ€ ì˜¤ì°¨ë¥¼ ë°±ë¶„ìœ¨ë¡œ ê³„ì‚°í•´ í‰ê· (MAEë¥¼ ë¹„ìœ¨, í¼ì„¼íŠ¸ë¡œ í‘œí˜„í•˜ì—¬ ìŠ¤ì¼€ì¸ ì˜ì¡´ì  ì—ëŸ¬ì˜ ë¬¸ì œì ì„ ê°œì„ )<br>
â–£ í•„ìš”ì„±: ì˜¤ì°¨ë¥¼ ìƒëŒ€ì ìœ¼ë¡œ í‰ê°€<br>
â–£ ì¥ì  : ì§ê´€ì ì´ê³ , ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì—ëŸ¬ìœ¨ ë¹„êµê°€ ì‰¬ìš´ ì¥ì <br>
â–£ ë‹¨ì : 0ê°’ ë¬¸ì œì™€ ê·¹ë‹¨ê°’ì— ë¯¼ê°(ì‹¤ì œ ì •ë‹µë³´ë‹¤ ë‚®ê²Œ ì˜ˆì¸¡í–ˆëŠ”ì§€, ë†’ê²Œ í–ˆëŠ”ì§€ë¥¼ íŒŒì•…í•˜ê¸° í˜ë“¤ê³  ì‹¤ì œ ì •ë‹µì´ 1ë³´ë‹¤ì‘ì„ ê²½ìš°,ë¬´í•œëŒ€ì˜ ê°’ìœ¼ë¡œ ìˆ˜ë ´)<br>

	def MAPE(y_true, y_pred):
		return ((abs((y_true - y_pred)/y_true))*100).mean(axis=None)

<br>
	
	from sklearn.metrics import mean_absolute_percentage_error
	
	mape = mean_absolute_percentage_error(y_true, y_pred)

<br>

# [9] í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (Mean Absolute Scaled Error, MASE)
<!-- ![](./images/MASE.svg) ![](./images/MASE1.svg) -->
![](./images/[9].png)
<br>
â–£ ì •ì˜: ì˜ˆì¸¡ê°’ì˜ ì˜¤ì°¨ë¥¼ ê¸°ì¤€ ì‹œì ì˜ ì˜¤ì°¨ì™€ ë¹„êµí•˜ì—¬ ë¹„ìœ¨í™”(ë°ì´í„°ë¥¼ ì²™ë„í™”í•˜ì—¬ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ì˜¤ì°¨ì˜ ì ˆëŒ€ê°’ì— ëŒ€í•œ í‰ê· )<br>
â–£ í•„ìš”ì„±: ë°ì´í„°ì— ë”°ë¼ ìœ ì—°í•œ í‰ê°€ ê°€ëŠ¥<br>
â–£ ì¥ì : ìŠ¤ì¼€ì¼ì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë‚®ì•„ì„œ ì•ˆì •ì ìœ¼ë¡œ ë¹„êµ ê°€ëŠ¥<br>
â–£ ë‹¨ì : í•´ì„ì´ ìƒëŒ€ì ìœ¼ë¡œ ì–´ë µë‹¤<br>

	def MASE(y_true, y_pred):
    	mae = np.mean(np.abs(y_true - y_pred))
    	naive_mae = np.mean(np.abs(y_true[1:] - y_true[:-1]))
    	return mae / naive_mae

	mase = MASE(y_true, y_pred)

<br>

# [10] R2 score
â–£ ì •ì˜: ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œë¡œ **SST(Total Sum of Squares)** ê´€ì¸¡ê°’ì—ì„œ ê´€ì¸¡ê°’ì˜ í‰ê· (í˜¹ì€ ì¶”ì •ì¹˜ì˜ í‰ê· )ì„ ëº€ ê²°ê³¼ì˜ ì´í•©ì¸ ì´ ì œê³±í•©<br>
â–£ í•„ìš”ì„±: ì „ì²´(Total)ì— ëŒ€í•œ ë³€ë™ì„±ì„ ë‚˜íƒ€ëƒ„ìœ¼ë¡œì¨ ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ íŒŒì•…<br>
â–£ ì¥ì : ì§ê´€ì <br>
â–£ ë‹¨ì : ëª¨ë¸ì´ ìµœì†Œí•œì˜ ê¸°ì¤€ë„ ë§Œì¡±í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ëŠ” ìŒìˆ˜ê°€ ë  ìˆ˜ ìˆìŒ<br>
![](./images/f_R2.png)
<br>
![](./images/ff_SST.png)
<br>


	from sklearn.metrics import r2_score

	r2 = r2_score(y_true, y_pred)


**(íšŒê·€ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤)**

	# ============================================
	# Iris ë°ì´í„° ê¸°ë°˜ íšŒê·€ í‰ê°€ì§€í‘œ 10ê°œ + í•´ì„í‘œ ì¶œë ¥ ì½”ë“œ
	#  - íƒ€ê¹ƒ: sepal length (ì²« ë²ˆì§¸ ì»¬ëŸ¼)
	#  - íŠ¹ì§•: ë‚˜ë¨¸ì§€ 3ê°œ(sepal width, petal length, petal width)
	# ============================================
	import numpy as np	
	from sklearn.metrics import (
	    mean_absolute_error,
	    mean_squared_error,
	    mean_squared_log_error,
	    mean_absolute_percentage_error,
	    r2_score)
	from sklearn.linear_model import LinearRegression
	from sklearn.model_selection import train_test_split
	from sklearn.datasets import load_iris
		
	# ------------------------------------------------------------------
	# 1. ì‚¬ìš©ì ì •ì˜ í‰ê°€ì§€í‘œ í•¨ìˆ˜ë“¤
	# ------------------------------------------------------------------
	# [1] í‰ê·  ì˜¤ì°¨ (ME, Mean Error)
	def mean_error(y_true, y_pred):	    
	    y_true = np.asarray(y_true)
	    y_pred = np.asarray(y_pred)
	    return np.mean(y_true - y_pred)
	
	# [5] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE)
	def rmse(y_true, y_pred):	    
	    return np.sqrt(mean_squared_error(y_true, y_pred))

	# [6] í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸ì ìš©) (RMSLE)	
	def rmsle(y_true, y_pred):
	    return np.sqrt(mean_squared_log_error(y_true, y_pred))
	
	# [7] í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (MPE, Mean Percentage Error)
	def mean_percentage_error(y_true, y_pred):
	    y_true = np.asarray(y_true)
	    y_pred = np.asarray(y_pred)
	    return np.mean((y_true - y_pred) / y_true)
	
	# [9] í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ (MASE, Mean Absolute Scaled Error)
	#     ë³¸ë˜ëŠ” ì‹œê³„ì—´(time series)ì—ì„œ ë§ì´ ì‚¬ìš©
	#     ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¥¼ ìœ„í•´ ìƒ˜í”Œ ìˆœì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ naive forecast ì‚¬ìš©
	def mase(y_true, y_pred):
	    y_true = np.asarray(y_true)
	    y_pred = np.asarray(y_pred)
	    mae = np.mean(np.abs(y_true - y_pred))
	    # naive forecast: í•œ ì‹œì  ì „ ê°’(y_{t-1})ì„ ì˜ˆì¸¡ìœ¼ë¡œ ì‚¬ìš©
	    naive_mae = np.mean(np.abs(y_true[1:] - y_true[:-1]))
	    return mae / naive_mae
	
	# ------------------------------------------------------------------
	# 2. í•´ì„ í•¨ìˆ˜ë“¤ (ì¢‹ìŒ / ë³´í†µ / ë‚˜ì¨) + ê¸°ì¤€ ë¬¸ìì—´
	# ------------------------------------------------------------------
	CRITERIA_ERROR_RELATIVE = "ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨"
	CRITERIA_MSLE_RMSLE     = "RMSLE<0.1:ì¢‹ìŒ, 0.1â‰¤RMSLE<0.2:ë³´í†µ, RMSLEâ‰¥0.2:ë‚˜ì¨"
	CRITERIA_PERCENTAGE     = "|ì˜¤ì°¨|<10%:ì¢‹ìŒ, 10~20%:ë³´í†µ, 20% ì´ˆê³¼:ë‚˜ì¨"
	CRITERIA_MASE           = "MASE<1:ì¢‹ìŒ, 1â‰¤MASE<2:ë³´í†µ, MASEâ‰¥2:ë‚˜ì¨"
	CRITERIA_R2             = "R2â‰¥0.8:ì¢‹ìŒ, 0.5â‰¤R2<0.8:ë³´í†µ, R2<0.5:ë‚˜ì¨"
		
	def interpret_error_relative(value, scale):
	    if scale == 0: return "í‰ê°€ë¶ˆê°€"
	
	    ratio = abs(value) / scale  # ìƒëŒ€ì˜¤ì°¨ ë¹„ìœ¨	
	    if ratio < 0.25: return "ì¢‹ìŒ"
	    elif ratio < 0.5: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_msle_rmsle(rmsle_value):
	    if rmsle_value < 0.1: return "ì¢‹ìŒ"
	    elif rmsle_value < 0.2: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_percentage_metric(perc_value):
	    perc = abs(perc_value) * 100  # %	
	    if perc < 10: return "ì¢‹ìŒ"
	    elif perc < 20: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_mase(mase_value):
	    if mase_value < 1: return "ì¢‹ìŒ"
	    elif mase_value < 2: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
		
	def interpret_r2(r2_value):	
	    if r2_value >= 0.8: return "ì¢‹ìŒ"
	    elif r2_value >= 0.5: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# ------------------------------------------------------------------
	# 3. Iris ë°ì´í„° ë¡œë“œ ë° íšŒê·€ ë¬¸ì œë¡œ êµ¬ì„±
	# ------------------------------------------------------------------	
	iris = load_iris()
	X_all = iris.data  # shape: (150, 4) -> [sepal length, sepal width, petal length, petal width]
	
	# íƒ€ê¹ƒ: sepal length (0ë²ˆì§¸ ì»¬ëŸ¼)
	y = X_all[:, 0]
	
	# íŠ¹ì§•: ë‚˜ë¨¸ì§€ 3ê°œ (sepal width, petal length, petal width)
	X = X_all[:, 1:]   # shape: (150, 3)
	
	# train / test ë¶„í• 
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
	
	# ì„ í˜•íšŒê·€ ëª¨ë¸ í•™ìŠµ
	model = LinearRegression()
	model.fit(X_train, y_train)
	
	# ì˜ˆì¸¡ê°’
	y_pred = model.predict(X_test)
	
	# íƒ€ê¹ƒ ìŠ¤ì¼€ì¼(í‘œì¤€í¸ì°¨) ê³„ì‚° (ì˜¤ì°¨ ê³„ì—´ í•´ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©)
	y_std = np.std(y_test)
		
	# ------------------------------------------------------------------
	# 4. 10ê°œ í‰ê°€ì§€í‘œ ê³„ì‚°
	# ------------------------------------------------------------------
	# [1] ME
	ME = mean_error(y_test, y_pred)
	# [2] MAE
	MAE = mean_absolute_error(y_test, y_pred)
	# [3] MSE
	MSE = mean_squared_error(y_test, y_pred)
	# [4] MSLE
	MSLE = mean_squared_log_error(y_test, y_pred)
	# [5] RMSE
	RMSE = rmse(y_test, y_pred)
	# [6] RMSLE
	RMSLE = rmsle(y_test, y_pred)
	# [7] MPE
	MPE = mean_percentage_error(y_test, y_pred)
	# [8] MAPE
	MAPE = mean_absolute_percentage_error(y_test, y_pred)
	# [9] MASE
	MASE = mase(y_test, y_pred)
	# [10] R2 score
	R2 = r2_score(y_test, y_pred)
		
	# ------------------------------------------------------------------
	# 5. í•´ì„ í…Œì´ë¸” êµ¬ì„± (ì§€í‘œëª…, ê°’, í•´ì„, ê¸°ì¤€)
	# ------------------------------------------------------------------
	rows = []	
	rows.append(("[1] ME",ME,interpret_error_relative(ME, y_std), CRITERIA_ERROR_RELATIVE))
	rows.append(("[2] MAE",MAE,interpret_error_relative(MAE, y_std),CRITERIA_ERROR_RELATIVE))
	# MSEëŠ” ì œê³± ë‹¨ìœ„ì´ë¯€ë¡œ í•´ì„ì€ RMSE ê¸°ì¤€ ì‚¬ìš©
	rows.append(("[3] MSE",MSE,interpret_error_relative(np.sqrt(MSE), y_std), CRITERIA_ERROR_RELATIVE + " (RMSE ê¸°ì¤€)"))
	rows.append(("[4] MSLE",MSLE,interpret_msle_rmsle(np.sqrt(MSLE)), CRITERIA_MSLE_RMSLE))
	rows.append(("[5] RMSE",RMSE,interpret_error_relative(RMSE, y_std), CRITERIA_ERROR_RELATIVE))
	rows.append(("[6] RMSLE",RMSLE,interpret_msle_rmsle(RMSLE), CRITERIA_MSLE_RMSLE))
	rows.append(("[7] MPE",MPE,interpret_percentage_metric(MPE), CRITERIA_PERCENTAGE))
	rows.append(("[8] MAPE",MAPE,interpret_percentage_metric(MAPE), CRITERIA_PERCENTAGE))
	rows.append(("[9] MASE",MASE,interpret_mase(MASE), CRITERIA_MASE))
	rows.append(("[10] R2",R2,interpret_r2(R2), CRITERIA_R2))
		
	# ------------------------------------------------------------------
	# 6. ê²°ê³¼ ì¶œë ¥
	# ------------------------------------------------------------------	
	print("=== Regression Metrics on Iris (Target: Sepal Length) ===\n")
	# ì„¸ë¶€ ê°’ ë¨¼ì € ì¶œë ¥
	print(">> Raw Metric Values")
	print(f"[1]  Mean Error (ME)                     : {ME:.4f}")
	print(f"[2]  Mean Absolute Error (MAE)           : {MAE:.4f}")
	print(f"[3]  Mean Squared Error (MSE)            : {MSE:.4f}")
	print(f"[4]  Mean Squared Log Error (MSLE)       : {MSLE:.4f}")
	print(f"[5]  Root Mean Squared Error (RMSE)      : {RMSE:.4f}")
	print(f"[6]  Root Mean Squared Log Error (RMSLE) : {RMSLE:.4f}")
	print(f"[7]  Mean Percentage Error (MPE)         : {MPE:.4f}")
	print(f"[8]  Mean Abs Percentage Error (MAPE)    : {MAPE:.4f}")
	print(f"[9]  Mean Abs Scaled Error (MASE)        : {MASE:.4f}")
	print(f"[10] R2 Score                             : {R2:.4f}")
	print()

	# í•´ì„ í‘œ ì¶œë ¥
	print(">> í•´ì„ í…Œì´ë¸” (íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€, ë°ì´í„° ìŠ¤ì¼€ì¼ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)")
	print("-" * 110)
	print(f"{'ì§€í‘œ':<10}{'ê°’':>12}{'í•´ì„(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)':>16}{'ê¸°ì¤€':>70}")
	print("-" * 110)
	for name, value, interp, crit in rows:
    # ê¸°ì¤€ ë¬¸ìì—´ì´ ê¸¸ì–´ì„œ ê·¸ëŒ€ë¡œ ë’¤ì— ë¶™ì—¬ì¤Œ
    	print(f"{name:<10}{value:>12.4f}{interp:>16}  {crit}")
	print("-" * 110)

<br>

**(íšŒê·€ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤ ì‹¤í–‰ ê²°ê³¼)**
	
	=== Regression Metrics on Iris (Target: Sepal Length) ===
	>> Raw Metric Values
	[1]  Mean Error (ME)                     : 0.0892
	[2]  Mean Absolute Error (MAE)           : 0.2469
	[3]  Mean Squared Error (MSE)            : 0.0981
	[4]  Mean Squared Log Error (MSLE)       : 0.0021
	[5]  Root Mean Squared Error (RMSE)      : 0.3132
	[6]  Root Mean Squared Log Error (RMSLE) : 0.0454
	[7]  Mean Percentage Error (MPE)         : 0.0123
	[8]  Mean Abs Percentage Error (MAPE)    : 0.0419
	[9]  Mean Abs Scaled Error (MASE)        : 0.2912
	[10] R2 Score                             : 0.8526

	>> í•´ì„ í…Œì´ë¸” (íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€, ë°ì´í„° ìŠ¤ì¼€ì¼ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
	--------------------------------------------------------------------------------------------------------------
	ì§€í‘œ            ê°’    í•´ì„(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)  ê¸°ì¤€
	--------------------------------------------------------------------------------------------------------------
	[1] ME          0.0892              ì¢‹ìŒ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨
	[2] MAE         0.2469              ë³´í†µ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨
	[3] MSE         0.0981              ë³´í†µ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨ (RMSE ê¸°ì¤€)
	[4] MSLE        0.0021              ì¢‹ìŒ  RMSLE<0.1:ì¢‹ìŒ, 0.1â‰¤RMSLE<0.2:ë³´í†µ, RMSLEâ‰¥0.2:ë‚˜ì¨
	[5] RMSE        0.3132              ë³´í†µ  ratio<0.25:ì¢‹ìŒ, 0.25â‰¤ratio<0.5:ë³´í†µ, ratioâ‰¥0.5:ë‚˜ì¨
	[6] RMSLE       0.0454              ì¢‹ìŒ  RMSLE<0.1:ì¢‹ìŒ, 0.1â‰¤RMSLE<0.2:ë³´í†µ, RMSLEâ‰¥0.2:ë‚˜ì¨
	[7] MPE         0.0123              ì¢‹ìŒ  |ì˜¤ì°¨|<10%:ì¢‹ìŒ, 10~20%:ë³´í†µ, 20% ì´ˆê³¼:ë‚˜ì¨
	[8] MAPE        0.0419              ì¢‹ìŒ  |ì˜¤ì°¨|<10%:ì¢‹ìŒ, 10~20%:ë³´í†µ, 20% ì´ˆê³¼:ë‚˜ì¨
	[9] MASE        0.2912              ì¢‹ìŒ  MASE<1:ì¢‹ìŒ, 1â‰¤MASE<2:ë³´í†µ, MASEâ‰¥2:ë‚˜ì¨
	[10] R2         0.8526              ì¢‹ìŒ  R2â‰¥0.8:ì¢‹ìŒ, 0.5â‰¤R2<0.8:ë³´í†µ, R2<0.5:ë‚˜ì¨
	--------------------------------------------------------------------------------------------------------------

<br>

|  í‰ê°€ì§€í‘œ           | ì¢‹ìŒ                             | ë³´í†µ                          | ë‚˜ì¨     |
|--------------------|----------------------------------|-------------------------------|----------|
| **[1] ME** í‰ê·  ì˜¤ì°¨           | &#124;ME&#124; / Ïƒ(y) < 0.25       | 0.25 â‰¤ &#124;ME&#124;/Ïƒ < 0.5     | â‰¥ 0.5    |
| **[2] MAE** í‰ê·  ì ˆëŒ€ ì˜¤ì°¨     | MAE / Ïƒ(y) < 0.25                 | 0.25 â‰¤ MAE/Ïƒ < 0.5            | â‰¥ 0.5    |
| **[3] MSE** í‰ê·  ì œê³± ì˜¤ì°¨     | âˆšMSE / Ïƒ(y) < 0.25                | 0.25 â‰¤ âˆšMSE/Ïƒ < 0.5           | â‰¥ 0.5    |
| **[4] MSLE** í‰ê·  ì œê³± ì˜¤ì°¨(ë¡œê·¸) | RMSLE < 0.10                      | 0.10 ~ 0.20                    | â‰¥ 0.20   |
| **[5] RMSE** í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨  | RMSE / Ïƒ(y) < 0.25                | 0.25 â‰¤ RMSE/Ïƒ < 0.5           | â‰¥ 0.5    |
| **[6] RMSLE** í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(ë¡œê·¸) | RMSLE < 0.10                      | 0.10 ~ 0.20                    | â‰¥ 0.20   |
| **[7] MPE** í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨     | &#124;MPE&#124; < 10%              | 10% ~ 20%                      | â‰¥ 20%    |
| **[8] MAPE** í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ | MAPE < 10%                         | 10% ~ 20%                      | > 20%    |
| **[9] MASE** í‰ê·  ì ˆëŒ€ ê·œëª¨ ì˜¤ì°¨ | MASE < 1                           | 1 ~ 2                          | â‰¥ 2      |
| **[10] RÂ²** ê²°ì •ê³„ìˆ˜            | RÂ² â‰¥ 0.80                          | 0.50 â‰¤ RÂ² < 0.80              | < 0.50   |




![](./images/SST.png)
<br>
ì¶œì²˜ : https://medium.com/coders-mojo/data-science-and-machine-learning-projects-mega-compilation-part-5-e50baa2faa85<br>

## SST(Total Sum of Squares) : ì´ ë³€ë™
â–£ ì •ì˜ : ë°ì´í„°ì˜ ì´ ë³€ë™ëŸ‰ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œë¡œ, ì‹¤ì œê°’($ğ‘¦_ğ‘–$)ê³¼ í‰ê· ê°’($\overline{y}$) ê°„ì˜ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í•©í•œ ê°’ìœ¼ë¡œ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ë¶„ì‚°ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„<br>
â–£ í•„ìš”ì„± : íšŒê·€ ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ê¸°ì¤€ì„ ì´ ë˜ê³ , ëª¨ë¸ ì—†ì´ë„ ë°ì´í„°ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë³€ë™ì„±ì„ ê³„ì‚°<br>
â–£ ì¥ì  : ë°ì´í„°ì˜ ì „ì²´ ë³€ë™ëŸ‰ì„ ëª…í™•íˆ ê³„ì‚°í•˜ì—¬ ëª¨ë¸ í‰ê°€ì˜ ê¸°ë³¸ ì²™ë„ê°€ ë˜ë©°, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ SSR, SSEì™€ í•¨ê»˜ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨<br>
â–£ ë‹¨ì  : ì‹¤ì œê°’ì˜ ë³€ë™ëŸ‰ë§Œ ì¸¡ì •í•  ë¿, ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ëŠ” ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ì´ ì—†ìœ¼ë©°, ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ì´ë‚˜ ë‹¨ìœ„ì— ë¯¼ê°í•˜ì—¬ í¬ê¸°ê°€ í¬ê²Œ ë³€í•  ìˆ˜ ìˆìŒ<br>
![](./images/f_SST.png)
<br>


## SSR(Sum of Squares due to Regression) : íšŒê·€ì— ì˜í•œ ë³€ë™
â–£ ì •ì˜ : ì˜ˆì¸¡ê°’(ğ‘¦^ğ‘–)ê³¼ í‰ê· ê°’($\overline{y}$)ì˜ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í•©í•œ ê°’ìœ¼ë¡œ ëª¨ë¸ì´ ì‹¤ì œ ë°ì´í„°ì˜ ë³€ë™ ì¤‘ì—ì„œ ì„¤ëª…í•œ ë³€ë™ëŸ‰ì„ ë‚˜íƒ€ëƒ„<br>
â–£ í•„ìš”ì„± : ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ë°ì´í„°ë¥¼ ì„¤ëª…í–ˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ì²™ë„ë¡œ, RÂ² Score ê³„ì‚°ì—ì„œ í•µì‹¬ ì—­í• ì„ í•˜ë©°, ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤Œ<br>
â–£ ì¥ì  : ëª¨ë¸ì´ ë°ì´í„° íŒ¨í„´ì„ ì–¼ë§ˆë‚˜ ì˜ íŒŒì•…í–ˆëŠ”ì§€ ëª…í™•íˆ ë‚˜íƒ€ë‚´ë©°, ğ‘†ğ‘†ğ‘…ì´ í´ìˆ˜ë¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ìš°ìˆ˜í•¨ì„ ì˜ë¯¸<br>
â–£ ë‹¨ì  : ë‹¨ë…ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ ê³¼ì í•© ì—¬ë¶€ë¥¼ í‰ê°€í•˜ê¸° ì–´ë µê³ , ë°ì´í„°ì— ì¡ìŒ(noise)ì´ ë§ì„ ê²½ìš° ì˜ëª»ëœ ì„¤ëª…ë ¥ì„ ì¸¡ì •<br>
![](./images/f_SSR.png)
<br>


## SSE(Sum of Squares Residual of Error) : ì”ì°¨ ì œê³±í•©
â–£ ì •ì˜ : ì‹¤ì œê°’($ğ‘¦_ğ‘–$)ê³¼ ì˜ˆì¸¡ê°’($\widehat{y_i}$)ì˜ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í•©í•œ ê°’ìœ¼ë¡œ ëª¨ë¸ì´ ì„¤ëª…í•˜ì§€ ëª»í•œ ë°ì´í„°ì˜ ë³€ë™ëŸ‰(ì”ì°¨)ì„ ë‚˜íƒ€ëƒ„<br>
â–£ í•„ìš”ì„± : ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ë©°, ì”ì°¨ ë¶„ì„ì„ í†µí•´ ëª¨ë¸ ê°œì„  ë°©í–¥ì„ ì œì‹œ<br>
â–£ ì¥ì  : ëª¨ë¸ì˜ í•œê³„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆìœ¼ë©°, SSEê°€ ì‘ì„ìˆ˜ë¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ìŒì„ ì˜ë¯¸<br>
â–£ ë‹¨ì  : SSEì˜ í¬ê¸°ê°€ ë°ì´í„°ì˜ í¬ê¸°ì™€ ë‹¨ìœ„ì— ë”°ë¼ í¬ê²Œ ë³€í•˜ë©°, ê·¹ë‹¨ê°’(outliers)ì— ë¯¼ê°í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì´ ì™œê³¡ë  ìˆ˜ ìˆìŒ<br>
![](./images/f_SSE.png)
<br>

---

![](./images/ff_R2.png)
<br>

---

**(ë°ì´í„°êµ¬ì¡°)** ![](./images/db.png)
<br>
**(ë°ì´í„°ì…‹)** https://github.com/YangGuiBee/ML/blob/main/TextBook-12/insurance.csv
<br>

	################################################################################
	# ë°ì´í„° ì‹œê°í™”
	################################################################################
	
	import pandas as pd
	import seaborn as sns
	import matplotlib.pyplot as plt
	
	# Load dataset from URL
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/insurance.csv"
	df = pd.read_csv(data_url)
	
	# Ensure categorical columns are treated as categories
	df['sex'] = df['sex'].astype('category')
	df['smoker'] = df['smoker'].astype('category')
	df['region'] = df['region'].astype('category')
	
	# Basic information about the dataset
	print("Dataset Information:")
	print(df.info())
	print("\nBasic Statistics:")
	print(df.describe())
	
	# Visualizations
	plt.figure(figsize=(14, 10))
	
	# Distribution of Charges
	plt.subplot(3, 2, 1)
	sns.histplot(df['charges'], kde=True, bins=30, color='blue')
	plt.title('Distribution of Charges')
	plt.xlabel('Charges')
	plt.ylabel('Frequency')
	
	# Age Distribution
	plt.subplot(3, 2, 2)
	sns.histplot(df['age'], kde=True, bins=20, color='green')
	plt.title('Age Distribution')
	plt.xlabel('Age')
	plt.ylabel('Frequency')
	
	# BMI vs Charges
	plt.subplot(3, 2, 3)
	sns.scatterplot(x='bmi', y='charges', data=df, hue='smoker', palette='Set1', alpha=0.7)
	plt.title('BMI vs Charges')
	plt.xlabel('BMI')
	plt.ylabel('Charges')
	
	# Region Counts
	plt.subplot(3, 2, 4)
	sns.countplot(x='region', data=df, palette='Set2')
	plt.title('Region Counts')
	plt.xlabel('Region')
	plt.ylabel('Count')
	
	# Charges by Smoker
	plt.subplot(3, 2, 5)
	sns.boxplot(x='smoker', y='charges', data=df, palette='Set1')
	plt.title('Charges by Smoker')
	plt.xlabel('Smoker')
	plt.ylabel('Charges')
	
	# Children Distribution
	plt.subplot(3, 2, 6)
	sns.countplot(x='children', data=df, palette='Set3')
	plt.title('Children Distribution')
	plt.xlabel('Number of Children')
	plt.ylabel('Count')
	
	plt.tight_layout()
	plt.show()
	
	# Correlation Heatmap (Numerical Columns Only)
	plt.figure(figsize=(10, 8))
	numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
	sns.heatmap(df[numerical_columns].corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
	plt.title('Correlation Heatmap')
	plt.show()

<br>

![](./images/data.png)
<br>

![](./images/data2.png)
<br>

	################################################################################
	# Multiple Linear Regression 
	# Decision Tree Regression
	################################################################################
	
	# Check and install necessary packages
	import subprocess
	import sys
	
	def install(package):
	    try:
	        __import__(package)
	    except ImportError:
	        print(f"Installing {package}...")
	        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
	
	# List of required packages
	required_packages = ['pandas', 'scikit-learn', 'xgboost', 'lightgbm', 'numpy']
	for package in required_packages:
	    install(package)
	
	# Import libraries
	import pandas as pd
	import numpy as np
	from sklearn.model_selection import train_test_split
	from sklearn.preprocessing import OneHotEncoder
	from sklearn.linear_model import LinearRegression
	from sklearn.tree import DecisionTreeRegressor
	from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
	
	# Load dataset from URL
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/insurance.csv"
	df = pd.read_csv(data_url)
	
	# Check and handle missing values
	print("Checking for missing values...")
	print(df.isnull().sum())  # Display the count of NaN values per column
	
	# Ensure no missing values
	assert not df.isnull().values.any(), "Data contains missing values!"
	
	# Preprocessing
	X = df.drop("charges", axis=1)
	y = df["charges"]
	categorical_features = ["sex", "smoker", "region"]
	numerical_features = ["age", "bmi", "children"]
	
	# Updated sparse_output instead of sparse
	encoder = OneHotEncoder(sparse_output=False, drop="first")
	X_encoded = encoder.fit_transform(X[categorical_features])
	X_numerical = X[numerical_features]
	
	X_preprocessed = pd.DataFrame(
	    np.hstack([X_numerical, X_encoded]),
	    columns=numerical_features + encoder.get_feature_names_out().tolist()
	)
	
	# Train-test split
	X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)
	
	# Evaluation metrics
	def evaluate_model(y_true, y_pred):
	    me = np.mean(y_pred - y_true)  # í‰ê·  ì˜¤ì°¨ (ì˜ˆì¸¡ê°’ - ì‹¤ì œê°’)
	    mae = mean_absolute_error(y_true, y_pred)  # í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
	    mse = mean_squared_error(y_true, y_pred)  # í‰ê·  ì œê³± ì˜¤ì°¨
	    rmse = np.sqrt(mse)  # í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨
	
	    # Conditional MSLE calculation
	    if (y_true > 0).all() and (y_pred > 0).all():
	        msle = mean_squared_error(np.log1p(y_true), np.log1p(y_pred))  # í‰ê·  ì œê³± ì˜¤ì°¨ (ë¡œê·¸ ì ìš©)
	        rmsle = np.sqrt(msle)  # í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (ë¡œê·¸ ì ìš©)
	    else:
	        msle = np.nan
	        rmsle = np.nan
	
	    mpe = np.mean((y_pred - y_true) / y_true) * 100  # í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨
	    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨
	    r2 = r2_score(y_true, y_pred)  # R2 ì ìˆ˜
	
	    return {
	        "ME": me,
	        "MAE": mae,
	        "MSE": mse,
	        "MSLE": msle,
	        "RMSE": rmse,
	        "RMSLE": rmsle,
	        "MPE": mpe,
	        "MAPE": mape,
	        "R2": r2,
	    }
	
	# Initialize models
	models = {
	    "Multiple Linear Regression": LinearRegression(),
	    "Decision Tree Regression": DecisionTreeRegressor(),
	}
	
	# Train and evaluate models
	results = {}
	for name, model in models.items():
	    model.fit(X_train, y_train)
	    y_pred = model.predict(X_test)
	
	    # Check for invalid prediction values
	    if (y_pred < 0).any():
	        print(f"Warning: Model {name} produced negative predictions. Adjusting values to zero.")
	        y_pred = np.maximum(y_pred, 0)  # Replace negative predictions with 0
	
	    results[name] = evaluate_model(y_test, y_pred)
	
	# Format evaluation results for consistent decimal places
	evaluation_results = pd.DataFrame(results)
	evaluation_results = evaluation_results.applymap(lambda x: f"{x:.6f}" if pd.notnull(x) else "NaN")
	
	# Display formatted results
	print("\nModel Evaluation Results:")
	print(evaluation_results)
	
	# Add explanations for each metric in Korean
	metric_explanations = {
	    "ME": "í‰ê·  ì˜¤ì°¨ (Mean Error): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ í‰ê·  ì°¨ì´. 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MAE": "í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (Mean Absolute Error): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì ˆëŒ€ì  ì°¨ì´ì˜ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MSE": "í‰ê·  ì œê³± ì˜¤ì°¨ (Mean Squared Error): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì œê³± ì°¨ì´ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MSLE": "í‰ê·  ì œê³± ì˜¤ì°¨ (ë¡œê·¸ ì ìš©, Mean Squared Log Error): ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œì˜ í‰ê·  ì œê³± ì˜¤ì°¨. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "RMSE": "í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (Root Mean Squared Error): í‰ê·  ì œê³± ì˜¤ì°¨ì˜ ì œê³±ê·¼. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "RMSLE": "í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (ë¡œê·¸ ì ìš©, Root Mean Squared Log Error): ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œì˜ ì œê³±ê·¼ ì˜¤ì°¨. ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MPE": "í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨ (Mean Percentage Error): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ë¹„ìœ¨ ì˜¤ì°¨ í‰ê· . 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.",
	    "MAPE": "í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ (Mean Absolute Percentage Error): ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨ì˜ í‰ê· . ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ.",
	    "R2": "R2 ì ìˆ˜ (Coefficient of Determination): ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë‚˜íƒ€ëƒ„. 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.",
	}
	
	# Append explanations to results
	print("\nModel Evaluation Results with Explanations:")
	for metric, explanation in metric_explanations.items():
	    print(f"{metric}: {explanation}")
	    print(evaluation_results.loc[metric])
	    print()
	
	# Prediction
	test_input = pd.DataFrame(
	    [[55, 21, 2, "female", "no", "northeast"]],
	    columns=["age", "bmi", "children", "sex", "smoker", "region"]
	)
	
	# Encode and predict
	test_encoded = encoder.transform(test_input[categorical_features])
	test_numerical = test_input[numerical_features]
	test_preprocessed = pd.DataFrame(
	    np.hstack([test_numerical, test_encoded]),
	    columns=numerical_features + encoder.get_feature_names_out().tolist()
	)
	
	# Predictions for test input
	predictions = {}
	for name, model in models.items():
	    predictions[name] = model.predict(test_preprocessed)[0]
	
	# Format predictions for consistent decimal places
	predictions_df = pd.DataFrame(predictions, index=["Predicted Charges"]).applymap(lambda x: f"{x:.6f}")
	
	# Display predictions
	print("\nPredicted Charges for Input:")
	print(predictions_df)
	
<br>

	################################################################################
	# Ridge Regression
	# Lasso Regression
	# Elastic Net Regression
	# Random Forest Regression
	# XGBoost
	# LightGBM
	################################################################################
	
	# Check and install necessary packages
	import subprocess
	import sys
	
	def install(package):
	    try:
	        __import__(package)
	    except ImportError:
	        print(f"Installing {package}...")
	        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
	
	# List of required packages
	required_packages = ['pandas', 'scikit-learn', 'xgboost', 'lightgbm', 'numpy']
	for package in required_packages:
	    install(package)
	
	# Import libraries
	import pandas as pd
	import numpy as np
	from sklearn.model_selection import train_test_split
	from sklearn.preprocessing import OneHotEncoder
	from sklearn.linear_model import Ridge, Lasso, ElasticNet
	from sklearn.ensemble import RandomForestRegressor
	from xgboost import XGBRegressor
	from lightgbm import LGBMRegressor
	from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
	
	# Load dataset from URL
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/insurance.csv"
	df = pd.read_csv(data_url)
	
	# Check and handle missing values
	print("Checking for missing values...")
	print(df.isnull().sum())  # Display the count of NaN values per column
	
	# Ensure no missing values
	assert not df.isnull().values.any(), "Data contains missing values!"
	
	# Preprocessing
	X = df.drop("charges", axis=1)
	y = df["charges"]
	categorical_features = ["sex", "smoker", "region"]
	numerical_features = ["age", "bmi", "children"]
	
	# Updated sparse_output instead of sparse
	encoder = OneHotEncoder(sparse_output=False, drop="first")
	X_encoded = encoder.fit_transform(X[categorical_features])
	X_numerical = X[numerical_features]
	
	X_preprocessed = pd.DataFrame(
	    np.hstack([X_numerical, X_encoded]),
	    columns=numerical_features + encoder.get_feature_names_out().tolist()
	)
	
	# Train-test split
	X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)
	
	# Evaluation metrics
	def evaluate_model(y_true, y_pred):
	    me = np.mean(y_pred - y_true)  # í‰ê·  ì˜¤ì°¨ (ì˜ˆì¸¡ê°’ - ì‹¤ì œê°’)
	    mae = mean_absolute_error(y_true, y_pred)  # í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
	    mse = mean_squared_error(y_true, y_pred)  # í‰ê·  ì œê³± ì˜¤ì°¨
	    rmse = np.sqrt(mse)  # í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨
	
	    # Conditional MSLE calculation
	    if (y_true > 0).all() and (y_pred > 0).all():
	        msle = mean_squared_error(np.log1p(y_true), np.log1p(y_pred))  # í‰ê·  ì œê³± ì˜¤ì°¨ (ë¡œê·¸ ì ìš©)
	        rmsle = np.sqrt(msle)  # í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (ë¡œê·¸ ì ìš©)
	    else:
	        msle = np.nan
	        rmsle = np.nan
	
	    mpe = np.mean((y_pred - y_true) / y_true) * 100  # í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨
	    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨
	    r2 = r2_score(y_true, y_pred)  # R2 ì ìˆ˜
	
	    return {
	        "ME": me,
	        "MAE": mae,
	        "MSE": mse,
	        "MSLE": msle,
	        "RMSE": rmse,
	        "RMSLE": rmsle,
	        "MPE": mpe,
	        "MAPE": mape,
	        "R2": r2,
	    }
	
	# Initialize models
	models = {
	    "Ridge Regression": Ridge(),
	    "Lasso Regression": Lasso(),
	    "Elastic Net Regression": ElasticNet(),
	    "Random Forest Regression": RandomForestRegressor(random_state=42),
	    "XGBoost": XGBRegressor(random_state=42),
	    "LightGBM": LGBMRegressor(random_state=42),
	}
	
	# Train and evaluate models
	results = {}
	for name, model in models.items():
	    model.fit(X_train, y_train)
	    y_pred = model.predict(X_test)
	
	    # Check for invalid prediction values
	    if (y_pred < 0).any():
	        print(f"Warning: Model {name} produced negative predictions. Adjusting values to zero.")
	        y_pred = np.maximum(y_pred, 0)  # Replace negative predictions with 0
	
	    results[name] = evaluate_model(y_test, y_pred)
	
	# Format evaluation results for consistent decimal places
	evaluation_results = pd.DataFrame(results)
	evaluation_results = evaluation_results.applymap(lambda x: f"{x:.6f}" if pd.notnull(x) else "NaN")
	
	# Display formatted results
	print("\nModel Evaluation Results:")
	print(evaluation_results)
	
	# Prediction
	test_input = pd.DataFrame(
	    [[55, 21, 2, "female", "no", "northeast"]],
	    columns=["age", "bmi", "children", "sex", "smoker", "region"]
	)
	
	# Encode and predict
	test_encoded = encoder.transform(test_input[categorical_features])
	test_numerical = test_input[numerical_features]
	test_preprocessed = pd.DataFrame(
	    np.hstack([test_numerical, test_encoded]),
	    columns=numerical_features + encoder.get_feature_names_out().tolist()
	)
	
	# Predictions for test input
	predictions = {}
	for name, model in models.items():
	    predictions[name] = model.predict(test_preprocessed)[0]
	
	# Format predictions for consistent decimal places
	predictions_df = pd.DataFrame(predictions, index=["Predicted Charges"]).applymap(lambda x: f"{x:.6f}")
	
	# Display predictions
	print("\nPredicted Charges for Input:")
	print(predictions_df)

---

![](./images/tscore.png)
<br>

---
#  12-2 : ë¶„ë¥˜ í‰ê°€ ì§€í‘œ
---
	
 	[1] ì˜¤ì°¨í–‰ë ¬, í˜¼ë™í–‰ë ¬ (Confusion Matrix)
  	[2] ì •í™•ë„ (Accurancy)
	[3] ì •ë°€ë„ (Precision), PPV (Positive Predictive Value)
	[4] ì¬í˜„ìœ¨ (Recall), ë¯¼ê°ë„ (Sensitivity), TPR (True Positive Rate)
	[5] F1 score
 	[6] ì˜¤ë¶„ë¥˜ìœ¨ (Error Rate)
  	[7] íŠ¹ì´ë„ (Specificity), TNR(True Negative Rate)
   	[8] ìœ„ì–‘ì„±ë¥  (Fall Out), FPR(False Positive Rate)
	[9] ROC curve
	[10]AUC score
	  
---

# [1] ì˜¤ì°¨í–‰ë ¬, í˜¼ë™í–‰ë ¬ (Confusion Matrix)

![](./images/CM_table.PNG)<br>
â–£ ì •ì˜: ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ê°„ì˜ ë¶„ë¥˜ ê²°ê³¼ë¥¼ í–‰ë ¬ í˜•íƒœë¡œ í‘œí˜„<br>
â–£ í•„ìš”ì„±: ë¶„ë¥˜ ëª¨ë¸ì˜ ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ ê³„ì‚°ì˜ ê¸°ì´ˆ<br>
â–£ ì¥ì : ì˜ˆì¸¡ì˜ ì „ì²´ì ì¸ ë¶„í¬ë¥¼ í•œëˆˆì— íŒŒì•…<br>
â–£ ë‹¨ì : ì´ì§„ ë¶„ë¥˜ì— ì í•©í•˜ë©° ë‹¤ì¤‘ í´ë˜ìŠ¤ì— ì ìš© ì‹œ ë³µì¡ë„ê°€ ì¦ê°€<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html<br>

TP(True Positive): ëª¨ë¸ì´ positiveë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ positive (ì •ë‹µ)<br>
TN(True Negative): ëª¨ë¸ì´ negativeë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ negative (ì •ë‹µ)<br>
FP(False Positive): ëª¨ë¸ì´ positiveë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ negative (ì˜¤ë‹µ)<br>
FN(False Negative): ëª¨ë¸ì´ negativeë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œë¡œ ì •ë‹µì´ positive (ì˜¤ë‹µ)<br>
<br>
**scikit-learnì˜ confusion_matrix ê¸°ë°˜**
<br>
![](./images/CM_table_real.PNG)

<br>

	from sklearn.metrics import confusion_matrix

	cm = confusion_matrix(y_true, y_pred)

<br>

# [2] ì •í™•ë„ (Accurancy)

$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$<br><br>
â–£ ì •ì˜: ì „ì²´ ë°ì´í„° ì¤‘ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡ëœ ë¹„ìœ¨(ë°ì´í„°ê°€ ë¶ˆê· í˜•í•  ë•Œ(positive:negative=9:1)ëŠ” Accuracyë§Œìœ¼ë¡œ ì œëŒ€ë¡œ ë¶„ë¥˜í–ˆëŠ”ì§€ëŠ” ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— Recallê³¼ Precisionì„ ì‚¬ìš©)<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ì‘ë™í•˜ëŠ”ì§€ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ í‰ê°€<br>
â–£ ì¥ì : ë‹¨ìˆœí•˜ê³  ì´í•´ê°€ ìš©ì´<br>
â–£ ë‹¨ì : ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì„ ì˜ëª» í‰ê°€í•  ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html<br>

<br>

	from sklearn.metrics import accuracy_score

	acc = accuracy_score(y_true, y_pred)

<br>

# [3] ì •ë°€ë„ (Precision), PPV(Positive Predictive Value)

$Precision = \frac{TP}{TP + FP}$<br><br>
â–£ ì •ì˜: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê¸ì •(positive) í´ë˜ìŠ¤ ì¤‘ ì‹¤ì œë¡œ ê¸ì •(positive) í´ë˜ìŠ¤ì¸ ë¹„ìœ¨ë¡œ, ì‹¤ì œ ì •ë‹µì´ negativeì¸ ë°ì´í„°ë¥¼ positiveë¼ê³  ì˜ëª» ì˜ˆì¸¡í•˜ë©´ ì•ˆ ë˜ëŠ” ê²½ìš°ì— ì¤‘ìš”í•œ ì§€í‘œê°€ ë  ìˆ˜ ìˆìœ¼ë©° Precisionì„ ë†’ì´ê¸° ìœ„í•´ì„  FP(ëª¨ë¸ì´ positiveë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì •ë‹µì€ negativeì¸ ê²½ìš°)ë¥¼ ë‚®ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”<br>
â–£ í•„ìš”ì„±: ì˜ëª»ëœ ê¸ì • ì˜ˆì¸¡(FP)ì„ ì¤„ì´ëŠ” ë° ì¤‘ìš”í•œ ì§€í‘œ<br>
â–£ ì¥ì : ì •í™•í•œ ì˜ˆì¸¡ì„ ê°•ì¡°<br>
â–£ ë‹¨ì : FNì€ ê³ ë ¤í•˜ì§€ ì•Šì•„ ì¬í˜„ìœ¨ê³¼ í•¨ê»˜ ì‚¬ìš© í•„ìš”<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html<br>

<br>

	from sklearn.metrics import precision_score
	
	precision = precision_score(y_true, y_pred)

<br>

# [4] ì¬í˜„ìœ¨ (Recall), ë¯¼ê°ë„ (Sensitivity), TPR (True Positive Rate)

$Recall = \frac{TP}{TP + FN}$<br><br>
â–£ ì •ì˜: ì‹¤ì œë¡œ ì •ë‹µì´ ê¸ì •(positive)ì¸ ê²ƒë“¤ ì¤‘ì—ì„œ ëª¨ë¸ì´ ê¸ì •(positive)ì´ë¼ê³  ì˜ˆì¸¡í•œ ë¹„ìœ¨ë¡œ, ì‹¤ì œ ì •ë‹µì´ positiveì¸ ë°ì´í„°ë¥¼ negativeë¼ê³  ì˜ëª» ì˜ˆì¸¡í•˜ë©´ ì•ˆ ë˜ëŠ” ê²½ìš°ì— ì¤‘ìš”í•œ ì§€í‘œê°€ ë  ìˆ˜ ìˆìœ¼ë©°, Recallë¥¼ ë†’ì´ê¸° ìœ„í•´ì„  FN(ëª¨ë¸ì´ negativeë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì •ë‹µì´ positiveì¸ ê²½ìš°)ì„ ë‚®ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”<br>
â–£ í•„ìš”ì„±: ë†“ì¹œ ê¸ì • ì˜ˆì¸¡(FN)ì„ ì¤„ì´ëŠ” ë° ì¤‘ìš”<br>
â–£ ì¥ì : ì‹¤ì œ ê¸ì • í´ë˜ìŠ¤ì— ëŒ€í•œ ëª¨ë¸ì˜ ë¯¼ê°ì„±ì„ ë‚˜íƒ€ëƒ„<br>
â–£ ë‹¨ì : FPëŠ” ê³ ë ¤í•˜ì§€ ì•Šì•„ Precisionê³¼ í•¨ê»˜ ì‚¬ìš© í•„ìš”<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html<br>

<br>

	from sklearn.metrics import recall_score
	
	recall = recall_score(y_true, y_pred)

<br>

# [5] F1 score

$F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}$<br><br>
â–£ ì •ì˜: Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· ìœ¼ë¡œ ë‘ ê°’ì˜ ê· í˜•ì„ í‰ê°€. Recallê³¼ Precisionì€ ìƒí˜¸ ë³´ì™„ì ì¸ í‰ê°€ ì§€í‘œì´ê¸° ë•Œë¬¸ì— F1 scoreë¥¼ ì‚¬ìš©í•˜ë©°, Precisionê³¼ Recallì´ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì³ì§€ì§€ ì•Šê³  ëª¨ë‘ í´ ë•Œ í° ê°’<br>
â–£ í•„ìš”ì„±: ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ Precisionê³¼ Recall ê°„ì˜ ê· í˜•ì„ í‰ê°€<br>
â–£ ì¥ì : ë‘ ì§€í‘œ ê°„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ë°˜ì˜<br>
â–£ ë‹¨ì : ê°œë³„ì ì¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ<br>
â–£ ì˜ˆì œ:https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html<br>

<br>

	from sklearn.metrics import f1_score

	f1 = f1_score(y_true, y_pred)

<br>

# [6] ì˜¤ë¶„ë¥˜ìœ¨ (Error Rate)

$Accuracy = \frac{FP + FN}{TP + TN + FP + FN}$<br><br>
â–£ ì •ì˜: ì „ì²´ ë°ì´í„° ì¤‘ ì˜ëª» ì˜ˆì¸¡ëœ ë¹„ìœ¨<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì˜ ë¶€ì •í™•ë„ë¥¼ ë‚˜íƒ€ëƒ„<br>
â–£ ì¥ì : ì •í™•ë„ì˜ ë³´ì™„ ì§€í‘œë¡œ í™œìš© ê°€ëŠ¥<br>
â–£ ë‹¨ì : ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” ìœ ì˜ë¯¸í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ : https://scikit-learn.org/stable/auto_examples/model_selection/plot_train_error_vs_test_error.html<br>

<br>

	error_rate = 1 - accuracy_score(y_true, y_pred)

<br>

# [7] íŠ¹ì´ë„ (Specificity), TNR(True Negative Rate)

$Specificity = \frac{TN}{TN + FP}$<br><br>
â–£ ì •ì˜: ì‹¤ì œ ë¶€ì • ë°ì´í„° ì¤‘ì—ì„œ ì˜¬ë°”ë¥´ê²Œ ë¶€ì •ìœ¼ë¡œ ì˜ˆì¸¡í•œ ë¹„ìœ¨<br>
â–£ í•„ìš”ì„±: ë¶€ì • í´ë˜ìŠ¤ë¥¼ ì •í™•íˆ ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€<br>
â–£ ì¥ì : Negative classì— ì´ˆì ì„ ë§ì¶˜ ë¶„ì„ì´ ê°€ëŠ¥<br>
â–£ ë‹¨ì : Positive classì˜ ì„±ëŠ¥ì€ ê³ ë ¤í•˜ì§€ ì•ŠìŒ<br>

<br>

	tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
	
	specificity = tn / (tn + fp)

<br>

# [8] ìœ„ì–‘ì„±ë¥  (Fall Out), FPR(False Positive Rate)

$Fall Out = 1 - Specificity = 1 - \frac{TN}{TN + FP} = \frac{FP}{FP + TN}$<br><br>
â–£ ì •ì˜: ì‹¤ì œ ë¶€ì •(negative) ë°ì´í„° ì¤‘ì—ì„œ ê¸ì •(positive)ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ë¹„ìœ¨<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì´ ì˜ëª»ëœ ê¸ì •ì„ ì–¼ë§ˆë‚˜ ìƒì„±í•˜ëŠ”ì§€ í‰ê°€<br>
â–£ ì¥ì : íŠ¹ì´ë„ì˜ ë³´ì™„ ì§€í‘œë¡œ ì‚¬ìš©<br>
â–£ ë‹¨ì : ê¸ì • í´ë˜ìŠ¤ì˜ ì„±ëŠ¥ì€ í‰ê°€í•˜ì§€ ëª»í•¨<br>

<br>

	tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
	
	fpr = fp / (fp + tn)

<br>

# [9] ROC curve
â–£ ì •ì˜: TPR(ì¬í˜„ìœ¨) Yì¶•ê³¼ FPR(ìœ„ì–‘ì„±ë¥ ) Xì¶•ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚¸ ê³¡ì„ ìœ¼ë¡œ ë‹¤ì–‘í•œ ì„ê³„ê°’ì—ì„œ Recall-Falloutì˜ ë³€í™”ë¥¼ ì‹œê°í™”í•œ ê²ƒ(Falloutì€ ì‹¤ì œ Falseì¸ data ì¤‘ì—ì„œ ëª¨ë¸ì´ Trueë¡œ ë¶„ë¥˜í•­ ë¹„ìœ¨ì„, Recallì€ ì‹¤ì œ Trueì¸ data ì¤‘ì—ì„œ ëª¨ë¸ì´ Trueë¡œ ë¶„ë¥˜í•œ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ„)<br>
â–£ í•„ìš”ì„±: ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì‹œê°ì ìœ¼ë¡œ í‰ê°€<br>
â–£ ì¥ì : Thresholdì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” í™•ì¸ì´ ê°€ëŠ¥<br>
â–£ ë‹¨ì : ê³¡ì„ ì´ ë‹¨ì¼ ìˆ«ìë¡œ ìš”ì•½ë˜ì§€ ì•Šì•„ ë¹„êµê°€ ì–´ë ¤ìš¸ ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html<br>

<br>

	from sklearn.metrics import roc_curve

	y_score = model.predict_proba(X_test)[:, 1]
	fpr, tpr, thresholds = roc_curve(y_true, y_score)


<br>	


# [10] AUC (Area Under Curve) score
â–£ ì •ì˜: ROC Curveì˜ ì•„ë˜ ë©´ì ìœ¼ë¡œ, 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§<br>
â–£ í•„ìš”ì„±: ëª¨ë¸ì˜ ë¶„ë¥˜ ì„±ëŠ¥ì„ ìˆ«ìë¡œ ê°„ë‹¨íˆ ë‚˜íƒ€ëƒ„<br>
â–£ ì¥ì : Thresholdì— ê´€ê³„ì—†ì´ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€<br>
â–£ ë‹¨ì : ë°ì´í„° ë¶ˆê· í˜•ì´ ì‹¬í•œ ê²½ìš° ì™œê³¡ë  ê°€ëŠ¥ì„±<br>
â–£ ì˜ˆì œ: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html<br>

<br>

	from sklearn.metrics import roc_auc_score

	auc = roc_auc_score(y_true, y_score)

<br>

1.0 ~ 0.9 : ì•„ì£¼ ì¢‹ìŒ<br>
0.9 ~ 0.8 : ì¢‹ìŒ<br>
0.8 ~ 0.7 : ê´œì°®ì€ ëª¨ë¸<br>
0.7 ~ 0.6 : ì˜ë¯¸ëŠ” ìˆìœ¼ë‚˜ ì¢‹ì€ ëª¨ë¸ì€ ì•„ë‹˜<br>
0.6 ~ 0.5 : ì¢‹ì§€ ì•Šì€ ëª¨ë¸<br>

<br>


**(ë¶„ë¥˜ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤)**

	# ============================================
	# Iris ê¸°ë°˜ ì´ì§„ë¶„ë¥˜ + í‰ê°€ì§€í‘œ 10ê°œ & í•´ì„í‘œ
	#  - ë ˆì´ë¸”: setosa(1) vs not-setosa(0)
	# ============================================
	import numpy as np
	
	from sklearn.datasets import load_iris
	from sklearn.model_selection import train_test_split
	from sklearn.linear_model import LogisticRegression
	from sklearn.metrics import (
	    confusion_matrix,
	    accuracy_score,
	    precision_score,
	    recall_score,
	    f1_score,
	    roc_curve,
	    roc_auc_score,
	)
	
	# ---------------------------------------------------------
	# 1. í•´ì„ ê¸°ì¤€ ë¬¸ìì—´ ì •ì˜
	# ---------------------------------------------------------
	CRIT_HIGH_09 = "ê°’ â‰¥ 0.90:ì¢‹ìŒ, 0.70 â‰¤ ê°’ < 0.90:ë³´í†µ, ê°’ < 0.70:ë‚˜ì¨"
	CRIT_LOW_01  = "ê°’ â‰¤ 0.10:ì¢‹ìŒ, 0.10 < ê°’ â‰¤ 0.30:ë³´í†µ, ê°’ > 0.30:ë‚˜ì¨"
	CRIT_AUC     = "AUC â‰¥ 0.90:ì¢‹ìŒ, 0.80 â‰¤ AUC < 0.90:ë³´í†µ, AUC < 0.80:ë‚˜ì¨"
	CRIT_ROC     = "ê³¡ì„ ì´ ì¢Œìƒë‹¨ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ (AUC ê¸°ì¤€: " + CRIT_AUC + ")"
	
	# ---------------------------------------------------------
	# 2. í•´ì„ í•¨ìˆ˜ë“¤
	# ---------------------------------------------------------
	# ê°’ì´ í´ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ(Acc, Precision, Recall, F1, TPR, TNR ë“±)
	def interpret_high_good(v):
	    if v >= 0.90: return "ì¢‹ìŒ"
	    elif v >= 0.70: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ(Error Rate, FPR ë“±)
	def interpret_low_good(v):
	    if v <= 0.10: return "ì¢‹ìŒ"
	    elif v <= 0.30: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# AUC ë° ROC í•´ì„ìš©
	def interpret_auc(v):
	    if v >= 0.90: return "ì¢‹ìŒ"
	    elif v >= 0.80: return "ë³´í†µ"
	    else: return "ë‚˜ì¨"
	
	# ---------------------------------------------------------
	# 3. ë°ì´í„° ë¡œë“œ & ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ êµ¬ì„±
	# ---------------------------------------------------------
	iris = load_iris()
	X = iris.data               # (150, 4)
	y_multi = iris.target       # 0:setosa, 1:versicolor, 2:virginica
	
	# ì´ì§„ ë¶„ë¥˜: setosa(1) vs ë‚˜ë¨¸ì§€(0)
	y = (y_multi == 0).astype(int)
	
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
	
	# ê°„ë‹¨í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ë¥˜ê¸°
	clf = LogisticRegression(solver="liblinear")
	clf.fit(X_train, y_train)
	
	# ì˜ˆì¸¡ (ë ˆì´ë¸”, í™•ë¥ )
	y_pred = clf.predict(X_test)
	y_score = clf.predict_proba(X_test)[:, 1]   # ì–‘ì„±(1)ì¼ í™•ë¥ 
	
	# ---------------------------------------------------------
	# 4. ë¶„ë¥˜ í‰ê°€ì§€í‘œ 10ê°œ ê³„ì‚°
	# ---------------------------------------------------------
	# [1] Confusion Matrix
	cm = confusion_matrix(y_test, y_pred)
	tn, fp, fn, tp = cm.ravel()
	
	# [2] Accuracy
	acc = accuracy_score(y_test, y_pred)
	
	# [3] Precision (PPV)
	precision = precision_score(y_test, y_pred)
	
	# [4] Recall / Sensitivity / TPR
	recall = recall_score(y_test, y_pred)  # TPR
	
	# [5] F1 score
	f1 = f1_score(y_test, y_pred)
	
	# [6] Error Rate
	error_rate = 1 - acc
	
	# [7] Specificity / TNR
	specificity = tn / (tn + fp)
	
	# [8] FPR (Fall-out)
	fpr_value = fp / (fp + tn)
	
	# [9] ROC curve
	fpr, tpr, thresholds = roc_curve(y_test, y_score)  # ê³¡ì„ ìš© ì¢Œí‘œ
	
	# [10] AUC score
	auc = roc_auc_score(y_test, y_score)
	
	# ---------------------------------------------------------
	# 5. Raw ê°’ ì¶œë ¥
	# ---------------------------------------------------------
	print("=== Classification Metrics on Iris (setosa vs others) ===\n")	
	print(">> Raw Metric Values")
	print(f"[1] Confusion Matrix:\n{cm}")
	print(f"[2] Accuracy                : {acc:.4f}")
	print(f"[3] Precision (PPV)         : {precision:.4f}")
	print(f"[4] Recall (Sensitivity/TPR): {recall:.4f}")
	print(f"[5] F1-score                : {f1:.4f}")
	print(f"[6] Error Rate              : {error_rate:.4f}")
	print(f"[7] Specificity (TNR)       : {specificity:.4f}")
	print(f"[8] FPR (Fall-out)          : {fpr_value:.4f}")
	print(f"[9] ROC curve points        : fpr.shape={fpr.shape}, tpr.shape={tpr.shape}")
	print(f"[10] AUC score              : {auc:.4f}\n")
	
	# ---------------------------------------------------------
	# 6. í•´ì„ìš© í…Œì´ë¸” êµ¬ì„± (ì§€í‘œëª…, ê°’, í•´ì„, ê¸°ì¤€)
	# ---------------------------------------------------------
	rows = []
	
	# [1] Confusion Matrix â†’ ì •í™•ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´ì„
	rows.append((
	    "[1] Confusion Matrix", f"TN={tn}, FP={fp}, FN={fn}, TP={tp}",
	    interpret_high_good(acc), "ëŒ€ê°í•© ë¹„ìœ¨(Accuracy) ê¸°ì¤€: " + CRIT_HIGH_09))
	
	rows.append((
	    "[2] Accuracy", f"{acc:.4f}", interpret_high_good(acc), CRIT_HIGH_09))
	
	rows.append((
	    "[3] Precision (PPV)", f"{precision:.4f}", interpret_high_good(precision), CRIT_HIGH_09	))
	
	rows.append((
	    "[4] Recall (Sensitivity/TPR)",f"{recall:.4f}", interpret_high_good(recall), CRIT_HIGH_09))
	
	rows.append((
	    "[5] F1-score",f"{f1:.4f}", interpret_high_good(f1), CRIT_HIGH_09))
	
	rows.append((
	    "[6] Error Rate", f"{error_rate:.4f}", interpret_low_good(error_rate), CRIT_LOW_01))
	
	rows.append((
	    "[7] Specificity (TNR)", f"{specificity:.4f}", interpret_high_good(specificity), CRIT_HIGH_09))
	
	rows.append((
	    "[8] FPR (Fall-out)", f"{fpr_value:.4f}", interpret_low_good(fpr_value), CRIT_LOW_01))
	
	rows.append((
	    "[9] ROC curve", f"points={len(fpr)}ê°œ", interpret_auc(auc), CRIT_ROC))
	
	rows.append((
	    "[10] AUC score", f"{auc:.4f}", interpret_auc(auc), CRIT_AUC))
	
	# ---------------------------------------------------------
	# 7. í•´ì„ í…Œì´ë¸” ì¶œë ¥
	# ---------------------------------------------------------
	print(">> í•´ì„ í…Œì´ë¸” (íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€, ë°ì´í„°/ë„ë©”ì¸ì— ë”°ë¼ ì¡°ì • ê¶Œì¥)")
	print("-" * 120)
	print(f"{'ì§€í‘œ':<28}{'ê°’':<24}{'í•´ì„':<10}{'ê¸°ì¤€'}")
	print("-" * 120)
	
	for name, value, interp, crit in rows:
	    print(f"{name:<28}{value:<24}{interp:<10}{crit}")
	
	print("-" * 120)
	print("\nâ€» ìœ„ êµ¬ê°„ê°’ë“¤ì€ ì‹¤ë¬´Â·ì—°êµ¬ì—ì„œ ìì£¼ ì“°ëŠ” íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€ì´ë©°, ë¬¸ì œ ë‚œì´ë„ì™€ ë„ë©”ì¸ì— ë”°ë¼ ì¡°ì •í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”.")



**(ë¶„ë¥˜ í‰ê°€ì§€í‘œ 10ê°œ ì •ë¦¬ ì˜ˆì œ ì†ŒìŠ¤ ì‹¤í–‰ ê²°ê³¼)**

<br>

---

**(ë°ì´í„° ì¶œì²˜)** https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data/data
<br>
**(ë°ì´í„°êµ¬ì¡°)** ![](./images/heart_disease_uci.png)
<br>
**(ë°ì´í„°ì…‹)** https://github.com/YangGuiBee/ML/blob/main/TextBook-14/heart_disease_uci.csv

	import pandas as pd
	import numpy as np
	from sklearn.model_selection import train_test_split
	from sklearn.preprocessing import StandardScaler, LabelEncoder
	from sklearn.linear_model import LogisticRegression
	from sklearn.naive_bayes import GaussianNB
	from sklearn.neighbors import KNeighborsClassifier
	from sklearn.svm import SVC
	from sklearn.tree import DecisionTreeClassifier
	from sklearn.ensemble import RandomForestClassifier
	from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score, 
	                             f1_score, roc_auc_score, roc_curve)
	import matplotlib.pyplot as plt
	
	# 1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/heart_disease_uci.csv"
	df = pd.read_csv(data_url)
	
	# 2. ê²°ì¸¡ê°’ í™•ì¸ ë° ì²˜ë¦¬
	print("Missing values in dataset before processing:\n", df.isnull().sum())  # ê²°ì¸¡ê°’ í™•ì¸
	
	# ê²°ì¸¡ê°’ ì²˜ë¦¬
	for col in df.columns:
	    if df[col].dtype == 'object':  # ë²”ì£¼í˜• ë°ì´í„°
	        df[col].fillna(df[col].mode()[0], inplace=True)  # ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´
	    else:  # ìˆ˜ì¹˜í˜• ë°ì´í„°
	        df[col].fillna(df[col].mean(), inplace=True)  # í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
	
	print("Missing values in dataset after processing:\n", df.isnull().sum())  # ê²°ì¸¡ê°’ í™•ì¸
	
	# 3. ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
	if 'num' in df.columns:
	    df.rename(columns={"num": "target"}, inplace=True)  # 'num' ì—´ì„ 'target'ìœ¼ë¡œ ë³€ê²½
	else:
	    raise ValueError("The dataset does not contain a 'num' column.")
	
	# 4. íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸
	assert 'target' in df.columns, "The dataset does not contain a 'target' column."
	df['target'] = df['target'].astype(int)  # ë³´ì¥: íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì •ìˆ˜
	
	# ë…ë¦½ ë³€ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ë¶„ë¦¬
	X = df.drop(["target", "id", "dataset"], axis=1)  # ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
	y = df["target"]
	
	# Train-Test Split í›„ ê²°ì¸¡ê°’ í™•ì¸
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
	
	# ìµœì¢…ì ìœ¼ë¡œ ê²°ì¸¡ê°’ í™•ì¸
	assert not X_train.isnull().values.any(), "X_train contains NaN values!"
	assert not X_test.isnull().values.any(), "X_test contains NaN values!"
	
	# ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
	label_encoders = {}
	categorical_columns = ['sex', 'cp', 'restecg', 'slope', 'thal']  # ë²”ì£¼í˜• ì»¬ëŸ¼
	for col in categorical_columns:
	    le = LabelEncoder()
	    X_train[col] = le.fit_transform(X_train[col])  # ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
	    X_test[col] = le.transform(X_test[col])  # ë™ì¼í•œ ë³€í™˜ ì ìš©
	    label_encoders[col] = le
	
	# ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (k-NN, SVMì—ì„œ í•„ìš”)
	scaler = StandardScaler()
	X_train_scaled = scaler.fit_transform(X_train)
	X_test_scaled = scaler.transform(X_test)
	
	# ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”
	models = {
	    "Logistic Regression": LogisticRegression(),
	    "Naive Bayes": GaussianNB(),
	    "k-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5),
	    "Support Vector Classifier": SVC(probability=True),
	    "Decision Tree": DecisionTreeClassifier(),
	    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
	}
	
	# ê²°ê³¼ ì €ì¥ìš©
	results = {}
	
	# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
	for name, model in models.items():
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        model.fit(X_train_scaled, y_train)  # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©
	        y_pred = model.predict(X_test_scaled)
	        y_prob = model.predict_proba(X_test_scaled)
	    else:
	        model.fit(X_train, y_train)
	        y_pred = model.predict(X_test)
	        y_prob = model.predict_proba(X_test)
	    
	    # í‰ê°€
	    cm = confusion_matrix(y_test, y_pred)
	    acc = accuracy_score(y_test, y_pred)
	    prec = precision_score(y_test, y_pred, average='macro')  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì²˜ë¦¬
	    rec = recall_score(y_test, y_pred, average='macro')      # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì²˜ë¦¬
	    f1 = f1_score(y_test, y_pred, average='macro')           # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì²˜ë¦¬
	    error_rate = 1 - acc
	    auc = roc_auc_score(y_test, y_prob, multi_class='ovr')   # ë‹¤ì¤‘ í´ë˜ìŠ¤ AUC
	
	    # ì˜¤ì°¨í–‰ë ¬ì—ì„œ TP, FP, TN, FN ê³„ì‚°
	    tp = np.diag(cm).sum()  # True Positives
	    fp = cm.sum(axis=0) - np.diag(cm)  # False Positives
	    fn = cm.sum(axis=1) - np.diag(cm)  # False Negatives
	    tn = cm.sum() - (fp + fn + tp)  # True Negatives
	
	    # í´ë˜ìŠ¤ë³„ ì§€í‘œ í‰ê·  ê³„ì‚°
	    specificity = tn / (tn + fp)
	    fall_out = fp / (fp + tn)
	    recall = tp / (tp + fn)
	
	    # ê²°ê³¼ ì €ì¥
	    results[name] = {
	        "Confusion Matrix (Numeric Values)": cm.tolist(),
	        "Accuracy": acc,
	        "Precision": prec,
	        "Recall (TPR)": recall.mean(),
	        "F1 Score": f1,
	        "Error Rate": error_rate,
	        "AUC": auc,
	        "Specificity (TNR)": specificity.mean(),
	        "Fall Out (FPR)": fall_out.mean(),
	    }
	
	# ê²°ê³¼ ì¶œë ¥
	for name, metrics in results.items():
	    print(f"\n{name} Results:")
	    for metric, value in metrics.items():
	        if metric == "Confusion Matrix (Numeric Values)":
	            print(f"{metric}:\n{value}")
	        else:
	            print(f"{metric}: {value:.4f}")
	
	# ROC Curve ì‹œê°í™”
	plt.figure(figsize=(10, 6))
	for name, model in models.items():
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        y_prob = model.predict_proba(X_test_scaled)
	    else:
	        y_prob = model.predict_proba(X_test)
	    fpr = {}
	    tpr = {}
	    for i in range(len(np.unique(y_test))):  # ê° í´ë˜ìŠ¤ë³„ë¡œ ì²˜ë¦¬
	        fpr[i], tpr[i], _ = roc_curve(y_test, y_prob[:, i], pos_label=i)
	        plt.plot(fpr[i], tpr[i], label=f"{name} (Class {i})")
	
	plt.plot([0, 1], [0, 1], "k--", label="Random Guess")
	plt.xlabel("False Positive Rate")
	plt.ylabel("True Positive Rate")
	plt.title("ROC Curve")
	plt.legend()
	plt.show()
	
![](./images/result.png)
<br><br>

Random ForestëŠ” Accuracy, Error Rate, AUC ì¸¡ë©´ì—ì„œ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•˜ë©°, ìµœê³ ì˜ ëª¨ë¸ë¡œ í‰ê°€<br>
SVCëŠ” ë†’ì€ AUCì™€ ë‚®ì€ FPRë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‘ ë²ˆì§¸ ëª¨ë¸ë¡œ í‰ê°€<br>

---

**ë°ì´í„° ì „ì²˜ë¦¬** <br>
**num = 0 â†’ target = 0 (ì‹¬ì¥ë³‘ ì—†ìŒ)** <br>
**num = 1, 2, 3, 4 â†’ target = 1 (ì‹¬ì¥ë³‘ ìˆìŒ)** <br>

	import pandas as pd
	import numpy as np
	from sklearn.model_selection import train_test_split
	from sklearn.preprocessing import StandardScaler, LabelEncoder
	from sklearn.linear_model import LogisticRegression
	from sklearn.naive_bayes import GaussianNB
	from sklearn.neighbors import KNeighborsClassifier
	from sklearn.svm import SVC
	from sklearn.tree import DecisionTreeClassifier
	from sklearn.ensemble import RandomForestClassifier
	from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score, 
	                             f1_score, roc_auc_score, roc_curve)
	import matplotlib.pyplot as plt
	
	# 1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
	data_url = "https://raw.githubusercontent.com/YangGuiBee/ML/main/TextBook-12/heart_disease_uci.csv"
	df = pd.read_csv(data_url)
	
	# 2. ê²°ì¸¡ê°’ í™•ì¸ ë° ì²˜ë¦¬
	print("Missing values in dataset before processing:\n", df.isnull().sum())  # ê²°ì¸¡ê°’ í™•ì¸
	
	# ê²°ì¸¡ê°’ ì²˜ë¦¬
	for col in df.columns:
	    if df[col].dtype == 'object':  # ë²”ì£¼í˜• ë°ì´í„°
	        df[col].fillna(df[col].mode()[0], inplace=True)  # ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´
	    else:  # ìˆ˜ì¹˜í˜• ë°ì´í„°
	        df[col].fillna(df[col].mean(), inplace=True)  # í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
	
	print("Missing values in dataset after processing:\n", df.isnull().sum())  # ê²°ì¸¡ê°’ í™•ì¸
	
	# 3. íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸ ë° ì´ì§„ ë¶„ë¥˜ë¡œ ë³€í™˜
	if 'target' not in df.columns:
	    df.rename(columns={"num": "target"}, inplace=True)  # 'num' ì—´ì„ 'target'ìœ¼ë¡œ ë³€ê²½
	assert 'target' in df.columns, "The dataset does not contain a 'target' column."
	
	if df['target'].nunique() > 2:
	    print("Warning: Detected multiclass target. Converting to binary classification (0/1).")
	    df['target'] = (df['target'] > 0).astype(int)  # 0: ì‹¬ì¥ë³‘ ì—†ìŒ, 1: ì‹¬ì¥ë³‘ ìˆìŒ
	
	# ë…ë¦½ ë³€ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ë¶„ë¦¬
	X = df.drop(["target"], axis=1)  # íƒ€ê²Ÿ ì—´ ì œê±°
	y = df["target"]
	
	# ë²”ì£¼í˜• ì—´ í™•ì¸ ë° ê³ ìœ ê°’ í™•ì¸
	print("\nUnique values in categorical columns before encoding:")
	for col in X.columns:
	    if X[col].dtype == 'object':
	        print(f"{col}: {X[col].unique()}")
	
	# 4. ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
	label_encoders = {}
	categorical_columns = [col for col in X.columns if X[col].dtype == 'object']  # ë¬¸ìì—´ ì»¬ëŸ¼ ìë™ íƒì§€
	for col in categorical_columns:
	    le = LabelEncoder()
	    X[col] = le.fit_transform(X[col])  # ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
	    label_encoders[col] = le
	
	# ë²”ì£¼í˜• ì²˜ë¦¬ í›„ í™•ì¸
	print("\nUnique values in categorical columns after encoding:")
	for col in categorical_columns:
	    print(f"{col}: {X[col].unique()}")
	
	# 5. Train-Test Split
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
	
	# 6. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (k-NN, SVMì—ì„œ í•„ìš”)
	scaler = StandardScaler()
	X_train_scaled = scaler.fit_transform(X_train)
	X_test_scaled = scaler.transform(X_test)
	
	# 7. ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”
	models = {
	    "Logistic Regression": LogisticRegression(),
	    "Naive Bayes": GaussianNB(),
	    "k-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5),
	    "Support Vector Classifier": SVC(probability=True),
	    "Decision Tree": DecisionTreeClassifier(),
	    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
	}
	
	# ê²°ê³¼ ì €ì¥ìš©
	results = {}
	
	# 8. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
	for name, model in models.items():
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        model.fit(X_train_scaled, y_train)  # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©
	        y_pred = model.predict(X_test_scaled)
	        y_prob = model.predict_proba(X_test_scaled)[:, 1]
	    else:
	        model.fit(X_train, y_train)
	        y_pred = model.predict(X_test)
	        y_prob = model.predict_proba(X_test)[:, 1]
	    
	    # í‰ê°€
	    cm = confusion_matrix(y_test, y_pred)
	    acc = accuracy_score(y_test, y_pred)
	    prec = precision_score(y_test, y_pred)
	    rec = recall_score(y_test, y_pred)
	    f1 = f1_score(y_test, y_pred)
	    error_rate = 1 - acc
	    auc = roc_auc_score(y_test, y_prob)
	
	    # ê²°ê³¼ ì €ì¥
	    results[name] = {
	        "Confusion Matrix": cm.tolist(),
	        "Accuracy": acc,
	        "Precision": prec,
	        "Recall (TPR)": rec,
	        "F1 Score": f1,
	        "Error Rate": error_rate,
	        "AUC": auc
	    }
	
	# ê²°ê³¼ ì¶œë ¥
	for name, metrics in results.items():
	    print(f"\n{name} Results:")
	    for metric, value in metrics.items():
	        if metric == "Confusion Matrix":
	            print(f"{metric}:\n{value}")
	        else:
	            print(f"{metric}: {value:.4f}")
	
	# 9. ROC Curve ì‹œê°í™”
	plt.figure(figsize=(10, 6))
	for name, model in models.items():
	    if name in ["k-Nearest Neighbors", "Support Vector Classifier"]:
	        y_prob = model.predict_proba(X_test_scaled)[:, 1]
	    else:
	        y_prob = model.predict_proba(X_test)[:, 1]
	    fpr, tpr, _ = roc_curve(y_test, y_prob)
	    plt.plot(fpr, tpr, label=f"{name} (AUC: {roc_auc_score(y_test, y_prob):.2f})")
	
	plt.plot([0, 1], [0, 1], "k--", label="Random Guess")
	plt.xlabel("False Positive Rate")
	plt.ylabel("True Positive Rate")
	plt.title("ROC Curve")
	plt.legend()
	plt.show()


![](./images/result2.PNG)
<br><br> 

[1] ì˜¤ì°¨í–‰ë ¬, í˜¼ë™í–‰ë ¬(Confusion Matrix) : ê° ëª¨ë¸ì´ í´ë˜ìŠ¤ ê°„ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë¶„ë¥˜í–ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„<br>
[2] ì •í™•ë„(Accurancy) : ê°€ì¥ ê°„ë‹¨í•œ ê¸°ì¤€ìœ¼ë¡œ, ì „ì²´ ë°ì´í„° ì¤‘ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ë¹„ìœ¨<br>
[3] ì •ë°€ë„(Precision), PPV(Positive Predictive Value) : ëª¨ë¸ì´ ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ ë°ì´í„° ì¤‘ ì‹¤ì œë¡œ ì–‘ì„±ì¸ ë¹„ìœ¨<br>
[4] ì¬í˜„ìœ¨(Recall), ë¯¼ê°ë„(Sensitivity), TPR(True Positive Rate) : ì‹¤ì œ ì–‘ì„± ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ íƒì§€í–ˆëŠ”ì§€ ë‚˜íƒ€ëƒ„<br>
[5] F1 score : Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· ìœ¼ë¡œ, ë‘ ì§€í‘œì˜ ê· í˜•ì„ í‰ê°€<br>
[6] ì˜¤ë¶„ë¥˜ìœ¨(Error Rate) : ì •í™•ë„ì˜ ë³´ì™„ ì§€í‘œë¡œ, ì „ì²´ ë°ì´í„° ì¤‘ ëª¨ë¸ì´ ì˜ëª» ì˜ˆì¸¡í•œ ë¹„ìœ¨<br>
[7] íŠ¹ì´ë„(Specificity), TNR(True Negative Rate) : ì‹¤ì œ ìŒì„± ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ íƒì§€í–ˆëŠ”ì§€ ë‚˜íƒ€ëƒ„<br>
[8] ìœ„ì–‘ì„±ë¥ (Fall Out), FPR(False Positive Rate) : ìŒì„± ë°ì´í„°ë¥¼ ì–‘ì„± ë°ì´í„°ë¡œ ì˜ëª» ë¶„ë¥˜í•œ ë¹„ìœ¨<br>
[9] ROC curve : ëª¨ë“  ì„ê³„ê°’(threshold)ì— ëŒ€í•´ TPR(ë¯¼ê°ë„, Recall)ì™€ FPR(ìœ„ì–‘ì„±ë¥ )ì˜ ê´€ê³„ ì‹œê°í™”<br>
[10]AUC score : ëª¨ë¸ì´ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ë¶„ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ<br>


---



